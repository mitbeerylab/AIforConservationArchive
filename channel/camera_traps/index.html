<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Slack Export - #camera_traps</title>
    
    <link rel=stylesheet type=text/css
          href="../../static/viewer.css">
    
</head>
<body>
<div id="slack-archive-viewer">
    
    <div id="sidebar">
        <h3 id="channel-title">Public Channels</h3>
        <ul class="list" id="channel-list">
            
                <li class="channel">
                    <a href="../ai4pacificislandseabirds/index.html">
                        # ai4pacificislandseabirds
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../animal_re-id/index.html">
                        # animal_re-id
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../audio/index.html">
                        # audio
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../camera-traps-hardware/index.html">
                        # camera-traps-hardware
                    </a>
                </li>
            
                <li class="channel active">
                    <a href="index.html">
                        # camera_traps
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../camtrapai-workshops/index.html">
                        # camtrapai-workshops
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../cv4animals/index.html">
                        # cv4animals
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../cvml-solutions-for-challenging-real-world-conservation-problems/index.html">
                        # cvml-solutions-for-challenging-real-world-conservation-problems
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../cvpr2023/index.html">
                        # cvpr2023
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../datasets/index.html">
                        # datasets
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../elephant_id_database_general/index.html">
                        # elephant_id_database_general
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../esa_2023_happy_hour/index.html">
                        # esa_2023_happy_hour
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../general/index.html">
                        # general
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../help_needed/index.html">
                        # help_needed
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../jobs/index.html">
                        # jobs
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../marine/index.html">
                        # marine
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../new_papers/index.html">
                        # new_papers
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../news/index.html">
                        # news
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../petitions/index.html">
                        # petitions
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../proj-id-and-count-salmon/index.html">
                        # proj-id-and-count-salmon
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../public-engagement/index.html">
                        # public-engagement
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../random/index.html">
                        # random
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../region-pnw/index.html">
                        # region-pnw
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../region-us-ne/index.html">
                        # region-us-ne
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../region-us-sw/index.html">
                        # region-us-sw
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../resources/index.html">
                        # resources
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../seadronesee/index.html">
                        # seadronesee
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../tdwg_ml/index.html">
                        # tdwg_ml
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../upcoming_events/index.html">
                        # upcoming_events
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../what-is-that/index.html">
                        # what-is-that
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../wildlifeinsights/index.html">
                        # wildlifeinsights
                    </a>
                </li>
            
        </ul>
        <h3 id="group-title">Private Channels</h3>
        <ul class="list" id="group-list">
            
        </ul>
        <h3 id="dm-title">Direct Messages</h3>
        <ul class="list" id="dms-list">
            
        </ul>
        <h3 id="mpim-title">Group Direct Messages</h3>
        <ul class="list" id="mpims-list">
            
        </ul>
    </div>
    
    <div class="messages">
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-09 13:41:58">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-08-09 13:41:58"><div class="time">2019-08-09 13:41:58</div></a>
                <div class="msg">
                    <p>@Sara Beery has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_purpose ">
        <div id="2019-08-09 13:41:58">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-08-09 13:41:58"><div class="time">2019-08-09 13:41:58</div></a>
                <div class="msg">
                    <p>set the channel description: Channel for those interested in AI/CV for camera traps</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-09 16:37:31">
            
                <img src="https://avatars.slack-edge.com/2023-05-21/5283978847047_6dfe29e62ff090fa3306_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Jon Van Oast
                     <span class="print-only user-email">(jon@wildme.org)</span>
                </div>
                <a href="#2019-08-09 16:37:31"><div class="time">2019-08-09 16:37:31</div></a>
                <div class="msg">
                    <p>@Jon Van Oast has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-09 17:09:11">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/723921280647_3ee3dea8f62871f8a715_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Siyu Yang
                     <span class="print-only user-email">(yasiyu@microsoft.com)</span>
                </div>
                <a href="#2019-08-09 17:09:11"><div class="time">2019-08-09 17:09:11</div></a>
                <div class="msg">
                    <p>@Siyu Yang has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-09 19:53:02">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/710927732467_361cf9702d4e00793c20_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Stefan Schneider
                     <span class="print-only user-email">(sschne01@uoguelph.ca)</span>
                </div>
                <a href="#2019-08-09 19:53:02"><div class="time">2019-08-09 19:53:02</div></a>
                <div class="msg">
                    <p>@Stefan Schneider has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-12 03:53:23">
            
                <img src="https://avatars.slack-edge.com/2019-08-12/723311044288_a8ac8b8a0d085e72adf8_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Thomas Starnes
                     <span class="print-only user-email">(thomas.starnes@rspb.org.uk)</span>
                </div>
                <a href="#2019-08-12 03:53:23"><div class="time">2019-08-12 03:53:23</div></a>
                <div class="msg">
                    <p>@Thomas Starnes has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-12 09:00:08">
            
                <img src="https://secure.gravatar.com/avatar/b5ee72bcdb577878796ac3c6570e9397.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0026-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Nicole Flores
                     <span class="print-only user-email">(nflores@conservation.org)</span>
                </div>
                <a href="#2019-08-12 09:00:08"><div class="time">2019-08-12 09:00:08</div></a>
                <div class="msg">
                    <p>@Nicole Flores has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-12 10:59:06">
            
                <img src="https://avatars.slack-edge.com/2019-08-12/712290501666_f5660ea9d958bdbc61bd_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Jeffrey Thompson
                     <span class="print-only user-email">(jthompson.py@gmail.com)</span>
                </div>
                <a href="#2019-08-12 10:59:06"><div class="time">2019-08-12 10:59:06</div></a>
                <div class="msg">
                    <p>@Jeffrey Thompson has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-13 11:46:42">
            
                <img src="https://secure.gravatar.com/avatar/ec0d67f19acdfa56a92eeb6313f75d11.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0000-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Manish Rai
                     <span class="print-only user-email">(rai00007@umn.edu)</span>
                </div>
                <a href="#2019-08-13 11:46:42"><div class="time">2019-08-13 11:46:42</div></a>
                <div class="msg">
                    <p>@Manish Rai has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-13 17:52:39">
            
                <img src="https://avatars.slack-edge.com/2019-08-16/731160379015_861aca9696a735477ff0_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dave Thau
                     <span class="print-only user-email">(thau@wwf.org)</span>
                </div>
                <a href="#2019-08-13 17:52:39"><div class="time">2019-08-13 17:52:39</div></a>
                <div class="msg">
                    <p>@Dave Thau has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-14 12:34:33">
            
                <img src="https://avatars.slack-edge.com/2021-05-08/2030294018551_55c7e50192aabb4d0794_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">»òtefan Istrate
                     <span class="print-only user-email">(stefan.istrate@gmail.com)</span>
                </div>
                <a href="#2019-08-14 12:34:33"><div class="time">2019-08-14 12:34:33</div></a>
                <div class="msg">
                    <p>@»òtefan Istrate has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-08-16 12:01:23">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-08-16 12:01:23"><div class="time">2019-08-16 12:01:23</div></a>
                <div class="msg">
                    <p>via Jeff Clune:</p>

<p>New dataset on LILA: 1.4M camera trap images from ~675 species from 12 countries from the Wildlife Conservation Society. It's one of the most diverse camera trap data sets available publicly <a href="http://lila.science/datasets/wcscameratraps">http://lila.science/datasets/wcscameratraps</a> Thanks to Dan Morris at Microsoft AI For Earth for data wrangling.</p>

<p>LILA.science now has over 10 million labeled images (and counting!).</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Siyu Yang, Manish Rai
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-16 12:55:30">
            
                <img src="https://secure.gravatar.com/avatar/42e2a91668e67236a14cf21ff5ccc9c9.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Chen Luo
                     <span class="print-only user-email">(chenluo@gmail.com)</span>
                </div>
                <a href="#2019-08-16 12:55:30"><div class="time">2019-08-16 12:55:30</div></a>
                <div class="msg">
                    <p>@Chen Luo has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-19 01:36:01">
            
                <img src="https://secure.gravatar.com/avatar/8044a6e062630031e71a86e15c13c2ab.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Saket Anand
                     <span class="print-only user-email">(anands@iiitd.ac.in)</span>
                </div>
                <a href="#2019-08-19 01:36:01"><div class="time">2019-08-19 01:36:01</div></a>
                <div class="msg">
                    <p>@Saket Anand has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-19 13:38:58">
            
                <img src="https://secure.gravatar.com/avatar/fad8243912668a0add63704d16e4c44f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Subhransu Maji
                     <span class="print-only user-email">(smaji@cs.umass.edu)</span>
                </div>
                <a href="#2019-08-19 13:38:58"><div class="time">2019-08-19 13:38:58</div></a>
                <div class="msg">
                    <p>@Subhransu Maji has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-19 18:44:00">
            
                <img src="https://avatars.slack-edge.com/2019-09-16/762265682192_938865162b387728244d_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Riccardo Pressiani
                     <span class="print-only user-email">(riccardo.pressiani@mail.polimi.it)</span>
                </div>
                <a href="#2019-08-19 18:44:00"><div class="time">2019-08-19 18:44:00</div></a>
                <div class="msg">
                    <p>@Riccardo Pressiani has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-20 09:02:34">
            
                <img src="https://secure.gravatar.com/avatar/88722d903090be6058838a3a5f8ebaf6.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Sheldon
                     <span class="print-only user-email">(sheldon@cs.umass.edu)</span>
                </div>
                <a href="#2019-08-20 09:02:34"><div class="time">2019-08-20 09:02:34</div></a>
                <div class="msg">
                    <p>@Dan Sheldon has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-20 12:43:47">
            
                <img src="https://secure.gravatar.com/avatar/5258575261f09422e876e97c0d1c3d44.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0003-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Zhongwei Cheng
                     <span class="print-only user-email">(emory.cheng@gmail.com)</span>
                </div>
                <a href="#2019-08-20 12:43:47"><div class="time">2019-08-20 12:43:47</div></a>
                <div class="msg">
                    <p>@Zhongwei Cheng has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-21 14:57:19">
            
                <img src="https://secure.gravatar.com/avatar/96c1db8ec96fbc8920a90bb7b7fb52bf.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">skennoch
                     <span class="print-only user-email">(samm@vulcan.com)</span>
                </div>
                <a href="#2019-08-21 14:57:19"><div class="time">2019-08-21 14:57:19</div></a>
                <div class="msg">
                    <p>@skennoch has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-21 23:02:22">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2019-08-21 23:02:22"><div class="time">2019-08-21 23:02:22</div></a>
                <div class="msg">
                    <p>@Ben Weinstein has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-08-21 23:03:18">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2019-08-21 23:03:18"><div class="time">2019-08-21 23:03:18</div></a>
                <div class="msg">
                    <p>one thing which I think is worth mentioning, and something @Sara Beery have discussed. We really don‚Äôt have a great sense of the relative accuracy of the currently published camera trap tools, and even less knowledge about how much they are in use.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-08-21 23:03:38">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2019-08-21 23:03:38"><div class="time">2019-08-21 23:03:38</div></a>
                <div class="msg">
                    <p>in general i‚Äôm shying away from too much work until some well known stuff in the pipeline gets published.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-08-21 23:04:01">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2019-08-21 23:04:01"><div class="time">2019-08-21 23:04:01</div></a>
                <div class="msg">
                    <p>but i‚Äôm super interested in hearing anecdotes if teams are using existing tools, tried them and failed, or they didn‚Äôt reach needs, etc.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-08-21 23:05:04">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-08-21 23:05:04"><div class="time">2019-08-21 23:05:04</div></a>
                <div class="msg">
                    <p>Siyu, Dan and I are working on "publishing" benchmarks on LILA - aka making them easy to download and use</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Jon Van Oast, Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-26 13:45:45">
            
                <img src="https://avatars.slack-edge.com/2019-08-26/727564533250_4bda977d3f85f4f6fc06_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Amrita Gupta
                     <span class="print-only user-email">(agupta375@gatech.edu)</span>
                </div>
                <a href="#2019-08-26 13:45:45"><div class="time">2019-08-26 13:45:45</div></a>
                <div class="msg">
                    <p>@Amrita Gupta has joined the channel</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Siyu Yang, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-29 15:29:55">
            
                <img src="https://secure.gravatar.com/avatar/0961cf5d410ef0f41709f238abd69aa5.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0006-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Heather Lynch
                     <span class="print-only user-email">(heather.lynch@stonybrook.edu)</span>
                </div>
                <a href="#2019-08-29 15:29:55"><div class="time">2019-08-29 15:29:55</div></a>
                <div class="msg">
                    <p>@Heather Lynch has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-09-05 13:34:15">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-09-05 13:34:15"><div class="time">2019-09-05 13:34:15</div></a>
                <div class="msg">
                    <p>From @Oisin Mac Aodha:</p>

<p>This camera trap project has some nice web tools for visualizing detections.
<a href="https://public.tableau.com/profile/hailey.boone#!/vizhome/NCCCSpeciesGraphic1/Dashboard1">https://public.tableau.com/profile/hailey.boone#!/vizhome/NCCCSpeciesGraphic1/Dashboard1</a></p>

<p><a href="https://www.nccandidcritters.org/">https://www.nccandidcritters.org/</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Oisin Mac Aodha, Adrian Hughes
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-09-05 13:34:20">
            
                <img src="https://secure.gravatar.com/avatar/4391c54952e1c48b6e9f3077946818bc.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0006-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Oisin Mac Aodha
                     <span class="print-only user-email">(macaodha@caltech.edu)</span>
                </div>
                <a href="#2019-09-05 13:34:20"><div class="time">2019-09-05 13:34:20</div></a>
                <div class="msg">
                    <p>@Oisin Mac Aodha has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-10-07 16:56:14">
            
                <img src="https://secure.gravatar.com/avatar/957e12344d789fb56ad53e63aca0d148.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Benjamin Richards
                     <span class="print-only user-email">(benjamin.richards@noaa.gov)</span>
                </div>
                <a href="#2019-10-07 16:56:14"><div class="time">2019-10-07 16:56:14</div></a>
                <div class="msg">
                    <p>i've been working with underwater camera traps and would be interested in discussing methods to estimate effective sampling area for underwater traps where tag/recapture studies are impractical.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-10-16 19:02:08">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-10-16 19:02:08"><div class="time">2019-10-16 19:02:08</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* This sounds really interesting, but I haven't worked much underwater.  What methods are you using currently?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-10-16 18:55:44">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-10-16 18:55:44"><div class="time">2019-10-16 18:55:44</div></a>
                <div class="msg">
                    <p>WILDLABS is hosting a virtual meetup on Camera Traps, Tuesday October 29th.  I'll be speaking, along with Roland Kays and Sam Seccombe.  Learn more and register here: <a href="https://www.wildlabs.net/resources/community-announcements/wildlabs-virtual-meetup-invitation-camera-trapping">https://www.wildlabs.net/resources/community-announcements/wildlabs-virtual-meetup-invitation-camera-trapping</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">WILDLABS.NET</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.wildlabs.net/resources/community-announcements/wildlabs-virtual-meetup-invitation-camera-trapping">WILDLABS Virtual Meetup Invitation: Camera Trapping</a></div>
                                <div class="link-text">
                                    Our first event in Season Three of the WILDLABS Virtual Meetup Series will be held on Tuesday, October 29th from 1:00pm_2:30pm GMT / 9:00am_10:30am EDT. Joining us as speakers are community members Roland Kays, Research Professor at North Carolina State University and Head of the Biodiversity Lab at the NC Museum of Natural Sciences; Sara Beery, NSF Graduate Research Fellow at Caltech and Research Intern at Google; and Sam Seccombe, Technical Project Manager and Field Specialist in the Conservation Tech Unit at the Zoological Society of London. Their talks will be followed by open discussion and community exchange. To join, register here.
                                </div>
                                
                                
    
        <a href="https://www.wildlabs.net/resources/community-announcements/wildlabs-virtual-meetup-invitation-camera-trapping">
            <img class="preview" src="https://www.wildlabs.net/sites/default/files/original_ww1113176_copy.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.wildlabs.net/resources/community-announcements/wildlabs-virtual-meetup-invitation-camera-trapping</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sam Kelly, Amrita Gupta
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-10-27 20:52:18">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-10-27 20:52:18"><div class="time">2019-10-27 20:52:18</div></a>
                <div class="msg">
                    <p>There's a postdoc opportunity available managing a large-scale network of camera traps in Western Canada:  <a href="https://wildcams.ca/updates/were-hiring/">https://wildcams.ca/updates/were-hiring/</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">wildcams.ca</div>
                            
                            
                                
                                <div class="link-title"><a href="https://wildcams.ca/updates/were-hiring/">We&#39;re Hiring!</a></div>
                                <div class="link-text">
                                    Postdoctoral Position: Science Coordinator for the WildCAM Network We seek a postdoctoral scholar to help lead an emerging network of wildlife camera trapping in British Columbia. The network‚ÄîWildlife Cameras for Adaptive Management, or WildCAM‚Äîis aiming to improve terrestrial wildlife management through supporting and coordinating camera trap surveys and analyses across large regions in BC and beyond. A diverse set of researchers and practitioners using camera traps have formed the network and identified the need to develop and communicate best practices in data collection, processing, sharing, and synthesis. We seek a Science Coordinator to work with the WildCAM Steering Committee in developing and delivering science-based advice and tools for building the network. Duties and deliverables may include: ‚Ä¢ Reviewing and communicating best practices in camera trap methodology based on scientific literature and expert opinion. ‚Ä¢ Developing ‚Äúproof-of-concept‚Äù case studies demonstrating the benefits of a network, such as synthesizing data or coordinating sampling designs across multiple projects. ‚Ä¢ Developing, applying or advising on methods and tools to improve the efficiency of data collection and management (e.g. shared protocols, cloud database, automated image processing, data analysis programming). ‚Ä¢ Preparing proposals, fundraising, and mentoring junior researchers/staff to support network activities. ‚Ä¢ Communicating and coordinating across Steering Committee and network members (e.g. organizing conference calls, meetings, website updates). The position will be based in the Wildlife Coexistence Lab at the University of British Columbia (&lt;a href=&#34;http://wildlife.forestry.ubc.ca&#34;&gt;wildlife.forestry.ubc.ca&lt;/a&gt;), under the direct supervision of Dr. Cole Burton. However, the position will also report to WildCAM Steering Committee members (&lt;https://wildcams.ca/about-us&gt;), and will be expected to work closely with these partners and other members of the network, particularly the BC Parks Foundation (&lt;https://bcparksfoundation.ca/&gt;). Desired qualifications include: ‚Ä¢ PhD (or MSc with commensurate experience) in wildlife ecology, ecological methodology, conservation biology, or similar field. ‚Ä¢ Experience conducting field surveys with camera traps and analyzing camera trap data. ‚Ä¢ Experience working with software programs/platforms such as R, Python, Github, JAGS, PostgresSQL, HTML/Java, Compute Canada or other cloud-based servers. ‚Ä¢ Proven track record with both peer-reviewed publication and scientific communication for non-technical audiences. ‚Ä¢ Motivation to apply science to address conservation and management challenges. ‚Ä¢ Able to work independently and as part of a team with diverse partners. ‚Ä¢ Effective communicator to diverse audiences. The position is available to start as soon as possible and funding is available for 1 year at a salary of $55K + benefits (contingent on a successful Mitacs Accelerate application). There is a strong potential for extending the position for multiple years, contingent on successful fundraising. Applications should be submitted as a single pdf attachment by email to &lt;a href=&#34;mailto:cole.burton@ubc.ca&#34;&gt;cole.burton@ubc.ca&lt;/a&gt;, with the subject ‚ÄúWildCAM Science Coordinator‚Äù, and should include: 1) 1-page cover letter stating your interest and key qualifications, 2) CV including contact information for 3 references, and 3) 2-4 examples of scientific and/or non-technical writing. Review of applications will begin immediately and continue until the position is filled.
                                </div>
                                
                                
    
        <a href="https://wildcams.ca/updates/were-hiring/">
            <img class="preview" src="https://wildcams.ca/site/assets/files/1745/picture6.1200x630.png"
                width="476"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://wildcams.ca/updates/were-hiring/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Jon Van Oast, Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-10-28 23:05:46">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-10-28 23:05:46"><div class="time">2019-10-28 23:05:46</div></a>
                <div class="msg">
                    <p>The Wildlife Insights AI model can now be tested on the <a href="https://www.wildlifeinsights.org/try-ai">https://www.wildlifeinsights.org/try-ai</a> page!  This uses a google tool to allow people to drag and drop images and see the image classification results from the model.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Henrik Cox (Sentinel), Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-11-13 22:10:55">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/710927732467_361cf9702d4e00793c20_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Stefan Schneider
                     <span class="print-only user-email">(sschne01@uoguelph.ca)</span>
                </div>
                <a href="#2019-11-13 22:10:55"><div class="time">2019-11-13 22:10:55</div></a>
                <div class="msg">
                    <p><a href="https://gfycat.com/emotionaloddballindigobunting">https://gfycat.com/emotionaloddballindigobunting</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Gfycat</div>
                            
                            
                                
                                <div class="link-title"><a href="https://gfycat.com/emotionaloddballindigobunting">mmb9i</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                
    
        <a href="https://gfycat.com/emotionaloddballindigobunting">
            <img class="preview" src="https://thumbs.gfycat.com/EmotionalOddballIndigobunting-size_restricted.gif"
                width="280"
                 height="280" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://gfycat.com/emotionaloddballindigobunting</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêÖ Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üòç Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-11-16 22:52:32">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2019-11-16 22:52:32"><div class="time">2019-11-16 22:52:32</div></a>
                <div class="msg">
                    <p>Zilong: A tool to identify empty images in camera-trap data - ScienceDirect
<a href="https://www.sciencedirect.com/science/article/pii/S1574954119303322">https://www.sciencedirect.com/science/article/pii/S1574954119303322</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.sciencedirect.com/science/article/pii/S1574954119303322">Zilong: A tool to identify empty images in camera-trap data</a></div>
                                <div class="link-text">
                                    The use of camera traps to research and monitor wildlife results in a large number of images. Many of the images are the result of a false trigger, re‚Ä¶
                                </div>
                                
                                
    
        <a href="https://www.sciencedirect.com/science/article/pii/S1574954119303322">
            <img class="preview" src="https://ars.els-cdn.com/content/image/S15749541.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.sciencedirect.com/science/article/pii/S1574954119303322</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Siyu Yang, Sam Kelly, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-12-10 16:05:53">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-12-10 16:05:53"><div class="time">2019-12-10 16:05:53</div></a>
                <div class="msg">
                    <p>Just put this on the <b>#new_papers</b> channel as well, but our recent work leveraging per-camera context for camera traps is now up on arxiv!  If any of you have questions or thoughts about other ways to improve ML models for camera traps, I'd love to discuss here üôÇ <a href="https://arxiv.org/abs/1912.03538">https://arxiv.org/abs/1912.03538</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/1912.03538">Long Term Temporal Context for Per-Camera Object Detection</a></div>
                                <div class="link-text">
                                    In static monitoring cameras, useful contextual information can stretch far beyond the few seconds typical video understanding models might see: subjects may exhibit similar behavior over multiple...
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/1912.03538</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Jon Van Oast, Sam Kelly, Siyu Yang, Dan Morris
                        </div>
                    
                        <div class="message-reaction">
                        üê• Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-12-17 12:50:44">
            
                <img src="https://avatars.slack-edge.com/2023-05-21/5283978847047_6dfe29e62ff090fa3306_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Jon Van Oast
                     <span class="print-only user-email">(jon@wildme.org)</span>
                </div>
                <a href="#2019-12-17 12:50:44"><div class="time">2019-12-17 12:50:44</div></a>
                <div class="msg">
                    <p>probably <em>not</em> news to most people on here, but will post anyway. üôÇ looks like <strong>wildlife insights</strong> has officially kicked into beta and is putting the word out.  here is a blog post about it on google (hi, @Tanya Birch!) <a href="https://www.blog.google/products/earth/ai-finds-where-the-wild-things-are/">https://www.blog.google/products/earth/ai-finds-where-the-wild-things-are/</a>    or, jump right to 4.5m camera trap images: <a href="https://app.wildlifeinsights.org/explore">https://app.wildlifeinsights.org/explore</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Google</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.blog.google/products/earth/ai-finds-where-the-wild-things-are/">Using AI to find where the wild things are</a></div>
                                <div class="link-text">
                                    Wildlife Insights helps researchers make better decisions about protecting species and habitats, with the help of Google Cloud &amp;amp; TensorFlow.
                                </div>
                                
                                
    
        <a href="https://www.blog.google/products/earth/ai-finds-where-the-wild-things-are/">
            <img class="preview" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Will_Burrard-Lucas___WWF-US_-_Female_Lion.max-1300x1300.jpg"
                width="375"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.blog.google/products/earth/ai-finds-where-the-wild-things-are/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêØ Oisin Mac Aodha, Sara Beery, Siyu Yang, Ben Weinstein
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-01-02 16:58:16">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2020-01-02 16:58:16"><div class="time">2020-01-02 16:58:16</div></a>
                <div class="msg">
                    <p>Five new camera trap data sets are live on LILA, thanks to the Snapshot Safari program:</p>

<p><a href="http://lila.science/datasets/snapshot-kgalagadi">http://lila.science/datasets/snapshot-kgalagadi</a>
<a href="http://lila.science/datasets/snapshot-enonkishu">http://lila.science/datasets/snapshot-enonkishu</a>
<a href="http://lila.science/datasets/snapshot-camdeboo">http://lila.science/datasets/snapshot-camdeboo</a>
<a href="http://lila.science/datasets/snapshot-mountain-zebra">http://lila.science/datasets/snapshot-mountain-zebra</a>
<a href="http://lila.science/datasets/snapshot-kruger">http://lila.science/datasets/snapshot-kruger</a></p>

<p>Everyone go train some models!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="http://lila.science/datasets/snapshot-kgalagadi">Snapshot Kgalagadi - LILA BC</a></div>
                                <div class="link-text">
                                    This data set contains 3611 sequences of camera trap images, totaling 10222 images, from the Snapshot Kgalagadi project, part of the Snapshot Safari network. Using the same camera trapping protocols at every site, Snapshot Safari members are collecting standardized data from many protected areas in Africa, which allows for cross-site comparisons to assess the efficacy...
                                </div>
                                
                                
    
        <a href="http://lila.science/datasets/snapshot-kgalagadi">
            <img class="preview" src="http://lila.science/wp-content/uploads/2019/12/kgathumb_KGA_S1_A02_R1_IMAG0007-scaled.jpg"
                width="324"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://lila.science/datasets/snapshot-kgalagadi</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="http://lila.science/datasets/snapshot-enonkishu">Snapshot Enonkishu - LILA BC</a></div>
                                <div class="link-text">
                                    This data set contains 13301 sequences of camera trap images, totaling 28544 images, from the Snapshot Enonkishu project, part of the Snapshot Safari network. Using the same camera trapping protocols at every site, Snapshot Safari members are collecting standardized data from many protected areas in Africa, which allows for cross-site comparisons to assess the efficacy...
                                </div>
                                
                                
    
        <a href="http://lila.science/datasets/snapshot-enonkishu">
            <img class="preview" src="http://lila.science/wp-content/uploads/2019/12/enothumb_ENO_S1_B06_R1_IMAG0211.jpg"
                width="324"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://lila.science/datasets/snapshot-enonkishu</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="http://lila.science/datasets/snapshot-camdeboo">Snapshot Camdeboo - LILA BC</a></div>
                                <div class="link-text">
                                    This data set contains 12132 sequences of camera trap images, totaling 30227 images, from the Snapshot Camdeboo project, part of the Snapshot Safari network. Using the same camera trapping protocols at every site, Snapshot Safari members are collecting standardized data from many protected areas in Africa, which allows for cross-site comparisons to assess the efficacy...
                                </div>
                                
                                
    
        <a href="http://lila.science/datasets/snapshot-camdeboo">
            <img class="preview" src="http://lila.science/wp-content/uploads/2019/12/cdbthumb_CDB_S1_C04_R2_IMAG0253.jpg"
                width="324"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://lila.science/datasets/snapshot-camdeboo</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="http://lila.science/datasets/snapshot-mountain-zebra">Snapshot Mountain Zebra - LILA BC</a></div>
                                <div class="link-text">
                                    This data set contains 71688 sequences of camera trap images, totaling 73034 images, from the Snapshot Mountain Zebra project, part of the Snapshot Safari network. Using the same camera trapping protocols at every site, Snapshot Safari members are collecting standardized data from many protected areas in Africa, which allows for cross-site comparisons to assess the...
                                </div>
                                
                                
    
        <a href="http://lila.science/datasets/snapshot-mountain-zebra">
            <img class="preview" src="http://lila.science/wp-content/uploads/2019/12/mtz_thumb.MTZ_S1_B04_R3_IMAG0180.jpg"
                width="333"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://lila.science/datasets/snapshot-mountain-zebra</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="http://lila.science/datasets/snapshot-kruger">Snapshot Kruger - LILA BC</a></div>
                                <div class="link-text">
                                    This data set contains 4747 sequences of camera trap images, totaling 10072 images, from the Snapshot Kruger project, part of the Snapshot Safari network. Using the same camera trapping protocols at every site, Snapshot Safari members are collecting standardized data from many protected areas in Africa, which allows for cross-site comparisons to assess the efficacy...
                                </div>
                                
                                
    
        <a href="http://lila.science/datasets/snapshot-kruger">
            <img class="preview" src="http://lila.science/wp-content/uploads/2019/12/kru_thumb.KRU_S1_48_R1_IMAG0015.jpg"
                width="325"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://lila.science/datasets/snapshot-kruger</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêí Sara Beery, Oisin Mac Aodha, Amrita Gupta
                        </div>
                    
                        <div class="message-reaction">
                        :zebra_face: Siyu Yang, Amrita Gupta
                        </div>
                    
                        <div class="message-reaction">
                        üëç Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-01-02 17:02:49">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-01-02 17:02:49"><div class="time">2020-01-02 17:02:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Amazing!! Great work as always ‚ò∫Ô∏è</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-01-04 11:33:33">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2020-01-04 11:33:33"><div class="time">2020-01-04 11:33:33</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* And one more:</p>

<p><a href="http://lila.science/datasets/snapshot-karoo">http://lila.science/datasets/snapshot-karoo</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="http://lila.science/datasets/snapshot-karoo">Snapshot Karoo - LILA BC</a></div>
                                <div class="link-text">
                                    This data set contains 14889 sequences of camera trap images, totaling 38074 images, from the Snapshot Karoo project, part of the Snapshot Safari network. Using the same camera trapping protocols at every site, Snapshot Safari members are collecting standardized data from many protected areas in Africa, which allows for cross-site comparisons to assess the efficacy...
                                </div>
                                
                                
    
        <a href="http://lila.science/datasets/snapshot-karoo">
            <img class="preview" src="http://lila.science/wp-content/uploads/2020/01/kar_thumb.KAR_S1_D04_R1_IMAG0073.jpg"
                width="324"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://lila.science/datasets/snapshot-karoo</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-01-04 11:33:56">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2020-01-04 11:33:56"><div class="time">2020-01-04 11:33:56</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Incidentally, the best part of my job is picking thumbnail images for camera trap data sets.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-01-06 16:42:03">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2020-01-06 16:42:03"><div class="time">2020-01-06 16:42:03</div></a>
                <div class="msg">
                    <p>Blog post about our (mostly Siyu's) work on ML for camera traps, specifically talking about how we do distributed batch inference (but also general camera trap goodness). <a href="https://medium.com/microsoftazure/accelerating-biodiversity-surveys-with-azure-machine-learning-9be53f41e674">https://medium.com/microsoftazure/accelerating-biodiversity-surveys-with-azure-machine-learning-9be53f41e674</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Medium</div>
                            
                            
                                
                                <div class="link-title"><a href="https://medium.com/microsoftazure/accelerating-biodiversity-surveys-with-azure-machine-learning-9be53f41e674">Accelerating biodiversity surveys with Azure Machine Learning</a></div>
                                <div class="link-text">
                                    Bringing computer vision to millions of camera trap photos
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Reading time</div>
                                        13 min read
                                    </div>
                                
                                
    
        <a href="https://medium.com/microsoftazure/accelerating-biodiversity-surveys-with-azure-machine-learning-9be53f41e674">
            <img class="preview" src="https://miro.medium.com/max/1200/1*igcZOBGqBwlbcNaaDAVKRQ.png"
                width="332"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://medium.com/microsoftazure/accelerating-biodiversity-surveys-with-azure-machine-learning-9be53f41e674</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üî• Jon Van Oast, Sara Beery, Frederic, Sam Kelly
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-01-06 16:43:16">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2020-01-06 16:43:16"><div class="time">2020-01-06 16:43:16</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* And a special shout-out to @Sara Beery, who - aside from kicking this whole workstream off for us ~1.5 years ago - created the video that Slack chose as the thumbnail. üôÇ</p>
                    
                    
                    
                        <div class="message-reaction">
                        ü§© Jon Van Oast, Sara Beery, Siyu Yang
                        </div>
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-01-07 21:05:28">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/723921280647_3ee3dea8f62871f8a715_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Siyu Yang
                     <span class="print-only user-email">(yasiyu@microsoft.com)</span>
                </div>
                <a href="#2020-01-07 21:05:28"><div class="time">2020-01-07 21:05:28</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi @Frederic, I‚Äôm here, and good find! Just corrected this link and others pointing to GitHub pages that have moved. Thanks :)</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Frederic
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-13 01:10:25">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-02-13 01:10:25"><div class="time">2020-02-13 01:10:25</div></a>
                <div class="msg">
                    <p>Anyone working on species ID in video?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-13 09:42:04">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-02-13 09:42:04"><div class="time">2020-02-13 09:42:04</div></a>
                <div class="msg">
                    <p>me, eventually. But nothing to report for awhile.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-13 09:48:44">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-02-13 09:48:44"><div class="time">2020-02-13 09:48:44</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yeah it's been on my todo list for a while too</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 16:44:38">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-09-02 16:44:38"><div class="time">2020-09-02 16:44:38</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sara Beery I am just about to start transitioning my focus from photos to videos for the <a href="http://bearresearch.org/">BearID Project</a>. I'm going to take advantage of the <b>#AIforEarth</b> grant this year!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 16:50:44">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-09-02 16:50:44"><div class="time">2020-09-02 16:50:44</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Very cool!!! What are you planning to try first?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 16:57:52">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-09-02 16:57:52"><div class="time">2020-09-02 16:57:52</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I plan to compare an OD trained for bears (and other species) with MegaDetector followed by classifier. I will also look to add object tracking to try to maintain individuals across a clip.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 16:59:11">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-09-02 16:59:11"><div class="time">2020-09-02 16:59:11</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I think different smart ways of combining information across the clip to get better IDs is really cool.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üòé Ed Miller
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:07:36">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-09-02 17:07:36"><div class="time">2020-09-02 17:07:36</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I think this fits with this weak attention idea that we are all really exploring.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:07:49">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-09-02 17:07:49"><div class="time">2020-09-02 17:07:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* ecology has this inherent connection in time and space</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:08:15">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-09-02 17:08:15"><div class="time">2020-09-02 17:08:15</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* but due to differing positions and angles we expect classifications/detections to be similar, but not identical.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:09:15">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-09-02 17:09:15"><div class="time">2020-09-02 17:09:15</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Exactly. We've been seeing good results (3% boost, on a pretty hard dataset) with Context R-CNN on AVA btw, which is a video object detection dataset</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:09:23">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-09-02 17:09:23"><div class="time">2020-09-02 17:09:23</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* so you would use the features from frame x to inform proceeding and following frames.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:09:45">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-09-02 17:09:45"><div class="time">2020-09-02 17:09:45</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I‚Äôm moving towards similiar idea with tree detections across years.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:10:02">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-09-02 17:10:02"><div class="time">2020-09-02 17:10:02</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* we expect that detections in year 1 to inform year 2 to do joint multi-temporal learning.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:10:09">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-09-02 17:10:09"><div class="time">2020-09-02 17:10:09</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Ben I was JUST talking about that exact thing with Pietro yesterday</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:10:22">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-09-02 17:10:22"><div class="time">2020-09-02 17:10:22</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* following sara‚Äôs general idea, but one-shot detector, etc.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:10:34">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-09-02 17:10:34"><div class="time">2020-09-02 17:10:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Can we meet up sometime next week and talk about trees?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:10:56">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-09-02 17:10:56"><div class="time">2020-09-02 17:10:56</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I've got trees on the brain lately üòâ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:11:06">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-09-02 17:11:06"><div class="time">2020-09-02 17:11:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* for sure.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:11:19">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-09-02 17:11:19"><div class="time">2020-09-02 17:11:19</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* i‚Äôm on baby duty all week, let‚Äôs do next week.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:29:53">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-09-02 17:29:53"><div class="time">2020-09-02 17:29:53</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I'm not planning to do any cutting edge research, just hoping to get something working reliably. My main aim with object tracking is to boost accuracy in individual identification as per <a href="https://advances.sciencemag.org/content/5/9/eaaw0736">Chimpanzee face recognition from videos in the wild using deep learning</a>.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Science Advances</div>
                            
                            
                                
                                <div class="link-title"><a href="https://advances.sciencemag.org/content/5/9/eaaw0736">Chimpanzee face recognition from videos in the wild using deep learning</a></div>
                                <div class="link-text">
                                    Video recording is now ubiquitous in the study of animal behavior, but its analysis on a large scale is prohibited by the time and resources needed to manually process large volumes of data. We present a deep convolutional neural network (CNN) approach that provides a fully automated pipeline for face detection, tracking, and recognition of wild chimpanzees from long-term video records. In a 14-year dataset yielding 10 million face images from 23 individuals over 50 hours of footage, we obtained an overall accuracy of 92.5% for identity recognition and 96.2% for sex recognition. Using the identified faces, we generated co-occurrence matrices to trace changes in the social network structure of an aging population. The tools we developed enable easy processing and annotation of video datasets, including those from other species. Such automated analysis unveils the future potential of large-scale longitudinal video archives to address fundamental questions in behavior and conservation.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://advances.sciencemag.org/content/5/9/eaaw0736</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 17:48:37">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-09-02 17:48:37"><div class="time">2020-09-02 17:48:37</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Getting something to work well on a new species IS cutting edge research! Screw all the theorists who would tell you otherwise üòÇ</p>
                    
                    
                    
                        <div class="message-reaction">
                        ü§£ Ed Miller
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 18:13:28">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-09-02 18:13:28"><div class="time">2020-09-02 18:13:28</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Ed Miller i‚Äôm happy to look it over once you have a working pipeline. The idea of cross-imagery feature learning is the focus of alteast 3 projects i‚Äôm running, so it‚Äôll be good to share ideas.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 18:14:07">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-09-02 18:14:07"><div class="time">2020-09-02 18:14:07</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Same üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 20:03:21">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-09-02 20:03:21"><div class="time">2020-09-02 20:03:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Sounds good. The existing bearid pipeline (for photos) is built around dlib (for historical reasons). For the moment I'm just coming up to speed on Azure. I've run some experiments on OD and classification using Custom Vision. I'll look at some of the existing <a href="https://www.microsoft.com/en-us/ai/ai-for-earth-tech-resources?rtc=1">AI for Earth APIs</a>. I had a link to some other networks from Microsoft (including tracking), but I can't seem to find it at the moment.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">microsoft.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.microsoft.com/en-us/ai/ai-for-earth-tech-resources?rtc=1">AI for Earth Tech Resources - Microsoft AI</a></div>
                                <div class="link-text">
                                    Explore AI for Earth technical resources. Discover open-source tools, models, public datasets, and more resources to support scientific research.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://www.microsoft.com/en-us/ai/ai-for-earth-tech-resources?rtc=1</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 20:04:51">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-09-02 20:04:51"><div class="time">2020-09-02 20:04:51</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Feel free to send a links to models I should be looking at. üòÄ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 20:09:21">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-09-02 20:09:21"><div class="time">2020-09-02 20:09:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Oh, and did I mention I also want efficient models I can eventually run on the edge? As part of my day job (at Arm), I will be testing some models on smartphones, Raspberry Pi's, camera SoCs, microcontrollers, etc.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-02 22:25:13">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-09-02 22:25:13"><div class="time">2020-09-02 22:25:13</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I found the link for for other networks from Microsoft that I had "misplaced": <a href="https://github.com/microsoft/computervision-recipes">https://github.com/microsoft/computervision-recipes</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">GitHub</div>
                            
                            
                                
                                <div class="link-title"><a href="https://github.com/microsoft/computervision-recipes">microsoft/computervision-recipes</a></div>
                                <div class="link-text">
                                    Best Practices, code samples, and documentation for Computer Vision. - microsoft/computervision-recipes
                                </div>
                                
                                
    
        <a href="https://github.com/microsoft/computervision-recipes">
            <img class="preview" src="https://repository-images.githubusercontent.com/170161374/44d38280-094f-11ea-9181-aca44cd96864"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://github.com/microsoft/computervision-recipes</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-19 13:04:01">
            
                <img src="https://avatars.slack-edge.com/2023-05-21/5283978847047_6dfe29e62ff090fa3306_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Jon Van Oast
                     <span class="print-only user-email">(jon@wildme.org)</span>
                </div>
                <a href="#2020-02-19 13:04:01"><div class="time">2020-02-19 13:04:01</div></a>
                <div class="msg">
                    <p>@Sara Beery - we do.  re: the bots we have which look at youtube videos.  we dont really use any kind of video-specific magic (e.g. treating nearby frames as strong evidence of images of the same animal).  it is very basic -- break the image up into frames and run them through our standard pipeline.  (there is a little bit of clustering we do after finding animals, but could be doing a lot more.)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-19 13:05:19">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-02-19 13:05:19"><div class="time">2020-02-19 13:05:19</div></a>
                <div class="msg">
                    <p>Cool. Most of what I've found so far is running frame-by-frame, which makes sense because it simplifies the input pipelines significantly.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-19 13:10:44">
            
                <img src="https://avatars.slack-edge.com/2023-05-21/5283978847047_6dfe29e62ff090fa3306_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Jon Van Oast
                     <span class="print-only user-email">(jon@wildme.org)</span>
                </div>
                <a href="#2020-02-19 13:10:44"><div class="time">2020-02-19 13:10:44</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* yeah, behind the scenes it is basically some <strong>ffmpeg</strong> and handwaving, then business as usual as if they were just photos from the start.   üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-19 13:11:02">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-02-19 13:11:02"><div class="time">2020-02-19 13:11:02</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Exactly</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-19 13:05:55">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-02-19 13:05:55"><div class="time">2020-02-19 13:05:55</div></a>
                <div class="msg">
                    <p>And allows for easy pre-training</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-19 13:08:50">
            
                <img src="https://avatars.slack-edge.com/2023-05-21/5283978847047_6dfe29e62ff090fa3306_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Jon Van Oast
                     <span class="print-only user-email">(jon@wildme.org)</span>
                </div>
                <a href="#2020-02-19 13:08:50"><div class="time">2020-02-19 13:08:50</div></a>
                <div class="msg">
                    <p>yes... we have certain aspects of our identification that takes into account time-proximity, but it was written for users in the field and still cameras... so it is not really what we would want for something like video sequence.  other than assuming nearby frames are likely the same individual, one other thing we have mulled over (but not done) is increasing the sampling rate once detection has found frames with the desired species.  that is, we currently only sample every 2 sec, since these are usually long videos with lots of noise (frames of people in boats talking about their holidays!)... but once we find N consecutive desirable frames, it would make a lot of sense to go back and pull just about every frame around the positive images; much better odds of finding identifiable images.  but we currently dont do that yet.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-03-16 17:37:25">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2020-03-16 17:37:25"><div class="time">2020-03-16 17:37:25</div></a>
                <div class="msg">
                    <p>For folks here who use images from <a href="http://lila.science">LILA</a>, a small but hopefully-useful addition to LILA functionality.  When we first started LILA, we didn‚Äôt want to have to deal with the complexities of building a service that would let you query for, e.g., ‚Äúall the images of cheetahs‚Äù or even ‚Äúall the images in this one folder from this one dataset‚Äù, so it was just ‚Äúgiant zipfiles or bust‚Äù.¬† But actually, sometimes you do just want part of a data set, and also giant zipfiles have become the #1 complaint about LILA.¬†</p>

<p>We still don‚Äôt want to deal with a fancy service, but we‚Äôve found a happy intermediate that lets people (a) not have to deal with giant zipfiles and (b) download (with a little effort) subsets of data sets, e.g. by folder or by species.</p>

<p>Details are here:</p>

<pre><code>&lt;http://lila.science/image-access&gt;
</code></pre>

<p>Not super-slick, we know, but hopefully a useful step for training models, since now you're just a bit of scripting away from being able to get, e.g., all the zebra images across all the LILA data sets.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üòé Nathaniel Rindlaub
                        </div>
                    
                        <div class="message-reaction">
                        üíØ Jon Van Oast, Ben Weinstein
                        </div>
                    
                        <div class="message-reaction">
                        :zebra_face: Siyu Yang
                        </div>
                    
                        <div class="message-reaction">
                        üêó Amrita Gupta
                        </div>
                    
                        <div class="message-reaction">
                        üëç Mikey Tabak, Bistra Dilkina
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-03-16 17:38:27">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-03-16 17:38:27"><div class="time">2020-03-16 17:38:27</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* This is amazing @Dan Morris and @Siyu Yang!!! Really useful :)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2020-03-26 17:35:25">
            
                <img src="https://secure.gravatar.com/avatar/e96336d4ab1e44113cdeeb9c597c99ae.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Mikey Tabak
                     <span class="print-only user-email">(tabakma@gmail.com)</span>
                </div>
                <a href="#2020-03-26 17:35:25"><div class="time">2020-03-26 17:35:25</div></a>
                <div class="msg">
                    <p>@Mikey Tabak has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-03-28 11:44:30">
            
                <img src="https://avatars.slack-edge.com/2020-03-28/1032763057972_7c3149152b537288189e_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Shah
                     <span class="print-only user-email">(shah@conservify.org)</span>
                </div>
                <a href="#2020-03-28 11:44:30"><div class="time">2020-03-28 11:44:30</div></a>
                <div class="msg">
                    <p>Does anyone here know of a good resource on the best commercially available camera traps? I know of Trail Cam Pro but I was curious if there have been reviews or publications that did a good job at evaluating what is on the market for ecology. </p>
                    
                    
                    
                        <div class="message-reaction">
                        üì∏ Sara Beery, Shah
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-03-28 11:49:07">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-03-28 11:49:07"><div class="time">2020-03-28 11:49:07</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I don't, but would also be interested! I relied heavily on Trail Cam Pro when deciding what cameras to buy for my study, but wished there was a better resource for ecology specifically.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-04-05 18:29:30">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/723921280647_3ee3dea8f62871f8a715_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Siyu Yang
                     <span class="print-only user-email">(yasiyu@microsoft.com)</span>
                </div>
                <a href="#2020-04-05 18:29:30"><div class="time">2020-04-05 18:29:30</div></a>
                <div class="msg">
                    <p><a href="http://lila.science/">LILA</a> update! We added some bounding box labels for vehicle and bird images in the NACTI dataset, and more substantially for ~16k sequences in the WCS Camera Trap dataset covering most locations.</p>

<p>WCS Camera Traps: <a href="http://lila.science/datasets/wcscameratraps">http://lila.science/datasets/wcscameratraps</a> (16k sequences ~42k images. We also uploaded a recommended train/val/test split over camera locations to encourage reporting performance in a consistent way)</p>

<p>NACTI: <a href="http://lila.science/datasets/nacti">http://lila.science/datasets/nacti</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Sara Beery, Zac Winzurk, Manish Rai
                        </div>
                    
                        <div class="message-reaction">
                        üëç Mikey Tabak, Ben Weinstein
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-04-27 18:40:11">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/723921280647_3ee3dea8f62871f8a715_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Siyu Yang
                     <span class="print-only user-email">(yasiyu@microsoft.com)</span>
                </div>
                <a href="#2020-04-27 18:40:11"><div class="time">2020-04-27 18:40:11</div></a>
                <div class="msg">
                    <p>Hi <b>#camera_traps</b></p>

<p>We‚Äôve just released a new version (v4.1) of the MegaDetector, which incorporates a bunch more locations from Borneo, Australia, and the WCS dataset (which comes from all over the world), amongst other. It now also has a ‚Äúvehicle‚Äù class for cars/trucks/tractors/bicycles!</p>

<p>More info here: <a href="https://github.com/microsoft/CameraTraps/releases/tag/v4.1">https://github.com/microsoft/CameraTraps/releases/tag/v4.1</a></p>

<p>In the future, we plan to use the ‚Äúreleases‚Äù feature on GitHub to announce new versions of the MegaDetector (and other future models). To get notified via email and GitHub, go ‚Äúwatch‚Äù our repo with the ‚ÄúReleases only‚Äù option:</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein, Sara Beery, Oisin Mac Aodha, David Healey, Frederic, Jon Van Oast, Sam Kelly
                        </div>
                    
                        <div class="message-reaction">
                        üòé Nathaniel Rindlaub, Zac Winzurk
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-04-27 18:42:19">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-04-27 18:42:19"><div class="time">2020-04-27 18:42:19</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Awesome!!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-05-01 13:55:37">
            
                <img src="https://avatars.slack-edge.com/2020-08-03/1284586180260_ce5ba282733f34b0aeba_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sam Kelly
                     <span class="print-only user-email">(sam@conservationxlabs.org)</span>
                </div>
                <a href="#2020-05-01 13:55:37"><div class="time">2020-05-01 13:55:37</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Exited about this!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container thread_broadcast ">
        <div id="2020-06-30 18:02:12">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/723921280647_3ee3dea8f62871f8a715_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Siyu Yang
                     <span class="print-only user-email">(yasiyu@microsoft.com)</span>
                </div>
                <a href="#2020-06-30 18:02:12"><div class="time">2020-06-30 18:02:12</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* There was apparently a lot of enthusiasm for a <strong>Colab</strong> to run MegaDetector on your own images at Sara‚Äôs recent talk. Here it is! <a href="https://github.com/microsoft/CameraTraps/blob/master/detection/megadetector_colab.ipynb">https://github.com/microsoft/CameraTraps/blob/master/detection/megadetector_colab.ipynb</a></p>

<p>Thanks to Alistair Stewart for contributing this and @louis030195 for contributing an earlier version of it!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">GitHub</div>
                            
                            
                                
                                <div class="link-title"><a href="https://github.com/microsoft/CameraTraps/blob/master/detection/megadetector_colab.ipynb">microsoft/CameraTraps</a></div>
                                <div class="link-text">
                                    Tools for training and running detectors and classifiers for wildlife images collected from motion-triggered cameras. - microsoft/CameraTraps
                                </div>
                                
                                
    
        <a href="https://github.com/microsoft/CameraTraps/blob/master/detection/megadetector_colab.ipynb">
            <img class="preview" src="https://repository-images.githubusercontent.com/152634113/a8368e00-68f3-11e9-8ba4-db76ce12417c"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://github.com/microsoft/CameraTraps/blob/master/detection/megadetector_colab.ipynb</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Sara Beery, Ben Weinstein, Omiros Pantazis, Carly Batist, Sam Kelly, Jonathan Granskog
                        </div>
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery, Bob Zak, Talia Speaker
                        </div>
                    
                        <div class="message-reaction">
                        üí• Drew Gray
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-17 20:37:53">
            
                <img src="https://avatars.slack-edge.com/2020-07-01/1218123595618_770912a6d4b23b6f88b2_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Bob Zak
                     <span class="print-only user-email">(robert.zak@comcast.net)</span>
                </div>
                <a href="#2020-07-17 20:37:53"><div class="time">2020-07-17 20:37:53</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* This worked great -- easy to follow, I was detecting animals from a private data set very quickly!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôÇ Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-05-18 13:45:56">
            
                <img src="https://avatars.slack-edge.com/2019-11-13/833083458820_6e297a02aaf872c8c18f_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Nathaniel Rindlaub
                     <span class="print-only user-email">(nathaniel.rindlaub@tnc.org)</span>
                </div>
                <a href="#2020-05-18 13:45:56"><div class="time">2020-05-18 13:45:56</div></a>
                <div class="msg">
                    <p>Hey all - thought this might be of interest. Manaaki Whenua Landcare Research, a New Zealand based land management research group, is hosting a series of webinars this week and there's one at 7:30 this evening (PST) titled "Using cameras and artificial intelligence for monitoring invasive species".  Could be cool to see what folks are up to in this space down under. You can register here: <a href="https://www.landcareresearch.co.nz/about/news/events/biosecurity-bonanza/agenda">https://www.landcareresearch.co.nz/about/news/events/biosecurity-bonanza/agenda</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Manaaki Whenua - Landcare Research</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.landcareresearch.co.nz/about/news/events/biosecurity-bonanza/agenda">Biosecurity Bonanza Agenda 2020</a></div>
                                <div class="link-text">
                                    Find out about the latest biosecurity research being undertaken at Manaaki Whenua - Landcare Research. This year&#39;s Biosecurity Bonanza will be presented as a series of 11 bite-sized webinars.
                                </div>
                                
                                
    
        <a href="https://www.landcareresearch.co.nz/about/news/events/biosecurity-bonanza/agenda">
            <img class="preview" src="http://www.landcareresearch.co.nz/__data/assets/image/0018/216612/share-imag.jpg"
                width="500"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.landcareresearch.co.nz/about/news/events/biosecurity-bonanza/agenda</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Amrita Gupta, Nathaniel Rindlaub, Sam Kelly, Manish Rai, Jon Van Oast, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-20 12:17:50">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-20 12:17:50"><div class="time">2020-06-20 12:17:50</div></a>
                <div class="msg">
                    <p>The Context R-CNN code is now released in the Tensorflow Object Detection API üéâ<a href="https://github.com/tensorflow/models/tree/master/research/object_detection#june-17th-2020">https://github.com/tensorflow/models/tree/master/research/object_detection#june-17th-2020</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">GitHub</div>
                            
                            
                                
                                <div class="link-title"><a href="https://github.com/tensorflow/models/tree/master/research/object_detection#june-17th-2020">tensorflow/models</a></div>
                                <div class="link-text">
                                    Models and examples built with TensorFlow. Contribute to tensorflow/models development by creating an account on GitHub.
                                </div>
                                
                                
    
        <a href="https://github.com/tensorflow/models/tree/master/research/object_detection#june-17th-2020">
            <img class="preview" src="https://avatars2.githubusercontent.com/u/15658638?s=400&amp;v=4"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://github.com/tensorflow/models/tree/master/research/object_detection#june-17th-2020</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Oisin Mac Aodha, Ben Weinstein, Stefan Schneider, Manish Rai
                        </div>
                    
                        <div class="message-reaction">
                        üî• Siyu Yang, Zac Winzurk, David Healey, Sam Kelly, Manish Rai
                        </div>
                    
                        <div class="message-reaction">
                        ü§© Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-20 12:18:38">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-20 12:18:38"><div class="time">2020-06-20 12:18:38</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* If you want to play with it, we set up a colab with our Snapshot Serengeti trained models: <a href="https://colab.sandbox.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/context_rcnn_tutorial.ipynb">https://colab.sandbox.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/context_rcnn_tutorial.ipynb</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">colab.research.google.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://colab.sandbox.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/context_rcnn_tutorial.ipynb">Google Colaboratory</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                
    
        <a href="https://colab.sandbox.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/context_rcnn_tutorial.ipynb">
            <img class="preview" src="https://colab.research.google.com/img/colab_favicon_256px.png"
                width="250"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://colab.sandbox.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/context_rcnn_tutorial.ipynb</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-20 12:19:58">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-20 12:19:58"><div class="time">2020-06-20 12:19:58</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* These models (both Faster R-CNN and Context R-CNN) were trained on the 1st 6 seasons, using the training locations recommended on LILA.science:  <a href="http://lila.science/datasets/snapshot-serengeti">http://lila.science/datasets/snapshot-serengeti</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="http://lila.science/datasets/snapshot-serengeti">Snapshot Serengeti - LILA BC</a></div>
                                <div class="link-text">
                                    Overview This data set contains approximately 2.65M sequences of camera trap images, totaling 7.1M images, from seasons one through eleven of the Snapshot Serengeti project, the flagship project of the Snapshot Safari network. Using the same camera trapping protocols at every site, Snapshot Safari members are collecting standardized data from many protected areas in Africa,...
                                </div>
                                
                                
    
        <a href="http://lila.science/datasets/snapshot-serengeti">
            <img class="preview" src="http://lila.science/wp-content/uploads/2018/10/ss_web.jpg"
                width="333"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://lila.science/datasets/snapshot-serengeti</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-20 12:21:26">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-20 12:21:26"><div class="time">2020-06-20 12:21:26</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* They were both trained on TPUs, and all hyperparameters are specified in the config files of the models, locations of the downloadable models can be found in the TFODAPI model zoo, or in the colab üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-20 12:23:22">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-20 12:23:22"><div class="time">2020-06-20 12:23:22</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* If you have other Snapshot Serengeti data saved locally, you can use the colab to play with the effect of context. It will use whatever group of images you point to to build up the contextual memory bank, and then use that context when running inference on each image with Context R-CNN.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-20 12:25:24">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-20 12:25:24"><div class="time">2020-06-20 12:25:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* The demo images we included are from one of the LILA.science test locations (unseen during training), you can see that our baseline model isn't handling this case very well.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-22 12:09:13">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-06-22 12:09:13"><div class="time">2020-06-22 12:09:13</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* can you point to where the model is actually defined?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-22 12:09:33">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-06-22 12:09:33"><div class="time">2020-06-22 12:09:33</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* like the layers, not the colab create_model</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-22 12:39:47">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-22 12:39:47"><div class="time">2020-06-22 12:39:47</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yep! It's here: <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/context_rcnn_meta_arch.py">https://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/context_rcnn_meta_arch.py</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">GitHub</div>
                            
                            
                                
                                <div class="link-title"><a href="https://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/context_rcnn_meta_arch.py">tensorflow/models</a></div>
                                <div class="link-text">
                                    Models and examples built with TensorFlow. Contribute to tensorflow/models development by creating an account on GitHub.
                                </div>
                                
                                
    
        <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/context_rcnn_meta_arch.py">
            <img class="preview" src="https://avatars2.githubusercontent.com/u/15658638?s=400&amp;v=4"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/context_rcnn_meta_arch.py</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-22 12:41:23">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-22 12:41:23"><div class="time">2020-06-22 12:41:23</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* And attention fns are defined here: <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/context_rcnn_lib.py">https://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/context_rcnn_lib.py</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">GitHub</div>
                            
                            
                                
                                <div class="link-title"><a href="https://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/context_rcnn_lib.py">tensorflow/models</a></div>
                                <div class="link-text">
                                    Models and examples built with TensorFlow. Contribute to tensorflow/models development by creating an account on GitHub.
                                </div>
                                
                                
    
        <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/context_rcnn_lib.py">
            <img class="preview" src="https://avatars2.githubusercontent.com/u/15658638?s=400&amp;v=4"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/context_rcnn_lib.py</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-22 12:47:37">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-22 12:47:37"><div class="time">2020-06-22 12:47:37</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Oh, and we took a distillation approach to training, so any images without bbox labels got weakly-supervised bboxes from MegaDetector v3 (any boxes over 0.9 score), matched to the image-level label. We only report performance on human-bbox-labeled (from the bbox json file on LILA) images from the recommended test locations (so we don't end up evaluating on weak labels). Looking forward to testing with MDV4 to see if that boosts performance further, as several iWildCam teams reported increased performance with the new version.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-22 13:12:15">
            
                <img src="https://secure.gravatar.com/avatar/98123d6f2f764d0f5ddad33ce51efc56.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Bistra Dilkina
                     <span class="print-only user-email">(dilkina@usc.edu)</span>
                </div>
                <a href="#2020-06-22 13:12:15"><div class="time">2020-06-22 13:12:15</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* awesome work, Sara!</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-22 19:32:23">
            
                <img src="https://avatars.slack-edge.com/2020-03-04/984702846663_31b09c3232dd5129e592_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Zac Winzurk
                     <span class="print-only user-email">(zwinzurk@asu.edu)</span>
                </div>
                <a href="#2020-06-22 19:32:23"><div class="time">2020-06-22 19:32:23</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Sara, is there a PyTorch implementation of this currently?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-22 19:40:38">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-22 19:40:38"><div class="time">2020-06-22 19:40:38</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Nope, sorry!  Haha that's what happens when you do work at Google.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-22 19:40:51">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-22 19:40:51"><div class="time">2020-06-22 19:40:51</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* If you want to make one please do!!!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-22 19:44:50">
            
                <img src="https://avatars.slack-edge.com/2020-03-04/984702846663_31b09c3232dd5129e592_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Zac Winzurk
                     <span class="print-only user-email">(zwinzurk@asu.edu)</span>
                </div>
                <a href="#2020-06-22 19:44:50"><div class="time">2020-06-22 19:44:50</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Haha I understand. I‚Äôll try to give it a go</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-22 19:45:17">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-22 19:45:17"><div class="time">2020-06-22 19:45:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Happy to answer implementation questions üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-23 12:37:32">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-06-23 12:37:32"><div class="time">2020-06-23 12:37:32</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I‚Äôm forwarding to colleagues. Long term thought, but i‚Äôll probably push we start from this as a baseline for our new grant for video processing. We are replacing DeepMeerkat (<a href="http://benweinstein.weebly.com/deepmeerkat.html">http://benweinstein.weebly.com/deepmeerkat.html</a>) with more recent tools. Hopefully a human-in-loop web component + portal for people to download models to apply to local data. We‚Äôll probably need to think about pruning and reducing the backbone size, but that‚Äôs a idea for like december. We haven‚Äôt even hired the postdoc on this grant yet.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Dr. Ben Weinstein</div>
                            
                            
                                
                                <div class="link-title"><a href="http://benweinstein.weebly.com/deepmeerkat.html">DeepMeerkat</a></div>
                                <div class="link-text">
                                    Machine learning for video-based biodiversity surveys.
                                </div>
                                
                                
    
        <a href="http://benweinstein.weebly.com/deepmeerkat.html">
            <img class="preview" src="http://benweinstein.weebly.com/uploads/8/6/3/0/8630882/published/deepmeerkatlogo.png?1507923535"
                width="205"
                 height="205" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://benweinstein.weebly.com/deepmeerkat.html</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-23 12:38:51">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-23 12:38:51"><div class="time">2020-06-23 12:38:51</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Very cool. We'll also want to think about when to store a context feature, because the high frame rate videos will be different than the low frame rate bursts üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-23 12:42:06">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-06-23 12:42:06"><div class="time">2020-06-23 12:42:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* yup. I have this vision of combining with the ladder type networks (<a href="https://dawn.cs.stanford.edu//2017/06/22/noscope/">https://dawn.cs.stanford.edu//2017/06/22/noscope/</a>) I like this idea since especially in wildlife time-lapse the vast majority of frames are almost identical and don‚Äôt need a deep learning model.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">dawn.cs.stanford.edu</div>
                            
                            
                                
                                <div class="link-title"><a href="https://dawn.cs.stanford.edu//2017/06/22/noscope/">            NoScope: 1000x Faster Deep Learning Queries over Video ¬∑ Stanford DAWN        </a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                
    
        <a href="https://dawn.cs.stanford.edu//2017/06/22/noscope/">
            <img class="preview" src="https://dawn.cs.stanford.edu/assets/dawn-logo.png"
                width="236"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://dawn.cs.stanford.edu//2017/06/22/noscope/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üòç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-23 12:45:36">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-23 12:45:36"><div class="time">2020-06-23 12:45:36</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Awesome.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-28 11:28:54">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-28 11:28:54"><div class="time">2020-06-28 11:28:54</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yannic Kilcher just released a GREAT walkthrough video for the paper: <a href="https://www.youtube.com/watch?v=eI8xTdcZ6VY&amp;feature=youtu.be">https://www.youtube.com/watch?v=eI8xTdcZ6VY&amp;feature=youtu.be</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">YouTube</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="" class="icon">
                                    }
                                    <a href="https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew">
                                    Yannic Kilcher
                                    </a><span class="print-only">(https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.youtube.com/watch?v=eI8xTdcZ6VY&amp;amp;feature=youtu.be">Context R-CNN: Long Term Temporal Context for Per-Camera Object Detection (Paper Explained)</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                
    
        <a href="https://www.youtube.com/watch?v=eI8xTdcZ6VY&amp;amp;feature=youtu.be">
            <img class="preview" src="https://i.ytimg.com/vi/eI8xTdcZ6VY/hqdefault.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.youtube.com/watch?v=eI8xTdcZ6VY&amp;amp;feature=youtu.be</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-07 12:45:07">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-07-07 12:45:07"><div class="time">2020-07-07 12:45:07</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Just watched this now. Amazingly good explanation. Working on my hyperspec attention network. I added in the comments that the code was out.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-25 19:44:05">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/723921280647_3ee3dea8f62871f8a715_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Siyu Yang
                     <span class="print-only user-email">(yasiyu@microsoft.com)</span>
                </div>
                <a href="#2020-06-25 19:44:05"><div class="time">2020-06-25 19:44:05</div></a>
                <div class="msg">
                    <p>Interesting discussion thread on the CameraTraps GitHub titled ‚ÄúAs an ecologist, what are you looking for to extract from camera traps?‚Äù that people might want to comment on/follow!
<a href="https://github.com/microsoft/CameraTraps/issues/176">https://github.com/microsoft/CameraTraps/issues/176</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">GitHub</div>
                            
                            
                                
                                <div class="link-title"><a href="https://github.com/microsoft/CameraTraps/issues/176">[building a potential Edge AI solution] As an ecologist, what are you looking for to extract from camera traps? ¬∑ Issue #176 ¬∑ microsoft/CameraTraps</a></div>
                                <div class="link-text">
                                    Hey all, Not sure if it falls under an issue (I&amp;amp;#39;m happy to post or x-post it somewhere more suitable). This repo may be the best place to ask some questions about what&amp;amp;#39;s needed to be integr...
                                </div>
                                
                                
    
        <a href="https://github.com/microsoft/CameraTraps/issues/176">
            <img class="preview" src="https://repository-images.githubusercontent.com/152634113/a8368e00-68f3-11e9-8ba4-db76ce12417c"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://github.com/microsoft/CameraTraps/issues/176</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üòç Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëç Carly Batist, »òtefan Istrate
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-10 14:37:02">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-07-10 14:37:02"><div class="time">2020-07-10 14:37:02</div></a>
                <div class="msg">
                    <p>Hey all, any public camera trap datasets with segmentation labels that anyone knows of?  I've been looking but haven't found anything useful.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Jon Van Oast
                        </div>
                    
                        <div class="message-reaction">
                        üëç Mikey Tabak
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-14 13:02:24">
            
                <img src="https://secure.gravatar.com/avatar/4391c54952e1c48b6e9f3077946818bc.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0006-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Oisin Mac Aodha
                     <span class="print-only user-email">(macaodha@caltech.edu)</span>
                </div>
                <a href="#2020-07-14 13:02:24"><div class="time">2020-07-14 13:02:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Not that I'm aware of. Maybe the animal categories in openimages might be useful? <a href="https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&amp;type=segmentation&amp;r=false&amp;c=%2Fm%2F01dws">https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&amp;type=segmentation&amp;r=false&amp;c=%2Fm%2F01dws</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-14 13:11:32">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-07-14 13:11:32"><div class="time">2020-07-14 13:11:32</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yeah, maybe I can bootstrap something from these üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-23 15:37:43">
            
                <img src="https://secure.gravatar.com/avatar/fad8243912668a0add63704d16e4c44f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Subhransu Maji
                     <span class="print-only user-email">(smaji@cs.umass.edu)</span>
                </div>
                <a href="#2020-07-23 15:37:43"><div class="time">2020-07-23 15:37:43</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Perhaps, some of the old-school background modeling approaches could be used to extract masks?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-23 15:42:34">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-07-23 15:42:34"><div class="time">2020-07-23 15:42:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* This was actually the subject of my first ever paper back in undergrad (<a href="https://ieeexplore.ieee.org/abstract/document/7532575">https://ieeexplore.ieee.org/abstract/document/7532575</a>). Because the frame rate is really low (no greater than one frame per second), because the background plants can also move, and because sometimes the animals don't move, the masks aren't great. I think it's reasonable to use as weak supervision, but I was hoping that someone had already gathered labels to accurately evaluate methods against. Looks like I'm going to need to label some data, at least for eval :)</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">ieeexplore.ieee.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://ieeexplore.ieee.org/abstract/document/7532575">Finding areas of motion in camera trap images - IEEE Conference Publication</a></div>
                                <div class="link-text">
                                    IEEE Xplore, delivering full text access to the world&#39;s highest quality technical literature in engineering and technology. | IEEE Xplore
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://ieeexplore.ieee.org/abstract/document/7532575</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üî• Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-23 15:47:13">
            
                <img src="https://secure.gravatar.com/avatar/fad8243912668a0add63704d16e4c44f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Subhransu Maji
                     <span class="print-only user-email">(smaji@cs.umass.edu)</span>
                </div>
                <a href="#2020-07-23 15:47:13"><div class="time">2020-07-23 15:47:13</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I see. Might be an interesting research topic to use all the sequence data + bounding box to learn a camera specific background prior and then do use something like GrabCut to extract the segmentation.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-23 15:53:06">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-07-23 15:53:06"><div class="time">2020-07-23 15:53:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yeah, that sounds like a great idea. I'm mentoring an incoming PhD student of Pietro's (Laure Delisle) and she's looking at weakly-supervised segmentation for camera traps. We were thinking of seeing if we can adapt the attention-based approach that worked well for detection, but we're in really early stages. Would you have time to meet up and brainstorm with us sometime?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-23 15:53:53">
            
                <img src="https://secure.gravatar.com/avatar/fad8243912668a0add63704d16e4c44f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Subhransu Maji
                     <span class="print-only user-email">(smaji@cs.umass.edu)</span>
                </div>
                <a href="#2020-07-23 15:53:53"><div class="time">2020-07-23 15:53:53</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yeah, happy to!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-23 15:54:36">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-07-23 15:54:36"><div class="time">2020-07-23 15:54:36</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Cool!  She's on vacation this week in Corsica (which I'm very jealous of lol) but I'll chat with her when she gets back and we can find a time to meet üôÇ</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Subhransu Maji
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-23 15:20:44">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-07-23 15:20:44"><div class="time">2020-07-23 15:20:44</div></a>
                <div class="msg">
                    <p>Is anyone working on open source camera trap hardware?</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ùï Ben Seleb
                        </div>
                    
                        <div class="message-reaction">
                        üôå Mike C
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-23 15:27:57">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-07-23 15:27:57"><div class="time">2020-07-23 15:27:57</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Ben Seleb wants to work on this for his PhD!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üòé Jon Van Oast, Ben Seleb
                        </div>
                    
                        <div class="message-reaction">
                        üëç Ed Miller
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-23 16:17:37">
            
                <img src="https://secure.gravatar.com/avatar/89cbe0fc12b2cc92d129f14b0a5f665e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mathias Tobler
                     <span class="print-only user-email">(matobler@gmx.net)</span>
                </div>
                <a href="#2020-07-23 16:17:37"><div class="time">2020-07-23 16:17:37</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Conservation X-Labs has an open challenge:
<a href="https://conservationx.com/challenge/cameratrap/camera">https://conservationx.com/challenge/cameratrap/camera</a></p>

<p>The issue is cost and scale. It would be great to have an open-source camera trap that allows for customized software, but you need to work out manufacturing at scale to make it work for researchers. Most researchers just want a camera that works and don't want to assemble, program etc. their camera before deployment. If I need 100 new camera traps three weeks from now that are ready to deploy for a project that just got funded, can you have a company manufacture and deliver them for &lt;$150 including hardware and housing?</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">conservationx.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://conservationx.com/challenge/cameratrap/camera">Camera Trap 3.0</a></div>
                                <div class="link-text">
                                    Conservation X - a site for great ideas, and exponential answers to environmental problems.
                                </div>
                                
                                
    
        <a href="https://conservationx.com/challenge/cameratrap/camera">
            <img class="preview" src="https://conservationx.com/ui/all/cxl-logo-fb-600.jpg"
                width="476"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://conservationx.com/challenge/cameratrap/camera</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üòé Ed Miller
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-23 20:42:04">
            
                <img src="https://avatars.slack-edge.com/2020-07-23/1253512304358_d7a08d75ee1614a9ddac_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Seleb
                     <span class="print-only user-email">(bseleb3@gatech.edu)</span>
                </div>
                <a href="#2020-07-23 20:42:04"><div class="time">2020-07-23 20:42:04</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Currently trying to lay the ground work for this ‚Äî happy to discuss! </p>
                    
                    
                    
                        <div class="message-reaction">
                        üòé Ed Miller, Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëÄ Mike C
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-24 13:05:58">
            
                <img src="https://avatars.slack-edge.com/2019-11-13/833083458820_6e297a02aaf872c8c18f_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Nathaniel Rindlaub
                     <span class="print-only user-email">(nathaniel.rindlaub@tnc.org)</span>
                </div>
                <a href="#2020-07-24 13:05:58"><div class="time">2020-07-24 13:05:58</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hey @Ben Seleb - I'm also interest in learning about what you're up to. I work for the Nature Conservancy and we're very interested in trying out modular, open-source camera trapping hardware.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ Mike C
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-29 13:19:31">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-07-29 13:19:31"><div class="time">2020-07-29 13:19:31</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Mathias Tobler Thanks for the link to the Camera Trap challenge. I agree cost and scale are always an issue, but so is fit for purpose. <a href="https://www.openacousticdevices.info/">AudioMoth</a> is a good example of a working open source hardware model. Custom software doesn't have to be the primary focus, it should just work out of the box for a core set of applications.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">openacousticdevices</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.openacousticdevices.info/">AudioMoth | Open Acoustic Devices</a></div>
                                <div class="link-text">
                                    Home for all information on AudioMoth, a low-cost, open-source acoustic monitoring device.
                                </div>
                                
                                
    
        <a href="https://www.openacousticdevices.info/">
            <img class="preview" src="https://static.wixstatic.com/media/b31671_0d3274ff32ac4e5bb7d42d2f173a0288%7Emv2_d_1466_1222_s_2.png/v1/fit/w_2500,h_1330,al_c/b31671_0d3274ff32ac4e5bb7d42d2f173a0288%7Emv2_d_1466_1222_s_2.png"
                width="300"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.openacousticdevices.info/</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-29 13:21:27">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-07-29 13:21:27"><div class="time">2020-07-29 13:21:27</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Ben Seleb I would definitely like to discuss this with you!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-28 14:14:51">
            
                <img src="https://avatars.slack-edge.com/2020-08-29/1354144022224_b8b2d9812a1ffe243e39_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mike C
                     <span class="print-only user-email">(mike@mikecee.solutions)</span>
                </div>
                <a href="#2020-08-28 14:14:51"><div class="time">2020-08-28 14:14:51</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Nathaniel Rindlaub @Ben Seleb - we make Open Source marine camera traps.  <a href="http://openoceancam.com/">http://openoceancam.com/</a></p>

<p>Would be cool to chat!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Open Ocean Camera (OOCAM)</div>
                            
                            
                                
                                <div class="link-title"><a href="http://openoceancam.com/">Open Ocean Camera (OOCAM): Underwater Research Camera</a></div>
                                <div class="link-text">
                                    The Open Ocean Camera or OOCAM is a modern &amp;amp; open-source underwater camera ideal for marine ocean research and AI powered post-processing!
                                </div>
                                
                                
    
        <a href="http://openoceancam.com/">
            <img class="preview" src="https://openoceancam.com/wp-content/uploads/2020/06/Pink-Cute-Chic-Vintage-90s-Virtual-Trivia-Quiz-Presentations-6-1024x576.png"
                width="444"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://openoceancam.com/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-11-23 04:11:35">
            
                <img src="https://avatars.slack-edge.com/2020-11-16/1528366916016_18d9a2232c813e507027_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Maxime Cauchoix
                     <span class="print-only user-email">(mcauchoixxx@gmail.com)</span>
                </div>
                <a href="#2020-11-23 04:11:35"><div class="time">2020-11-23 04:11:35</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Ed Miller we have projects like that too. happy to chat!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-13 12:30:52">
            
                <img src="https://avatars.slack-edge.com/2020-08-29/1354144022224_b8b2d9812a1ffe243e39_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mike C
                     <span class="print-only user-email">(mike@mikecee.solutions)</span>
                </div>
                <a href="#2021-08-13 12:30:52"><div class="time">2021-08-13 12:30:52</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Maxime Cauchoix would love to check yours out. Any link?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-27 14:44:17">
            
                <img src="https://secure.gravatar.com/avatar/8044a6e062630031e71a86e15c13c2ab.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Saket Anand
                     <span class="print-only user-email">(anands@iiitd.ac.in)</span>
                </div>
                <a href="#2020-07-27 14:44:17"><div class="time">2020-07-27 14:44:17</div></a>
                <div class="msg">
                    <p>This may be of interest:
<a href="https://www.guinnessworldrecords.com/world-records/601784-largest-camera-trap-wildlife-survey">https://www.guinnessworldrecords.com/world-records/601784-largest-camera-trap-wildlife-survey</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Guinness World Records</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.guinnessworldrecords.com/world-records/601784-largest-camera-trap-wildlife-survey">Largest camera-trap wildlife survey</a></div>
                                <div class="link-text">
                                    The Guinness World Records Official site with ultimate record-breaking facts &amp;amp; achievements. Do you want to set a world record? Are you Officially Amazing?
                                </div>
                                
                                
    
        <a href="https://www.guinnessworldrecords.com/world-records/601784-largest-camera-trap-wildlife-survey">
            <img class="preview" src="http://www.guinnessworldrecords.com/assets/2471566"
                width="392"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.guinnessworldrecords.com/world-records/601784-largest-camera-trap-wildlife-survey</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêÖ Siyu Yang, Mathias Tobler, David Healey, Manish Rai
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-27 16:18:59">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/723921280647_3ee3dea8f62871f8a715_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Siyu Yang
                     <span class="print-only user-email">(yasiyu@microsoft.com)</span>
                </div>
                <a href="#2020-07-27 16:18:59"><div class="time">2020-07-27 16:18:59</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* WII has contributed training data to the MegaDetector training data set too!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-27 16:36:08">
            
                <img src="https://secure.gravatar.com/avatar/98123d6f2f764d0f5ddad33ce51efc56.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Bistra Dilkina
                     <span class="print-only user-email">(dilkina@usc.edu)</span>
                </div>
                <a href="#2020-07-27 16:36:08"><div class="time">2020-07-27 16:36:08</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* that is awesome, Saket! well done!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-07-29 07:23:44">
            
                <img src="https://secure.gravatar.com/avatar/8044a6e062630031e71a86e15c13c2ab.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Saket Anand
                     <span class="print-only user-email">(anands@iiitd.ac.in)</span>
                </div>
                <a href="#2020-07-29 07:23:44"><div class="time">2020-07-29 07:23:44</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks Bistra! The credit really goes to WII to pull it off. I'm excited to be involved though üôÇ.
@Siyu Yang That's wonderful! Thanks for this information. I didn't know that.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-01 21:13:42">
            
                <img src="https://avatars.slack-edge.com/2020-07-01/1218123595618_770912a6d4b23b6f88b2_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Bob Zak
                     <span class="print-only user-email">(robert.zak@comcast.net)</span>
                </div>
                <a href="#2020-08-01 21:13:42"><div class="time">2020-08-01 21:13:42</div></a>
                <div class="msg">
                    <p>Is anyone working on or thought about a "smart PIR" sensor.  Something more subtle than threshold detection from bandpass filtered PIR signal (possibly involving co-designed optics) aimed at reducing false negatives (missed animals) , and false positives (waving vegetation)?   My thought (for my own education) was to start "small" -- yet as I think about the whole process -- from gathering training data, to testing in real life vs. state of the art, this problem begets a number of smaller (also challenging) steps üòï üôÇ   @Sam Kelly @Sara Beery @Ed Miller</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-01 21:17:13">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-08-01 21:17:13"><div class="time">2020-08-01 21:17:13</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* It sounds really interesting, but I haven't done anything with PIR.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-02 21:06:09">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-08-02 21:06:09"><div class="time">2020-08-02 21:06:09</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I did some experimentation with using a PIR sensor as a human detector for a wearable camera. It ended up not being a good solution for a device that is not in a fixed location. I never got to the point of "smart PIR". I suggest you start with a platform like <a href="https://www.edgeimpulse.com/">Edge Impulse</a> which makes it easy to experiment with various ML models for sensors (Dan Situnayaki from Edge Impulse did a <a href="https://www.youtube.com/watch?v=DhHw17Z-lvI">Tech Tutors talk on WildLabs</a>). If you search for "tinyml pir" you can also find some interesting references.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-03 07:09:13">
            
                <img src="https://avatars.slack-edge.com/2020-07-01/1218123595618_770912a6d4b23b6f88b2_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Bob Zak
                     <span class="print-only user-email">(robert.zak@comcast.net)</span>
                </div>
                <a href="#2020-08-03 07:09:13"><div class="time">2020-08-03 07:09:13</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks for these pointers.   I will definitely check these out!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-03 10:39:41">
            
                <img src="https://avatars.slack-edge.com/2020-08-03/1284586180260_ce5ba282733f34b0aeba_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sam Kelly
                     <span class="print-only user-email">(sam@conservationxlabs.org)</span>
                </div>
                <a href="#2020-08-03 10:39:41"><div class="time">2020-08-03 10:39:41</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* one of the things we looked at a while back was background subtraction from one of these low-power, always-on cameras (and one of these <a href="https://www.adafruit.com/product/4469">https://www.adafruit.com/product/4469</a>) - @Vivian Shen did most of this work. it had mixed results, but many of the problems that face PIRs (false positives, range etc.) were still an issue. Could definitely be something interesting here though... and happy to help out with anything on this!!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-03 13:35:26">
            
                <img src="https://avatars.slack-edge.com/2020-07-01/1218123595618_770912a6d4b23b6f88b2_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Bob Zak
                     <span class="print-only user-email">(robert.zak@comcast.net)</span>
                </div>
                <a href="#2020-08-03 13:35:26"><div class="time">2020-08-03 13:35:26</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* cool.  I had looked at the lower resolution 8x8 panasonic GridEye part (adafruit AMG8833).  Even without the post processing, the power consumption (4 mA typical ** 3 volt = 12 mW) was an issue.  As one one expect, the higher resolution Melexis part is even "hotter" -- something like 60 mW  @Vivian Shen how did you evaluate the performance (accuracy) of MLX90640 solution?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-04 09:20:15">
            
                <img src="https://avatars.slack-edge.com/2020-08-03/1284586180260_ce5ba282733f34b0aeba_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sam Kelly
                     <span class="print-only user-email">(sam@conservationxlabs.org)</span>
                </div>
                <a href="#2020-08-04 09:20:15"><div class="time">2020-08-04 09:20:15</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Bob Zak actually sorry I think it actually may have been the grideye. </p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-11-07 20:57:17">
            
                <img src="https://avatars.slack-edge.com/2020-07-01/1218123595618_770912a6d4b23b6f88b2_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Bob Zak
                     <span class="print-only user-email">(robert.zak@comcast.net)</span>
                </div>
                <a href="#2020-11-07 20:57:17"><div class="time">2020-11-07 20:57:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sam Kelly Just found a newer IR sensor coupled with an ULP AI inference chip. See: <a href="https://greenwaves-technologies.com/thermal-ir-based-gappoc-b-board-for-people-detection-and-counting/">https://greenwaves-technologies.com/thermal-ir-based-gappoc-b-board-for-people-detection-and-counting/</a> Development board includes 80x80 IR sensor.  Unfortunately, I still think this about 10x the power it needs to be (when operated continously, vs. every 10's of seconds in human counting application). I am making slow progress on an AI inference backend for the standard two (or 4 element) PIR sensor aimed at reducing number of missed animals.  Taking a long time to put together a methodology and tools to generate training data and compare to current state of art (which does seem to be improving)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-28 14:19:01">
            
                <img src="https://avatars.slack-edge.com/2020-08-29/1354144022224_b8b2d9812a1ffe243e39_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Mike C
                     <span class="print-only user-email">(mike@mikecee.solutions)</span>
                </div>
                <a href="#2020-08-28 14:19:01"><div class="time">2020-08-28 14:19:01</div></a>
                <div class="msg">
                    <p>Thanks for the add @Sara Beery!
Excited to be part of the community. We are a multifield STEM team from The University of Hong Kong working on a <strong>marine camtrap with autosorting</strong> 
<a href="https://openoceancam.com/software/">https://openoceancam.com/software/</a>
<a href="https://openoceancam.com/hardware/">https://openoceancam.com/hardware/</a></p>

<p>Would love to learn from you all and collaborate! Let‚Äôs save the world :i<em>love</em>you<em>hand</em>sign::skin<em>tone</em>2:</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Open Ocean Camera (OOCAM)</div>
                            
                            
                                
                                <div class="link-title"><a href="https://openoceancam.com/software/">Software - Open Ocean Camera (OOCAM)</a></div>
                                <div class="link-text">
                                    EasyAI The EasyAI interface is built to simplify and accelerate the difficult task of post-processing of images &amp;amp; videos. Users can simply upload the footage recorded on our interface and our AI returns the images/videos classified by marine species.¬† Hundreds of hours of manual post-processing of footage can now be completed in just few hours [‚Ä¶]
                                </div>
                                
                                
    
        <a href="https://openoceancam.com/software/">
            <img class="preview" src="https://openoceancam.com/wp-content/uploads/2020/06/image-1-943x1024.png"
                width="230"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://openoceancam.com/software/</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Open Ocean Camera (OOCAM)</div>
                            
                            
                                
                                <div class="link-title"><a href="https://openoceancam.com/hardware/">Hardware - Open Ocean Camera (OOCAM)</a></div>
                                <div class="link-text">
                                    OOCAM Hardware Battery Battery Combined Battery 222 Wh Basic Battery Pack 12 Days Battery Life Rechargeable Interchangeable Extra Battery (222Wh ~ 12 days) OOCAM supports upto 2 Battery Packs Camera Camera 12.3 MP | 1080p Video Sony IMX129 Sensor Max Photo Resolution ‚Äì 3280√ó2464 Video Resolution Options ‚Äì 1080p30 | 720p60 | 640x480p90 Adjustable ISO, [‚Ä¶]
                                </div>
                                
                                
    
        <a href="https://openoceancam.com/hardware/">
            <img class="preview" src="https://openoceancam.com/wp-content/uploads/2020/08/WhatsApp-Image-2020-08-26-at-10.04.32-PM-150x150.jpeg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://openoceancam.com/hardware/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëã Oisin Mac Aodha
                        </div>
                    
                        <div class="message-reaction">
                        üëç Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-28 17:35:24">
            
                <img src="https://avatars.slack-edge.com/2023-05-21/5283978847047_6dfe29e62ff090fa3306_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Jon Van Oast
                     <span class="print-only user-email">(jon@wildme.org)</span>
                </div>
                <a href="#2020-08-28 17:35:24"><div class="time">2020-08-28 17:35:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* thanks for sharing this!  very cool hardware/software combination you have going on here.   i have shared it with our team at <strong>wild me</strong> ... we work with lamave via <a href="http://whaleshark.org">whaleshark.org</a> and <a href="http://mantamatcher.org">mantamatcher.org</a>, etc.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-29 00:45:26">
            
                <img src="https://avatars.slack-edge.com/2020-08-29/1354144022224_b8b2d9812a1ffe243e39_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mike C
                     <span class="print-only user-email">(mike@mikecee.solutions)</span>
                </div>
                <a href="#2020-08-29 00:45:26"><div class="time">2020-08-29 00:45:26</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Jon Van Oast awesome! We‚Äôve deployed a cam with LAMAVE in the Bohol Strait and are cooking up more deployment plans with Alessandro.</p>

<p>Actually, it would if OOCAM Founder Sidhant and I could jump on the phone with you to chat hardware. We want to know what people with wealth of field experience  like you are currently using!</p>

<p><tel:+85294413850|+852 94413850> Whatsapp
<a href="mailto:mike@mikecee.solutions">mike@mikecee.solutions</a> email üôè:skin<em>tone</em>2:</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-28 15:15:51">
            
                <img src="https://secure.gravatar.com/avatar/89cbe0fc12b2cc92d129f14b0a5f665e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Mathias Tobler
                     <span class="print-only user-email">(matobler@gmx.net)</span>
                </div>
                <a href="#2020-08-28 15:15:51"><div class="time">2020-08-28 15:15:51</div></a>
                <div class="msg">
                    <p>Hi everyone, I am about to start training several new models to classify our camera trap data and wanted to run a few questions about some details by the community for input. I am training in Keras and I am using MegaDetector to first crop out individual animals and use the crops to train the species classification model. I use models pre-trained on the ImageNet data and use transfer learning to train on our data. First, I keep the base layers (pre-trained model) frozen and only train the top layers, after a while I unfreeze the whole model and keep training. Here the specific questions:</p>

<p>‚Ä¢ Most examples I have seen add a new Dense layer before the final Softmax layer. In my case I use a dense layer with 1024 units, but I am not sure if this is a) needed or b) how many units are best in my case (we have about 50 classes in our model).
‚Ä¢ What is the best training strategy for this? Currently for the fixed step I am using a SGD optimizer with lr = 1e-2, momentum = 0.9, decay = 1e-4, after unfreezing I change to lr = 1e-4, momentum = 0.9, decay = 1e-6. Anything that would be more efficient? Speed is not of concern here, accuracy is priority.
‚Ä¢ I am currently using InceptionV3, InceptionResNetV2 and Xception (with comparable results). I just noticed that there are several new pre-trained models now included with Keras; DenseNet, NASNet and EfficientNet. While I will likely use an ensemble model strategy for the final classification pipeline, I would still like to keep the number of models to 3-4. Any suggestion which models might perform best for this task?</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚≠ê Rose Zhao, Mike C, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-29 00:42:47">
            
                <img src="https://avatars.slack-edge.com/2020-08-29/1354144022224_b8b2d9812a1ffe243e39_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mike C
                     <span class="print-only user-email">(mike@mikecee.solutions)</span>
                </div>
                <a href="#2020-08-29 00:42:47"><div class="time">2020-08-29 00:42:47</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Mathias Tobler perhaps the guys at <a href="https://medium.com/konvergen">https://medium.com/konvergen</a> might be able to chip in advice. If not, they should be able to put you in touch with someone with practical experience</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Medium</div>
                            
                            
                                
                                <div class="link-title"><a href="https://medium.com/konvergen">Konvergen.AI ‚Äì Medium</a></div>
                                <div class="link-text">
                                    The sharing platform of &lt;a href=&#34;http://Konvergen.ai&#34;&gt;Konvergen.ai&lt;/a&gt;. Visit our homepage at &lt;https://konvergen.ai&gt;.
                                </div>
                                
                                
    
        <a href="https://medium.com/konvergen">
            <img class="preview" src="https://cdn-images-1.medium.com/max/1200/1*vrjHijRIhBrg_YWYt5JsoQ.png"
                width="250"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://medium.com/konvergen</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-29 15:06:15">
            
                <img src="https://avatars.slack-edge.com/2019-08-26/727564533250_4bda977d3f85f4f6fc06_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Amrita Gupta
                     <span class="print-only user-email">(agupta375@gatech.edu)</span>
                </div>
                <a href="#2020-08-29 15:06:15"><div class="time">2020-08-29 15:06:15</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Regarding how many units to use in your final layer, I think that would depend on how distinctive the 50 classes you have are. e.g. imagine if your dataset had only 2 classes, say automobiles and deer from CIFAR10. Samples from those classes could most likely be condensed down to 2d embeddings for the purpose of classification. The more visually similar/complex the classes, the more features might be needed to distinguish between them. If you're getting good performance with 1024 final-layer features, you could reduce it and see if the test set performance falls (indicating you maybe do want to use a larger dense layer to learn enough features), improves (you might have been overfitting the feature extractor to the train set), or doesn't change?</p>
                    
                    
                    
                        <div class="message-reaction">
                        :i_love_you_hand_sign: Sara Beery, Mike C
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-04 14:34:50">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-09-04 14:34:50"><div class="time">2020-09-04 14:34:50</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I've seen really nice results recently with EfficientNet, as to learning rate my go-to starting point is a 2K step warm-up from 0 to my initial learning rate, which is usually best around 0.002 or 0.004, then drop the learning rate by 10x after one-two epochs (I do this manually, once the model appears to have converged at the first learning rate) I don't freeze any part of the network during training, I haven't found it to make a difference.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-04 14:36:08">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-09-04 14:36:08"><div class="time">2020-09-04 14:36:08</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Then I'll do a bit of a sweep over initial learning rates, going up and down by factors of 2, to make sure that I'm not missing something</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-04 14:37:02">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-09-04 14:37:02"><div class="time">2020-09-04 14:37:02</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Once I've got a good set of parameters for this dataset and a good idea of convergence time, I'll switch to a cosine learning rate which usually will give a bit of a boost.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-18 01:50:48">
            
                <img src="https://secure.gravatar.com/avatar/89cbe0fc12b2cc92d129f14b0a5f665e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mathias Tobler
                     <span class="print-only user-email">(matobler@gmx.net)</span>
                </div>
                <a href="#2020-09-18 01:50:48"><div class="time">2020-09-18 01:50:48</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sara Beery thanks for the input! I just saw your comments now, but it's good timing. I finished updating my code to use EfficientNet, started some first training runs yesterday but I am still playing around with learning rates. Will try your suggestions. What optimizer are you using?</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚≠ê Mike C
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-02-26 10:58:53">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-02-26 10:58:53"><div class="time">2021-02-26 10:58:53</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Just saw this, sorry!! Adam, usually, but I tend to go with what the original code for that architecture used so sometimes I use SGD. In my experience SGD can be a little more sensitive to hyperparameters.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-04 07:55:43">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2020-09-04 07:55:43"><div class="time">2020-09-04 07:55:43</div></a>
                <div class="msg">
                    <p>New camera trap data set on LILA, thanks to Island Conservation.  This includes ~65k bounding boxes, and represents island ecosystems we haven't had on LILA before:</p>

<p><a href="http://lila.science/datasets/island-conservation-camera-traps/">http://lila.science/datasets/island-conservation-camera-traps/</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üòç Sara Beery, Amrita Gupta, Zac Winzurk, Sam Kelly, Mike C
                        </div>
                    
                        <div class="message-reaction">
                        üèùÔ∏è Sara Beery, Carly Batist, Amrita Gupta, Zac Winzurk, Ed Miller, Siyu Yang
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-04 11:41:29">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2020-09-04 11:41:29"><div class="time">2020-09-04 11:41:29</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* That's awesome! Curious which islands? The webpage just says 7 from 6 countries</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-04 11:56:17">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2020-09-04 11:56:17"><div class="time">2020-09-04 11:56:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* We obfuscated the specific island names away prior to release at the request of Island Conservation; they are considered sensitive information.  If you have a specific project that would benefit from access to one or more of the specific locations, I would contact David Will (his email is on the dataset page).</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-09-04 11:58:37">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2020-09-04 11:58:37"><div class="time">2020-09-04 11:58:37</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* But it's only the specific islands that were obfuscated; the <em>countries</em> (or regions in some cases) are in the metadata... they are: Ecuador, Chile, Dominican Republic, Puerto Rico, Micronesia, and Palau.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Carly Batist
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-02-15 14:09:22">
            
                <img src="https://avatars.slack-edge.com/2022-11-07/4325264017430_1d69dc73e8586441b2af_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Omiros Pantazis
                     <span class="print-only user-email">(omiros.pantazis.16@ucl.ac.uk)</span>
                </div>
                <a href="#2021-02-15 14:09:22"><div class="time">2021-02-15 14:09:22</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hey @Dan Morris, do you know whether a location id (not specific lat/lon coordinates need)  and datetime are available anywhere? They do not seem to be part of the json file as with other camera trap datasets. I sent an email to David as suggested but asking here as well in case you know</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-11-12 09:32:10">
            
                <img src="https://avatars.slack-edge.com/2020-11-09/1494000753348_3e6fa01875308342d9ae_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Petar Gyurov
                     <span class="print-only user-email">(pgyurov93@gmail.com)</span>
                </div>
                <a href="#2020-11-12 09:32:10"><div class="time">2020-11-12 09:32:10</div></a>
                <div class="msg">
                    <p>Hey everyone. I'm putting together a comparison table of camera trap software/code that aids with detection and classification. Feedback, corrections and suggestions are appreciated üëç
<a href="https://www.notion.so/pgyurov/Solution-Comparison-2eac80825c4941b0b2b5fad3daea1cc3">https://www.notion.so/pgyurov/Solution-Comparison-2eac80825c4941b0b2b5fad3daea1cc3</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Petar&#39;s Notion on Notion</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.notion.so/pgyurov/Solution-Comparison-2eac80825c4941b0b2b5fad3daea1cc3">Solution Comparison</a></div>
                                <div class="link-text">
                                    A new tool for teams &amp;amp; individuals that blends everyday work apps into one.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://www.notion.so/pgyurov/Solution-Comparison-2eac80825c4941b0b2b5fad3daea1cc3</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üòÉ Carly Batist, Sara Beery, Mikey Tabak
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-11-12 10:36:15">
            
                <img src="https://secure.gravatar.com/avatar/e580d2cbeb30d149ef50bc735767289f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0025-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Matt Hron
                     <span class="print-only user-email">(matt.hron@wildlifeprotectionsolutions.org)</span>
                </div>
                <a href="#2020-11-12 10:36:15"><div class="time">2020-11-12 10:36:15</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Peter. You can add wpsWatch (<a href="https://wildlifeprotectionsolutions.org/wpswatch/">https://wildlifeprotectionsolutions.org/wpswatch/</a>) to the list. It's a web platform for managing connected camera traps and associated data, and it uses Megadetector, a model hosted by silverpond (<a href="https://silverpond.com.au/2020/08/14/wps-model-optimization-a-case-study/">https://silverpond.com.au/2020/08/14/wps-model-optimization-a-case-study/</a>), and additional AI integrations coming soon. I'd be happy to answer any questions you have about it.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">wildlifeprotectionsolutions.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://wildlifeprotectionsolutions.org/wpswatch/">wpsWatch | Wildlife Protection Solutions</a></div>
                                <div class="link-text">
                                    MONITORING WILDLIFE AND DETECTING THREATS IN REAL TIME wpsWatch is our core mobile and desktop app solution for fighting wildlife crime in real time. Using a suite of custom camera traps, sensors, and software, we‚Äôve developed a system¬†capable of providing 24/7 monitoring for any given conservat ...
                                </div>
                                
                                
    
        <a href="https://wildlifeprotectionsolutions.org/wpswatch/">
            <img class="preview" src="https://wildlifeprotectionsolutions.org/wp-content/uploads/2019/07/wpsWatch-featured-image.jpg"
                width="540"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://wildlifeprotectionsolutions.org/wpswatch/</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Silverpond</div>
                            
                            
                                
                                <div class="link-title"><a href="https://silverpond.com.au/2020/08/14/wps-model-optimization-a-case-study/">WPS model optimization, a case study - Silverpond</a></div>
                                <div class="link-text">
                                    Report by Bhavesh Sharma. WPS and Silverpond‚Äôs HighLighter Wildlife Protection Solutions (WPS) is a non-profit organisation that provides solutions for [‚Ä¶]
                                </div>
                                
                                
    
        <a href="https://silverpond.com.au/2020/08/14/wps-model-optimization-a-case-study/">
            <img class="preview" src="https://silverpond.com.au/wp-content/uploads/2020/04/wps2-scaled.jpg"
                width="535"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://silverpond.com.au/2020/08/14/wps-model-optimization-a-case-study/</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-11-12 10:42:28">
            
                <img src="https://avatars.slack-edge.com/2020-11-09/1494000753348_3e6fa01875308342d9ae_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Petar Gyurov
                     <span class="print-only user-email">(pgyurov93@gmail.com)</span>
                </div>
                <a href="#2020-11-12 10:42:28"><div class="time">2020-11-12 10:42:28</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Awesome, I will add it to the list. Thanks.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-01-11 17:13:54">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2021-01-11 17:13:54"><div class="time">2021-01-11 17:13:54</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* FYI I try to keep this up to date:</p>

<p><a href="http://aka.ms/cameratrapsurvey">http://aka.ms/cameratrapsurvey</a></p>

<p>Feel free to grab content, and let me know what I'm missing!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Camera Trap ML Survey</div>
                            
                            
                                
                                <div class="link-title"><a href="http://aka.ms/cameratrapsurvey">Overview</a></div>
                                <div class="link-text">
                                    Everything I know about machine learning and camera traps.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: http://aka.ms/cameratrapsurvey</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Petar Gyurov
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-02-17 13:45:25">
            
                <img src="https://secure.gravatar.com/avatar/e3deec60e08a24805b3952a4248d0ad5.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0004-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Greg Lipstein
                     <span class="print-only user-email">(greg@drivendata.org)</span>
                </div>
                <a href="#2021-02-17 13:45:25"><div class="time">2021-02-17 13:45:25</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Petar Gyurov just seeing this, seems like a great list. Here's an addition if you're including camera trap videos (also mentioned in Dan's list above): <a href="https://zamba.drivendata.org/">Zamba</a> is the open source python project, <a href="https://www.zambacloud.com/">ZambaCloud</a> is the web application built on top that handles execution on the cloud. Will be doing a round of additional development in the next six months, e.g. to facilitate retraining</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">zamba.drivendata.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://zamba.drivendata.org/">Project Zamba: Computer Vision for Wildlife Research and Conservation</a></div>
                                <div class="link-text">
                                    Project Zamba is an open source software tool that uses machine learning to identify wildlife from camera trap footage.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://zamba.drivendata.org/</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-02-17 14:25:03">
            
                <img src="https://avatars.slack-edge.com/2020-11-09/1494000753348_3e6fa01875308342d9ae_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Petar Gyurov
                     <span class="print-only user-email">(pgyurov93@gmail.com)</span>
                </div>
                <a href="#2021-02-17 14:25:03"><div class="time">2021-02-17 14:25:03</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks @Greg Lipstein, I will add it to the list üëç</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-01-11 17:14:58">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2021-01-11 17:14:58"><div class="time">2021-01-11 17:14:58</div></a>
                <div class="msg">
                    <p>New camera trap data set on LILA, courtesy of The Nature Conservancy:</p>

<p><a href="http://lila.science/datasets/channel-islands-camera-traps/">http://lila.science/datasets/channel-islands-camera-traps/</a></p>

<p>Includes lots of bounding boxes!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="http://lila.science/datasets/channel-islands-camera-traps/">Channel Islands Camera Traps - LILA BC</a></div>
                                <div class="link-text">
                                    Overview This data set contains 246,529 camera trap images from 73 camera locations in the Channel Islands, California. All animals are annotated with bounding boxes. Data were provided by The Nature Conservancy. Animals are classified as rodent1 (82914), fox (48150), bird (11099), skunk (1071), or other (159). 114,949 images (47%) are empty. 1All images of...
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Written by</div>
                                        lilawp
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Est. reading time</div>
                                        1 minute
                                    </div>
                                
                                
    
        <a href="http://lila.science/datasets/channel-islands-camera-traps/">
            <img class="preview" src="http://lila.science/wp-content/uploads/2020/12/channel-islands-thumb.jpg"
                width="333"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://lila.science/datasets/channel-islands-camera-traps/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üòç Sara Beery, Oisin Mac Aodha, Ben Weinstein, Tony Chang, Olivier Gimenez, Carly Batist, David Will, Jon Van Oast, Mikey Tabak, Ben Seleb
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Nathaniel Rindlaub, Ed Miller, Omiros Pantazis
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-01-28 10:44:21">
            
                <img src="https://avatars.slack-edge.com/2022-06-17/3696311190401_ec55743de740f4e5c7c2_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Thijs
                     <span class="print-only user-email">(thijs@q42.nl)</span>
                </div>
                <a href="#2021-01-28 10:44:21"><div class="time">2021-01-28 10:44:21</div></a>
                <div class="msg">
                    <p>We are busy training a model for WWF Myanmar, sadly they don't have too much data available, so I'm looking for ways to combine datasets. The main thing that makes Myanmar different¬†is that they use¬†canopy level camera traps, so the angle is different from the datasets we currently have.</p>

<p>Does anyone know if there are CT datasets with humans taken from canopy level? We are mainly focussing on detecting Humans.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-01-28 10:45:26">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-01-28 10:45:26"><div class="time">2021-01-28 10:45:26</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris @Siyu Yang I know we talked about canopy data at one point. Are any of the datasets on LILA captured from a similar angle?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-01-28 11:29:38">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2021-01-28 11:29:38"><div class="time">2021-01-28 11:29:38</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Unfortunately no, but the camera angle question may be moot, since I'm not aware of any public datasets with any humans in them at all. :(</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-02-08 12:26:03">
            
                <img src="https://avatars.slack-edge.com/2020-11-09/1494000753348_3e6fa01875308342d9ae_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Petar Gyurov
                     <span class="print-only user-email">(pgyurov93@gmail.com)</span>
                </div>
                <a href="#2021-02-08 12:26:03"><div class="time">2021-02-08 12:26:03</div></a>
                <div class="msg">
                    <p>Version 0.0.1 of <strong><a href="https://github.com/petargyurov/megadetector-gui">MegaDetector GUI</a></strong> is out üéâ
<strong>A tool to help you quickly sort through empty/not-empty camera trap images.</strong>
<em>(Not officially affiliated with Microsoft/CameraTraps -- this is an open source project based on their work)</em></p>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Ben Weinstein, Olivier Gimenez, Omiros Pantazis, Nathaniel Rindlaub, Carly Batist, Mikey Tabak, Dan Morris, Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üôå Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-03-29 13:04:05">
            
                <img src="https://secure.gravatar.com/avatar/429061336defbfa9e108ab09def29918.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ixchel Meza
                     <span class="print-only user-email">(ixchel.meza.ch@gmail.com)</span>
                </div>
                <a href="#2021-03-29 13:04:05"><div class="time">2021-03-29 13:04:05</div></a>
                <div class="msg">
                    <p>Hi all, üëã:skin<em>tone</em>4: @Sara Beery do you know if there are intentions to pass megadetector to tf 2x? if yes, do you know when? I was trying to do that with keras, but it is a bit tricky‚Ä¶</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-03-29 13:06:00">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-03-29 13:06:00"><div class="time">2021-03-29 13:06:00</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I'd like it to happen too!  I'll bring it up with Dan and Siyu üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-03-29 13:06:34">
            
                <img src="https://secure.gravatar.com/avatar/429061336defbfa9e108ab09def29918.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ixchel Meza
                     <span class="print-only user-email">(ixchel.meza.ch@gmail.com)</span>
                </div>
                <a href="#2021-03-29 13:06:34"><div class="time">2021-03-29 13:06:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* yes please!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-03-29 18:32:02">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2021-03-29 18:32:02"><div class="time">2021-03-29 18:32:02</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yes, we are working on MegaDetector version 5 now, and with extremely high probability, it will be based on TF2.  Still a few months out, though; lots of training data to curate before we get to the model-training part.  But moving along!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üòé Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-03-29 19:16:26">
            
                <img src="https://secure.gravatar.com/avatar/429061336defbfa9e108ab09def29918.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ixchel Meza
                     <span class="print-only user-email">(ixchel.meza.ch@gmail.com)</span>
                </div>
                <a href="#2021-03-29 19:16:26"><div class="time">2021-03-29 19:16:26</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* great! hopefully is tf2x</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-03-29 19:39:39">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2021-03-29 19:39:39"><div class="time">2021-03-29 19:39:39</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I confess that I parsed "tf 2x" in your question as "TF 2.x", when now I realize that I think you intended it as "TFX in TF2.x".  On that I have no comment, since I just learned from this thread that TFX is a thing. :)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-03-29 19:40:54">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-03-29 19:40:54"><div class="time">2021-03-29 19:40:54</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I also thought you meant tf 2.x, which is what I meant üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-03-29 21:06:29">
            
                <img src="https://secure.gravatar.com/avatar/429061336defbfa9e108ab09def29918.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ixchel Meza
                     <span class="print-only user-email">(ixchel.meza.ch@gmail.com)</span>
                </div>
                <a href="#2021-03-29 21:06:29"><div class="time">2021-03-29 21:06:29</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* yes, I meant tf 2.x sorry for the confusion :)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-04-30 21:36:13">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/723921280647_3ee3dea8f62871f8a715_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Siyu Yang
                     <span class="print-only user-email">(yasiyu@microsoft.com)</span>
                </div>
                <a href="#2021-04-30 21:36:13"><div class="time">2021-04-30 21:36:13</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* (Also in case this applies, people tell us that you can load the model in a TF2 environment by using the compatibility package in the import statements - see this issue tensorflow-gpu version ¬∑ Issue #246 ¬∑ microsoft/CameraTraps (<a href="http://github.com">github.com</a><a href="https://github.com/microsoft/CameraTraps/issues/246">)</a> )</p>
                    <div class="message-attachment"
                            style="border-color: #cb2431">
                            
                            
                                <div class="attachment-author">
                                    
                                        <img src="https://avatars.githubusercontent.com/u/39545188?v=4" class="icon">
                                    }
                                    <a href="https://github.com/pbick">
                                    pbick
                                    </a><span class="print-only">(https://github.com/pbick)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href="https://github.com/microsoft/CameraTraps/issues/246">#246 tensorflow-gpu version</a></div>
                                <div class="link-text">
                                    &lt;p&gt;Hello, just a quick question about the supported tensorflow-gpu version. I am having installation issues with version 1.13.1 and was wondering if there is a more recent version that works, or if it must necessarily be 1.13.1. Thanks!&lt;/p&gt;
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Comments</div>
                                        2
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                                    <div class="attachment-footer">
                                        <img src="https://github.githubassets.com/favicon.ico" class="icon" />
                                        &lt;a href=&#34;https://github.com/microsoft/CameraTraps&#34;&gt;microsoft/CameraTraps&lt;/a&gt;
                                    </div>
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëç:skin_tone_4: Ixchel Meza
                        </div>
                    
                        <div class="message-reaction">
                        ‚úÖ Mitch Fennell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-05-01 12:41:41">
            
                <img src="https://secure.gravatar.com/avatar/429061336defbfa9e108ab09def29918.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ixchel Meza
                     <span class="print-only user-email">(ixchel.meza.ch@gmail.com)</span>
                </div>
                <a href="#2021-05-01 12:41:41"><div class="time">2021-05-01 12:41:41</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks I'll give it a try</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-06-16 08:50:17">
            
                <img src="https://avatars.slack-edge.com/2021-07-27/2328648358305_c6f10f351ae5296c3ca1_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Vincent Miele CNRS
                     <span class="print-only user-email">(vincent.miele@univ-lyon1.fr)</span>
                </div>
                <a href="#2021-06-16 08:50:17"><div class="time">2021-06-16 08:50:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi, just one word to mention that we (here in CNRS France, with @Noa Rigoudy) would be very happy to test MegaDetector version 5 when it will be available. Super usefull work @Dan Morris @Sara Beery @Siyu Yang If we can help...</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-07-12 13:23:51">
            
                <img src="https://avatars.slack-edge.com/2021-05-08/2030294018551_55c7e50192aabb4d0794_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">»òtefan Istrate
                     <span class="print-only user-email">(stefan.istrate@gmail.com)</span>
                </div>
                <a href="#2021-07-12 13:23:51"><div class="time">2021-07-12 13:23:51</div></a>
                <div class="msg">
                    <p>Hi all! I was looking over the WCS dataset on lila.science (<a href="http://lila.science/datasets/wcscameratraps">http://lila.science/datasets/wcscameratraps</a>) and I was wondering where the recommended train/val/test splits are coming from. In particular, I'm seeing many camera trap locations not included in any of the 3 splits (e.g. "334", "1211"), but which appear in the annotations. I understand the human images were removed, but those locations are also associated with non-human images. Any idea why the recommended splits don't include all locations? (@Dan Morris? @Sara Beery?) Thanks!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="http://lila.science/datasets/wcscameratraps">WCS Camera Traps - LILA BC</a></div>
                                <div class="link-text">
                                    Overview This data set contains approximately 1.4M camera trap images representing around 675 species from 12 countries, making it one of the most diverse camera trap data sets available publicly. Data were provided by the Wildlife Conservation Society. The most common classes are tayassu pecari (peccary), meleagris ocellata (ocellated turkey), and bos taurus (cattle). A...
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Written by</div>
                                        lilawp
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Est. reading time</div>
                                        1 minute
                                    </div>
                                
                                
    
        <a href="http://lila.science/datasets/wcscameratraps">
            <img class="preview" src="http://lila.science/wp-content/uploads/2019/06/wcs_thumbnail.jpg"
                width="333"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://lila.science/datasets/wcscameratraps</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-07-12 13:35:29">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2021-07-12 13:35:29"><div class="time">2021-07-12 13:35:29</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* That was a long time ago, so I don't remember specifically, but I can tell you the most common reason this happens in general, and it's because the only species that occur at those locations have so few occurrences at other locations that meaningful classifier training and/or validation would be impossible for those species.  Does that compute here?  Are these locations with either very few images or bespoke species?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-07-13 06:22:06">
            
                <img src="https://avatars.slack-edge.com/2021-05-08/2030294018551_55c7e50192aabb4d0794_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">»òtefan Istrate
                     <span class="print-only user-email">(stefan.istrate@gmail.com)</span>
                </div>
                <a href="#2021-07-13 06:22:06"><div class="time">2021-07-13 06:22:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Not really. I think some locations could be considered as having few images (if ~100 images counts as "few"), but most have thousands and for quite frequent species. Take for example this missing location:</p>

<p>"4334": {
    "human": 1226,
    "motorcycle": 40,
    "meleagris ocellata": 180,
    "leopardus pardalis": 100,
    "empty": 95,
    "procyon lotor": 590,
    "odocoileus virginianus": 80,
    "didelphis sp": 370,
    "dasyprocta punctata": 170,
    "urocyon cinereoargenteus": 170,
    "unknown": 40,
    "claravis pretiosa": 30,
    "agouti paca": 119,
    "leptotila plumbeiceps": 10,
    "equus ferus": 10,
    "puma yagoroundi": 20,
    "panthera onca": 10,
    "crax rubra": 10,
    "dasypus novemcinctus": 20
  },</p>

<p>Out of these 19 classes, 16 are from top 100 in WCS, i.e. classes with at least 800 images in the entire dataset.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-07-13 06:25:17">
            
                <img src="https://avatars.slack-edge.com/2021-05-08/2030294018551_55c7e50192aabb4d0794_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">»òtefan Istrate
                     <span class="print-only user-email">(stefan.istrate@gmail.com)</span>
                </div>
                <a href="#2021-07-13 06:25:17"><div class="time">2021-07-13 06:25:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I'm attaching a file with more (but not all) missing locations from "recommended train/val/test splits".</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="https://files.slack.com/files-pri/TM808NB0D-F0288T51R8R/location_to_species.txt?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc">location_to_species.txt</a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-07-13 10:27:21">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-07-13 10:27:21"><div class="time">2021-07-13 10:27:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris I didn't make the recommended splits for these so I'm not sure, but one possibility is that more data was added to the dataset later on and the split wasn't changed?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-07-22 13:56:03">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2021-07-22 13:56:03"><div class="time">2021-07-22 13:56:03</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* The WCS dataset was not updated anything other than minor bug fixes... Stefan, I'm sorry to say this one might just remain a mystery.  Did you happen to compute the total number of images that are excluded from the splits?  If it's &lt;10%, I recommend we add all the missing locations to "train" and call it a day.  If it's more substantial, we might consider a v2 of the splits (leaving the old one available as well); to my knowledge no one has published using the existing splits.  Sorry we don't have a clear answer here!</p>

<p>FWIW since we posted those splits, I've become a little less enthusiastic about including a "test" split in public splits like this; the concept of "test" doesn't really make sense when everything is public, or at the very least is a little misleading.  So maybe it's a blessing in disguise if we decide to re-split into just train/val.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-07-22 14:04:02">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-07-22 14:04:02"><div class="time">2021-07-22 14:04:02</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* agreed re: train/val</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-07 06:49:51">
            
                <img src="https://avatars.slack-edge.com/2021-05-08/2030294018551_55c7e50192aabb4d0794_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">»òtefan Istrate
                     <span class="print-only user-email">(stefan.istrate@gmail.com)</span>
                </div>
                <a href="#2021-08-07 06:49:51"><div class="time">2021-08-07 06:49:51</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* According to my calculations, the proportion of images excluded from the splits is around 35%. That being said I wasn't planning on relying on the recommended splits anyway. I was just investigating the data a bit. :-)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-02 13:57:00">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2021-08-02 13:57:00"><div class="time">2021-08-02 13:57:00</div></a>
                <div class="msg">
                    <p>New data set on LILA, with ~1.5M images from Idaho, courtesy of the Idaho Department of Fish and Game:</p>

<p><a href="http://lila.science/datasets/idaho-camera-traps/">http://lila.science/datasets/idaho-camera-traps/</a></p>

<p>If folks are looking to train models that would be immediately useful to an organization that is already using AI tools in their workflow (ergo it would be relatively easy to introduce new models), this data set would be great for training a one-class deer/elk classifier (i.e., separating deer and elk from everything else), and may also be great for training a classifier to recognize snowy/foggy lenses, which present a unique challenge for AI-based workflows, because "no animals present" is different than "the lens was covered in snow so I don't actually know whether there are any animals present".</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="http://lila.science/datasets/idaho-camera-traps/">Idaho Camera Traps - LILA BC</a></div>
                                <div class="link-text">
                                    Overview This data set contains approximately 1.5 million camera trap images from Idaho. Labels are provided for 62 categories, most of which are animal classes (‚Äúdeer‚Äù, ‚Äúelk‚Äù, and ‚Äúcattle‚Äù are the most common animal classes), but labels also include some state indicators (e.g. ‚Äúsnow on lens‚Äù, ‚Äúfoggy lens‚Äù). Approximately 70.5% of images are labeled as...
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Written by</div>
                                        lilawp
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Est. reading time</div>
                                        2 minutes
                                    </div>
                                
                                
    
        <a href="http://lila.science/datasets/idaho-camera-traps/">
            <img class="preview" src="http://lila.science/wp-content/uploads/2021/07/idaho-camera-traps.jpg"
                width="444"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: http://lila.science/datasets/idaho-camera-traps/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëè Oisin Mac Aodha, Siyu Yang, Carly Batist, Omiros Pantazis, Tony Chang, Alan Ma
                        </div>
                    
                        <div class="message-reaction">
                        :the_horns: Mitch Fennell, Rosho, Sam Kelly
                        </div>
                    
                        <div class="message-reaction">
                        üôå Sara Beery, Jon Van Oast, Sam Kelly
                        </div>
                    
                        <div class="message-reaction">
                        üëç Sam Kelly
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-11-12 15:15:00">
            
                <img src="https://avatars.slack-edge.com/2021-09-09/2472196017637_6b0b6a8c688f8723ee6d_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Katie Wetstone (she, her)
                     <span class="print-only user-email">(katie@drivendata.org)</span>
                </div>
                <a href="#2021-11-12 15:15:00"><div class="time">2021-11-12 15:15:00</div></a>
                <div class="msg">
                    <p><a href="https://aiforconservation.slack.com/archives/CLWGQ4BJ6/p1636747711072400">https://aiforconservation.slack.com/archives/CLWGQ4BJ6/p1636747711072400</a></p>
                    <div class="message-attachment"
                            >
                            
                            
                                <div class="attachment-author">
                                    
                                        <img src="https://avatars.slack-edge.com/2021-09-09/2472196017637_6b0b6a8c688f8723ee6d_48.jpg" class="icon">
                                    }
                                    <a href="https://aiforconservation.slack.com/team/U02DZ47A49G">
                                    Katie Wetstone (she, her)
                                    </a><span class="print-only">(https://aiforconservation.slack.com/team/U02DZ47A49G)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href=""></a></div>
                                <div class="link-text">
                                    &lt;p&gt;&lt;strong&gt;Hi everyone!&lt;/strong&gt; üêµ¬†&lt;strong&gt;We are spreading the word about a free, open-source tool called¬†&lt;a href=&#34;https://zamba.drivendata.org/&#34;&gt;Zamba&lt;/a&gt;¬†that automatically detects and classifies animals in camera trap videos. If you use camera traps to capture videos, we‚Äôd love your feedback!&lt;/strong&gt;¬†üêµ¬†Try your videos with the species we cover or use our training functionality to make yourself a custom model just for your data.¬†&lt;/p&gt;

&lt;p&gt;We want to make the tool as useful as possible, and are hoping to gather user feedback. In particular, we‚Äôd love to have users test out the Zamba¬†&lt;a href=&#34;https://zamba.drivendata.org/docs/stable/&#34;&gt;python package&lt;/a&gt;. We‚Äôve just released v2 of this package with brand new models and more features!&lt;/p&gt;

&lt;p&gt;For background, we at¬†&lt;a href=&#34;https://www.drivendata.org/&#34;&gt;DrivenData&lt;/a&gt;¬†developed the tool in partnership with experts from the Max Planck Institute for Evolutionary Anthropology (&lt;a href=&#34;http://www.eva.mpg.de/index.html&#34;&gt;MPI-EVA&lt;/a&gt;). A few basics about Zamba:
‚Ä¢ üß†¬†&lt;strong&gt;Zamba uses artificial intelligence and computer vision to perform intensive camera trap video processing work&lt;/strong&gt;, freeing up more time for humans to focus on interpreting the content and using the results.
‚Ä¢ :female&lt;em&gt;technologist::skin&lt;/em&gt;tone_4:&lt;em&gt;*¬†*&lt;/em&gt;Zamba can be accessed through an easy command line interface or as a Python¬†&lt;a href=&#34;https://zamba.drivendata.org/docs/&#34;&gt;package&lt;/a&gt;¬†- the code is all open-source on¬†&lt;a href=&#34;https://github.com/drivendataorg/zamba&#34;&gt;Github&lt;/a&gt;!
‚Ä¢ üêò¬†Pretrained¬†&lt;a href=&#34;https://zamba.drivendata.org/docs/stable/models/species-detection/&#34;&gt;models&lt;/a&gt;¬†are available to predict 42 different species common to western Europe and central Africa, plus blank versus non-blank.
‚Ä¢ üåç¬†Zamba can be adapted to any set of species or ecosystem. Users can easily use their own labeled videos to generate a retrained model specific to their use case.
‚Ä¢ üì∏¬†Zamba is trained on over 27,000 hand-labeled camera trap videos.
A couple ways you can contribute:
‚Ä¢ Flag any bugs you find while using the Zamba python package - or submit an issue directly to the¬†&lt;a href=&#34;https://github.com/drivendataorg/zamba/issues&#34;&gt;Github repo&lt;/a&gt;
‚Ä¢ Let us know which parts of the package¬†&lt;a href=&#34;https://zamba.drivendata.org/docs/stable/&#34;&gt;documentation&lt;/a&gt;¬†are confusing or could be improved
‚Ä¢ Train a¬†&lt;a href=&#34;https://zamba.drivendata.org/docs/stable/train-tutorial/&#34;&gt;new custom model&lt;/a&gt;¬†and make it available to others through the¬†&lt;a href=&#34;https://github.com/drivendataorg/zamba/wiki&#34;&gt;Model Zoo Wiki&lt;/a&gt;
You can send us any feedback or thoughts by commenting on this post, filling an issue on the GitHub repository, or by emailing¬†&lt;a href=&#34;mailto:info@drivendata.org&#34;&gt;info@drivendata.org&lt;/a&gt;. Close collaboration with subject area expects has been critical to the development of Zamba, and we look forward to hearing your perspectives!¬†üéâ&lt;/p&gt;
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://aiforconservation.slack.com/archives/CLWGQ4BJ6/p1636747711072400</div>
                                
                                
                                    <div class="attachment-footer">
                                        <img src="" class="icon" />
                                        Thread in Slack Conversation
                                    </div>
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-11-27 16:55:29">
            
                <img src="https://avatars.slack-edge.com/2021-11-02/2692736509489_046a7d53c35106ac322b_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Alan Ma
                     <span class="print-only user-email">(alanma393141@gmail.com)</span>
                </div>
                <a href="#2021-11-27 16:55:29"><div class="time">2021-11-27 16:55:29</div></a>
                <div class="msg">
                    <p>Howdy all,</p>

<p>I am currently working on a roadkill prevention project that involves using a trap camera to help collect wildlife activity data.  It's purpose is to warn drivers of animal presence detected and simultaneously collect image data for monitoring wildlife activity along road environments in the pursuit of preserving wildlife/human wellbeing. In particular this project is expanding the computer vision side of things through greater species identification power. Via multiple infrared sensors and a radar sensor, the project hopes to detect wildlife presence through changes in the environment heat signatures and depth. Once the sensors have been triggered a NoIR camera snaps a picture of it's field of vision. After the picture has been collected, hopefully capturing wildlife in the process, a offline pre-trained ML model runs to identify the said wildlife. The identified wildlife species as well as metadata are incorporated to be mapped for the purpose of identifying regions of dense wildlife activity as well as possible migration patterns.</p>

<p>This project is looking for suggestions and collaboration due to my limited scope on the implementation of artificial intelligence, I was hoping to receive assistance from the community on improving the machine learning capabilities of this project. More specifically, the project is looking to expand on a larger wildlife species prediction capability <em>* (1) and identify migration/animal behavior patterns (2). <strong>(</strong> If you know or are willing to share a database of wildlife images to help improve this project's machine learning model it would be greatly appreciated! One of the major challenges in helping improve the current wildlife identification model is a lack of available images in model training.)</em>*</p>

<p>If there are individuals willing to, I would love to discuss more deeply the methods used or other ideas on how to improve on the project's limitations.</p>

<p>Thanks in advance for your time - Alan</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëã Sara Beery, Kai Waddington
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-11-28 08:34:37">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2021-11-28 08:34:37"><div class="time">2021-11-28 08:34:37</div></a>
                <div class="msg">
                    <p>Megadetector (<a href="https://github.com/microsoft/CameraTraps/blob/master/megadetector.md">https://github.com/microsoft/CameraTraps/blob/master/megadetector.md</a>) is great for identifying animals in camera traps. There have been WILDLABS tech tutors episodes on this as well by @Siyu Yang &amp; @Sara Beery - <a href="https://www.wildlabs.net/resources/tech-tutors/how-do-i-get-started-megadetector">here</a> &amp; <a href="https://www.wildlabs.net/resources/tech-tutors/how-do-i-get-started-using-machine-learning-my-camera-traps">here</a>. Also look on LILA BC (<a href="https://lila.science/">https://lila.science/</a>), tons of datasets. Also might be worth talking to the folks at Wildlife Insights if you haven‚Äôt already (<a href="https://www.wildlifeinsights.org/">https://www.wildlifeinsights.org/</a>). You can also check out the Conservation Tech Directory (<a href="https://conservationtech.directory/">https://conservationtech.directory/</a>) and filter by camera trap to see projects in the space.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="https://lila.science/">LILA BC (Labeled Image Library of Alexandria: Biology and Conservation)</a></div>
                                <div class="link-text">
                                    LILA BC is a repository for archival data sets related to biology and conservation. Our intention is to create a valuable resource for the scientific community, including for machine learning researchers and/or those that want to harness machine learning for biology and conservation. Machine learning depends on labeled data, but getting access to such data in biology and conservation is a challenge. Consequently, everyone benefits when more labeled data is made available.
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Est. reading time</div>
                                        1 minute
                                    </div>
                                
                                
    
        <a href="https://lila.science/">
            <img class="preview" src="https://lila.science/wp-content/uploads/2018/10/IMG_1881_web.jpg"
                width="333"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://lila.science/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery, Talia Speaker
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-11-28 08:36:18">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2021-11-28 08:36:18"><div class="time">2021-11-28 08:36:18</div></a>
                <div class="msg">
                    <p>You might also want to post to the community forum on WILDLABS - <a href="https://www.wildlabs.net/community">https://www.wildlabs.net/community</a>. It‚Äôs a really amazing online platform for conservation tech. And one of the forum groups is for camera traps.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Talia Speaker
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-12-13 10:03:27">
            
                <img src="https://secure.gravatar.com/avatar/6fb6f243d36cae61a5f9ff8e03472aae.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Katja Seltmann
                     <span class="print-only user-email">(seltmann@ccber.ucsb.edu)</span>
                </div>
                <a href="#2021-12-13 10:03:27"><div class="time">2021-12-13 10:03:27</div></a>
                <div class="msg">
                    <p>Hi all- Does anyone have camera trap data of honeybees or bumblebees I can use for an undergraduate capstone student project? I have a NSF called Big-Bee where we are creating 3D images of many bees (<a href="http://big-bee.net">http://big-bee.net</a>) and I would like to test the use of these images for training ML models for bee detection. Thanks in advance for your consideration!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-12-13 10:28:35">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-12-13 10:28:35"><div class="time">2021-12-13 10:28:35</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* can we see a sample image?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-12-13 11:09:06">
            
                <img src="https://secure.gravatar.com/avatar/6fb6f243d36cae61a5f9ff8e03472aae.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Katja Seltmann
                     <span class="print-only user-email">(seltmann@ccber.ucsb.edu)</span>
                </div>
                <a href="#2021-12-13 11:09:06"><div class="time">2021-12-13 11:09:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* All of the images will be available online in the next 6 months under CC license at <a href="https://library.big-bee.net/portal">https://library.big-bee.net/portal</a>. Here are some prototypes (<a href="https://ucsb.box.com/s/m0bzpme4xhg0stbx99e6a5kkjcgf85sn">https://ucsb.box.com/s/m0bzpme4xhg0stbx99e6a5kkjcgf85sn</a>)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-12-13 12:52:59">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2361920803907_ad849dc380fc3d3470dc_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Daniel Davila
                     <span class="print-only user-email">(daniel.davila@kitware.com)</span>
                </div>
                <a href="#2021-12-13 12:52:59"><div class="time">2021-12-13 12:52:59</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Not camera trap data, but this work comes to mind:
<a href="https://github.com/vladan-stojnic/Detection-of-Small-Flying-Objects-in-UAV-Videos">https://github.com/vladan-stojnic/Detection-of-Small-Flying-Objects-in-UAV-Videos</a></p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">vladan-stojnic/Detection-of-Small-Flying-Objects-in-UAV-Videos</a></div>
                                <div class="link-text">
                                    Code for paper &#34;Detection of Flying Honeybees in UAV Videos&#34;
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        35
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        Python
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-12-13 13:57:47">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2021-12-13 13:57:47"><div class="time">2021-12-13 13:57:47</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Also not camera trap data, but close to what you're asking about, and labeled with pretty rich annotations:</p>

<p><a href="https://lila.science/datasets/boxes-on-bees-and-pollen">https://lila.science/datasets/boxes-on-bees-and-pollen</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="https://lila.science/datasets/boxes-on-bees-and-pollen">Boxes on Bees and Pollen - LILA BC</a></div>
                                <div class="link-text">
                                    Overview The goal of the BeeLivingSensor project is to non-invasively track honey bees at hive entrances, and to track the type and volume of pollen they bring into the hive. By analyzing the color of the pollen and aggregating it with other data, the project aims to to determine the plant biodiversity around the beehive....
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Written by</div>
                                        lilawp
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Est. reading time</div>
                                        1 minute
                                    </div>
                                
                                
    
        <a href="https://lila.science/datasets/boxes-on-bees-and-pollen">
            <img class="preview" src="http://lila.science/wp-content/uploads/2021/03/bee_thumb.png"
                width="271"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://lila.science/datasets/boxes-on-bees-and-pollen</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-01-10 12:21:25">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-01-10 12:21:25"><div class="time">2022-01-10 12:21:25</div></a>
                <div class="msg">
                    <p>New camera trap data set on LILA, helping to broaden LILA‚Äôs coverage of rainforest ecosystems:</p>

<p><a href="https://lila.science/datasets/swg-camera-traps">https://lila.science/datasets/swg-camera-traps</a></p>

<p>Around 2M images in total, including around 100k bounding boxes.  Thanks to the Saola Working Group for providing this data!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="https://lila.science/datasets/swg-camera-traps">SWG Camera Traps 2018-2020 - LILA BC</a></div>
                                <div class="link-text">
                                    Overview This data set contains 436,617 sequences of camera trap images from 982 locations in Vietnam and Lao, totaling 2,039,657 images. Labels are provided for 120 categories, primarily at the species level (for example, the most common labels are ‚ÄúEurasian Wild Pig‚Äù, ‚ÄúLarge-antlered Muntjac‚Äù, and ‚ÄúUnidentified Murid‚Äù). Approximately 12.98% of images are labeled as empty....
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Written by</div>
                                        lilawp
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Est. reading time</div>
                                        2 minutes
                                    </div>
                                
                                
    
        <a href="https://lila.science/datasets/swg-camera-traps">
            <img class="preview" src="http://lila.science/wp-content/uploads/2021/12/pheasant_web.jpg"
                width="333"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://lila.science/datasets/swg-camera-traps</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery, Peter Bull, Oisin Mac Aodha, Subhransu Maji, Omiros Pantazis, Mitch Fennell, Agnethe Seim Olsen, Kai Waddington
                        </div>
                    
                        <div class="message-reaction">
                        :thumbsup_all: Frederic Fol Leymarie
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-01-22 01:21:36">
            
                <img src="https://avatars.slack-edge.com/2021-02-23/1809933377808_8dc18744741ad7500d94_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Mitch Fennell
                     <span class="print-only user-email">(mitchell.fennell@gmail.com)</span>
                </div>
                <a href="#2022-01-22 01:21:36"><div class="time">2022-01-22 01:21:36</div></a>
                <div class="msg">
                    <p>Longtime lurker, first time poster here! We've recently released a pre-print assessing the efficacy and efficiency of using MegaDetector to classify an out-of-sample dataset, specifically with a large number of human images. The performance was quite impressive, and we figure the results may be of interest to some folks here: <a href="https://www.biorxiv.org/content/10.1101/2022.01.14.476404v2">https://www.biorxiv.org/content/10.1101/2022.01.14.476404v2</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">bioRxiv</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.biorxiv.org/content/10.1101/2022.01.14.476404v2">Use of object detection in camera trap image identification: assessing a method to rapidly and accurately classify human and animal detections for research and application in recreation ecology</a></div>
                                <div class="link-text">
                                    Camera traps are increasingly used to answer complex ecological questions. However, the rapidly growing number of images collected presents technical challenges. Each image must be classified to extract data, requiring significant labour, and potentially creating an information bottleneck. We applied an object-detection model (MegaDetector) to camera trap data from a study of recreation ecology in British Columbia, Canada. We tested its performance in detecting humans and animals relative to manual image classifications, and assessed efficiency by comparing the time required for manual classification versus a modified workflow integrating object-detection with manual classification. We also evaluated the reliability of using MegaDetector to create an index of human activity for application to the study of recreation impacts to wildlife. In our application, MegaDetector detected human and animal images with 97% accuracy. The overall time required to process the dataset was reduced by over 500%, and the manual processing component was reduced by 840%. The index of human detection events from MegaDetector matched the output from manual classification, with a mean 0.45% difference in estimated human detections across site-weeks. Our test of an open-source object-detection model showed it performed well in partially classifying a camera trap dataset, significantly increasing processing efficiency. We suggest that this tool could be integrated into existing camera trap workflows to accelerate research and application by alleviating data bottlenecks, particularly for surveys processing large volumes of human images. We also show how the model and workflow can be used to anonymize human images prior to classification, protecting individual privacy. ### Competing Interest Statement The authors have declared no competing interest.
                                </div>
                                
                                
    
        <a href="https://www.biorxiv.org/content/10.1101/2022.01.14.476404v2">
            <img class="preview" src="https://www.biorxiv.org/sites/default/files/images/biorxiv_logo_homepage7-5-small.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.biorxiv.org/content/10.1101/2022.01.14.476404v2</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Kakani Katija, David Will, Carly Batist, Dan Morris
                        </div>
                    
                        <div class="message-reaction">
                        üëè Lucia Gordon, Omiros Pantazis
                        </div>
                    
                        <div class="message-reaction">
                        üòç Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        :thumbsup_all: Frederic Fol Leymarie
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-07 12:31:10">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-02-07 12:31:10"><div class="time">2022-02-07 12:31:10</div></a>
                <div class="msg">
                    <p>Not exactly a new dataset, but we just added over 300k bounding boxes (up from ~50k to ~375k) to the WCS Camera Traps data set on LILA:</p>

<p><a href="https://lila.science/datasets/wcscameratraps">https://lila.science/datasets/wcscameratraps</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="https://lila.science/datasets/wcscameratraps">WCS Camera Traps - LILA BC</a></div>
                                <div class="link-text">
                                    Overview This data set contains approximately 1.4M camera trap images representing around 675 species from 12 countries, making it one of the most diverse camera trap data sets available publicly. Data were provided by the Wildlife Conservation Society. The most common classes are tayassu pecari (peccary), meleagris ocellata (ocellated turkey), and bos taurus (cattle). A...
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Written by</div>
                                        lilawp
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Est. reading time</div>
                                        2 minutes
                                    </div>
                                
                                
    
        <a href="https://lila.science/datasets/wcscameratraps">
            <img class="preview" src="http://lila.science/wp-content/uploads/2019/06/wcs_thumbnail.jpg"
                width="333"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://lila.science/datasets/wcscameratraps</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Dhruv Sheth, Lukas Picek
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Peter Bull, Mitch Fennell, Dhruv Sheth, Kai Waddington
                        </div>
                    
                        <div class="message-reaction">
                        üòç Dhruv Sheth
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-08 22:03:36">
            
                <img src="https://avatars.slack-edge.com/2022-02-07/3065156420725_fc9955ffae363c5939f2_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Juliana Velez
                     <span class="print-only user-email">(velez063@umn.edu)</span>
                </div>
                <a href="#2022-02-08 22:03:36"><div class="time">2022-02-08 22:03:36</div></a>
                <div class="msg">
                    <p>Hi everyone! I'm working on a project to improve wildlife habitat in multifunctional landscapes in the Colombian Orinoquia. We are using camera traps and acoustic monitoring, which drove my interest in AI, as we are getting tons of data. I wanted to share our <a href="https://arxiv.org/abs/2202.02283">new review</a> of AI-powered platforms -- Wildlife Insights, MegaDetector, MLWIC2 and Conservation AI -- for processing camera trap data (shoutout to coauthor @Mikey Tabak and reviewer @Dan Morris). Along with the paper, we released our <a href="https://lila.science/orinoquia-camera-traps/">data in LILA</a> (~100K images; ) and published a <a href="https://ai-camtraps.netlify.app/">GitBook</a> that illustrates the use of these platforms and provides R code for evaluating model performance. We hope this will be useful for camera trappers interested in using AI!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2202.02283">Choosing an Appropriate Platform and Workflow for Processing...</a></div>
                                <div class="link-text">
                                    Camera traps have transformed how ecologists study wildlife species distributions, activity patterns, and interspecific interactions. Although camera traps provide a cost-effective method for...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2202.02283">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2202.02283</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="https://lila.science/orinoquia-camera-traps/">Orinoqu√≠a Camera Traps - LILA BC</a></div>
                                <div class="link-text">
                                    Overview This data set contains 104,782 images collected from a 50-camera-trap array deployed from January to July 2020 within the private natural reserves El Rey Zamuro (31 km2) and Las Unamas (40 km2), located in the Meta department in the Orinoqu√≠a region in central Colombia. We deployed cameras using a stratified random sampling design across...
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Written by</div>
                                        lilawp
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Est. reading time</div>
                                        2 minutes
                                    </div>
                                
                                
    
        <a href="https://lila.science/orinoquia-camera-traps/">
            <img class="preview" src="http://lila.science/wp-content/uploads/2022/01/orinoquia-thumb-web.jpg"
                width="333"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://lila.science/orinoquia-camera-traps/</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">ai-camtraps.netlify.app</div>
                            
                            
                                
                                <div class="link-title"><a href="https://ai-camtraps.netlify.app/">Guide for using artificial intelligence systems for camera trap data processing</a></div>
                                <div class="link-text">
                                    We aim to provide an overview of the steps required to use platforms that implement artificial intelligence into workflows for processing camera trap images.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://ai-camtraps.netlify.app/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üòç Sara Beery, Carly Batist, Ankita Shukla, Mikey Tabak
                        </div>
                    
                        <div class="message-reaction">
                        üëç Dan Morris, Mitch Fennell, Subhransu Maji
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-08 22:07:10">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-02-08 22:07:10"><div class="time">2022-02-08 22:07:10</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* This paper is awesome. It's so useful to see a case study of what the different platforms and models translate to in terms of practical use!!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üíØ Carly Batist, Mitch Fennell
                        </div>
                    
                        <div class="message-reaction">
                        üòç Juliana Velez
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-09 02:06:13">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-02-09 02:06:13"><div class="time">2022-02-09 02:06:13</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* ^Totally agree!!! Very cool paper</p>
                    
                    
                    
                        <div class="message-reaction">
                        üòç Juliana Velez
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-09 09:13:53">
            
                <img src="https://avatars.slack-edge.com/2022-02-07/3065156420725_fc9955ffae363c5939f2_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Juliana Velez
                     <span class="print-only user-email">(velez063@umn.edu)</span>
                </div>
                <a href="#2022-02-09 09:13:53"><div class="time">2022-02-09 09:13:53</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thank you @Sara Beery and @Carly Batist! üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-09 11:31:24">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-02-09 11:31:24"><div class="time">2022-02-09 11:31:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Juliana Velez i'm forwarding this to my friend/colleague Juan Parra at Antoquia who is also doing biodiversity surveys, but I think in eastern colombia.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Juliana Velez, Mitch Fennell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-09 11:39:54">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-02-09 11:39:54"><div class="time">2022-02-09 11:39:54</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Also a word of enthusiasm for this data set: if someone is looking for a dataset to demonstrate that there's a ceiling on the recall we can achieve without looking at sequence information, this is a perfect dataset.  I looked at all the MegaDetector misses on the whole dataset, and they are more or less the same cases where a human can't see the images in an individual image either: you <strong>have</strong> to see the fuzzy blob moving behind the bushes.  I also think that a sequence-based system doesn't have to "beat" an image-based system to be super-useful for cases like this, it could complement it to improve overall recall.  So I'll buy anyone a granola bar who can run something like Sara's Context R-CNN work against this dataset and find a bunch of little fuzzy moving blobs that MegaDetector misses, even if the precision you need to get to that recall is a lot lower, and even if the sequence-based system misses a bunch of non-moving things that you can see perfectly well in single images.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Sara Beery, Mitch Fennell
                        </div>
                    
                        <div class="message-reaction">
                        üëç Juliana Velez, Barry Brook
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-20 08:32:33">
            
                <img src="https://avatars.slack-edge.com/2022-02-09/3075038202214_f9ee2a2a94dcc3815f28_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Peter van Lunteren
                     <span class="print-only user-email">(contact@pvanlunteren.com)</span>
                </div>
                <a href="#2022-02-20 08:32:33"><div class="time">2022-02-20 08:32:33</div></a>
                <div class="msg">
                    <p>Hello everybody,</p>

<p>What a wonderful idea to create a community for AI-savvy ecologists! @Dan Morris, thanks for adding me. My name is Peter and I‚Äôm a wildlife ecologist from The Netherlands with a special interest in machine learning. While practicing my python I created a simple GUI for the MegaDetector model plus some extra features. I called it EcoAssist and plan to keep it up-to-date. You can download it here: <a href="https://github.com/PetervanLunteren/EcoAssist">https://github.com/PetervanLunteren/EcoAssist</a></p>

<p>Features:
‚Ä¢ Detect animals, persons and vehicles in images or video‚Äôs
‚Ä¢ Separate files into subdirectories based on their detections
‚Ä¢ Draw boxes around the detections or crop them
‚Ä¢ Create .xml label files in Pascal VOC format for further ML processing
‚Ä¢ Shortcut to labelImg to adjust annotations
‚Ä¢ Easily set parameters like threshold and checkpoint frequency
Help me to keep improving EcoAssist and let me know about any improvements, bugs, or new features. Thanks!</p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">PetervanLunteren/EcoAssist</a></div>
                                <div class="link-text">
                                    An application for detecting animals in camera trap images
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        1
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        Python
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëç Oisin Mac Aodha, Dhruv Sheth, Mitch Fennell, Dan Morris, Sara Beery, Saket Anand, Jon Van Oast, Petar Gyurov, Barry Brook
                        </div>
                    
                        <div class="message-reaction">
                        üëã Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üí™ Thijs
                        </div>
                    
                        <div class="message-reaction">
                        :thumbsup_all: Frederic Fol Leymarie
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-03-22 05:21:22">
            
                <img src="https://avatars.slack-edge.com/2021-05-08/2030294018551_55c7e50192aabb4d0794_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">»òtefan Istrate
                     <span class="print-only user-email">(stefan.istrate@gmail.com)</span>
                </div>
                <a href="#2022-03-22 05:21:22"><div class="time">2022-03-22 05:21:22</div></a>
                <div class="msg">
                    <p>Happy to announce iWildCam 2022, our 5th annual camera trap challenge, focused on helping ecologists monitor biodiversity. Join the Kaggle competition and help us count individual animals across sequences of images.</p>

<p><a href="https://www.kaggle.com/c/iwildcam2022-fgvc9">https://www.kaggle.com/c/iwildcam2022-fgvc9</a></p>

<p>[Competition co-organized with @Sara Beery &amp; @John Beuving, with valuable support from @Dan Morris.]</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">kaggle.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.kaggle.com/c/iwildcam2022-fgvc9">iWildCam 2022 - FGVC9</a></div>
                                <div class="link-text">
                                    Count the number of animals in a sequence of images
                                </div>
                                
                                
    
        <a href="https://www.kaggle.com/c/iwildcam2022-fgvc9">
            <img class="preview" src="https://storage.googleapis.com/kaggle-competitions/kaggle/33843/logos/thumb76_76.png?t=2022-02-12-21-25-18"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.kaggle.com/c/iwildcam2022-fgvc9</div>
                                
                                
                            
                        </div>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëç Oisin Mac Aodha, Mitch Fennell, Dan Morris, Sara Beery, Stefan Schneider
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Sara Beery, Stefan Schneider, Kakani Katija, Oorjit Mahajan
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-04-26 16:09:06">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-04-26 16:09:06"><div class="time">2022-04-26 16:09:06</div></a>
                <div class="msg">
                    <p>I did my first update in about a zillion years to my "list of ML for camera trap stuff":</p>

<p><a href="https://agentmorris.github.io/camera-trap-ml-survey/">https://agentmorris.github.io/camera-trap-ml-survey/</a></p>

<p>In particular I hadn't added any papers since late 2020, so shout-outs to lots of new papers:</p>

<p><a href="https://agentmorris.github.io/camera-trap-ml-survey/#camera-trap-ml-papers">https://agentmorris.github.io/camera-trap-ml-survey/#camera-trap-ml-papers</a></p>

<p>Drop me a line if I'm missing things and/or if my short summaries badly misrepresented anyone's work.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üåü Talia Speaker, Mitch Fennell, Olivier Gimenez, Oorjit Mahajan, Timm Haucke, Oisin Mac Aodha, Omiros Pantazis, Carly Batist
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Jon Van Oast, Oorjit Mahajan
                        </div>
                    
                        <div class="message-reaction">
                        :thumbsup_all: Frederic Fol Leymarie, Oorjit Mahajan
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-04-26 16:10:04">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-04-26 16:10:04"><div class="time">2022-04-26 16:10:04</div></a>
                <div class="msg">
                    <p>Ok!! Looking forward to checking it out</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-04-28 09:07:47">
            
                <img src="https://avatars.slack-edge.com/2022-11-07/4325264017430_1d69dc73e8586441b2af_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Omiros Pantazis
                     <span class="print-only user-email">(omiros.pantazis.16@ucl.ac.uk)</span>
                </div>
                <a href="#2022-04-28 09:07:47"><div class="time">2022-04-28 09:07:47</div></a>
                <div class="msg">
                    <p>Hi everybody, there follows a belated self-promotion that I think is relevant for the channel:
Last year we published a paper on <strong>self-supervised learning for camera traps</strong> species classification on the International Conference on Computer Vision (<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Pantazis_Focus_on_the_Positives_Self-Supervised_Learning_for_Biodiversity_Monitoring_ICCV_2021_paper.pdf">https://openaccess.thecvf.com/content/ICCV2021/papers/Pantazis<em>Focus</em>on<em>the</em>Positives<em>S[‚Ä¶]d</em>Learning<em>for</em>Biodiversity<em>Monitoring</em>ICCV<em>2021</em>paper.pdf</a>). Among others, we showed that:
i) self-supervised learning on the same-domain is more effective than transfer learning esp. when not lots of labels are available,
ii) exploiting context information during self-supervised learning, such as location/time which is basically always available can further boost performance,
iii) findings were consistent across 4 camera trap datasets.
There is also a short video <a href="https://www.youtube.com/watch?v=MRQ26QNGJS4&amp;t=3s">https://www.youtube.com/watch?v=MRQ26QNGJS4&amp;t=3s</a> available if you wanna learn more and a github repository <a href="https://github.com/omipan/camera_traps_self_supervised/">https://github.com/omipan/camera_traps_self_supervised/</a> in place If you would like to use our code.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Sara Beery, Daniel Davila, Oisin Mac Aodha, Mitch Fennell, Kakani Katija, Amy Andrews
                        </div>
                    
                        <div class="message-reaction">
                        üëç Justine Boulent, Oisin Mac Aodha, Dan Morris, Amrita Gupta
                        </div>
                    
                        <div class="message-reaction">
                        üòé Jon Van Oast
                        </div>
                    
                        <div class="message-reaction">
                        :thumbsup_all: Frederic Fol Leymarie, Monty Ammar
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-20 15:58:17">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-06-20 15:58:17"><div class="time">2022-06-20 15:58:17</div></a>
                <div class="msg">
                    <p>Excited to announce the release of MegaDetectors (not a typo) v5!  Check out the full release notes here:</p>

<p><a href="https://github.com/microsoft/CameraTraps/releases/tag/v5.0">https://github.com/microsoft/CameraTraps/releases/tag/v5.0</a></p>

<p>Thanks to some of the folks on this channel who did some pre-release testing for us.</p>

<p>Let us know what your experiences are with both the instructions and the model(s)... we think it's a major improvement over MDv4, but we're cautious about being too confident until the community (that's you üôÇ) has had a chance to weigh in.  So, please weigh in!</p>

<p>@Siyu Yang @Saul Greenberg</p>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Sara Beery, Thijs, Suzanne Stathatos, Felipe Parodi, Mitch Fennell, Fagner Cunha, »òtefan Istrate, Olivier Gimenez, Stephanie O&#39;Donnell, Timm Haucke, Talia Speaker, Amrita Gupta, Sam Kelly
                        </div>
                    
                        <div class="message-reaction">
                        üëç Carly Batist, Anton Alvarez
                        </div>
                    
                        <div class="message-reaction">
                        üçæ Jon Van Oast, Nathaniel Rindlaub
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-20 16:59:54">
            
                <img src="https://avatars.slack-edge.com/2022-06-17/3696311190401_ec55743de740f4e5c7c2_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Thijs
                     <span class="print-only user-email">(thijs@q42.nl)</span>
                </div>
                <a href="#2022-06-20 16:59:54"><div class="time">2022-06-20 16:59:54</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Awesome! Would it be possible to get a quantized model so I could run this on a raspberry pi? Or is that a totally bonkers idea? üòá</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-20 18:28:17">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-06-20 18:28:17"><div class="time">2022-06-20 18:28:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* MDv5 was exported at the end of training using the standard Yolov5 export process, which quantizes to FP16.  Depending on how many triggers you typically get (e.g. per minute) on your camera, it's definitely plausible that this will run fine on a Pi device.   A few folks even did this with MDv4, which was much heavier.  So if you're up for it, give it a try and let us know what happens in terms of processing times.  You may be able to run the full .pt file, but Yolov5 also supports exporting to TFLite, and then you might follow a tutorial like this one to run the TFLite model on your device:</p>

<p><a href="https://www.codeproject.com/Articles/5293079/Deploying-YOLOv5-Model-on-Raspberry-Pi-with-Coral">https://www.codeproject.com/Articles/5293079/Deploying-YOLOv5-Model-on-Raspberry-Pi-with-Coral</a></p>

<p>All of that said, MDv5 - just like MDv4 - is trained to favor accuracy over speed and is not designed for embedded systems, so really what we recommend for embedded environments is using MD as an oracle, i.e. to generate bounding boxes on unlabeled images that match the ecosystem where you'll be deploying your embedded device,  and using those boxes to train whatever detector best matches your resource constraints.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-24 03:07:26">
            
                <img src="https://avatars.slack-edge.com/2021-07-27/2328648358305_c6f10f351ae5296c3ca1_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Vincent Miele CNRS
                     <span class="print-only user-email">(vincent.miele@univ-lyon1.fr)</span>
                </div>
                <a href="#2022-06-24 03:07:26"><div class="time">2022-06-24 03:07:26</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris Just a word to say that I tested MDv5 on very hard cases (those that MDv4 was enable to handle) and big success ! I'm actually enable to find cases in my big database were MDv5 is failing... Congrats</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-24 19:25:57">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-06-24 19:25:57"><div class="time">2022-06-24 19:25:57</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Vincent Miele CNRS... that's great!  We're always curious about these cases, so if you are able to share a description of the kinds of images where MDv5 does better, or a couple representative images (either here or by email to cameratraps@lila.science), that would satiate my curiosity. üôÇ  But in any case, glad to see that you saw improvement!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-29 05:06:44">
            
                <img src="https://avatars.slack-edge.com/2021-07-27/2328648358305_c6f10f351ae5296c3ca1_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Vincent Miele CNRS
                     <span class="print-only user-email">(vincent.miele@univ-lyon1.fr)</span>
                </div>
                <a href="#2022-06-29 05:06:44"><div class="time">2022-06-29 05:06:44</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Sure, I'll do that asap. We stay in touch</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-07-04 15:21:17">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-07-04 15:21:17"><div class="time">2022-07-04 15:21:17</div></a>
                <div class="msg">
                    <p>I finally got around to mapping all of the categories for all of the camera trap datasets on LILA to a common taxonomy, more information here:</p>

<p><a href="https://lila.science/taxonomy-mapping-for-camera-trap-data-sets/">https://lila.science/taxonomy-mapping-for-camera-trap-data-sets/</a></p>

<p>The goal is to make it easier to train models that span multiple datasets.  Lots of subjective decisions were involved, so, taxonomy experts, please send me bug fixes.</p>

<p>Also along the way I got to browse a zillion versions of this page, basically used to make sure that total nonsense didn't happen, e.g., that birds didn't get mapped to fish, or African species didn't end up in Idaho:</p>

<p><a href="https://lila.science/public/taxonomy-preview/">https://lila.science/public/taxonomy-preview/</a></p>

<p>Let me know if anything looks suspicious!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="https://lila.science/taxonomy-mapping-for-camera-trap-data-sets/">Taxonomy Mapping for Camera Trap Data Sets - LILA BC</a></div>
                                <div class="link-text">
                                    All the camera trap data sets use their own category names‚Ä¶ have they been mapped to a common taxonomy? Yes! This .csv file defines a mapping from every category in every camera trap dataset on LILA to the iNaturalist taxonomy. The goal is to let users train classifiers that span datasets, e.g. to be able...
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Est. reading time</div>
                                        1 minute
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://lila.science/taxonomy-mapping-for-camera-trap-data-sets/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Jon Van Oast, Sara Beery, Omiros Pantazis, Benno Simmons, Carly Batist, Oisin Mac Aodha, Talia Speaker, Mitch Fennell, Lukas Picek, Kai Waddington, Gaspard Dussert, Jeff Reed
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-07-05 04:45:22">
            
                <img src="https://secure.gravatar.com/avatar/4391c54952e1c48b6e9f3077946818bc.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0006-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Oisin Mac Aodha
                     <span class="print-only user-email">(macaodha@caltech.edu)</span>
                </div>
                <a href="#2022-07-05 04:45:22"><div class="time">2022-07-05 04:45:22</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Very cool. Do you know if this maps directly to the taxonomy used on iNat?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-07-05 12:09:47">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-07-05 12:09:47"><div class="time">2022-07-05 12:09:47</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yes, the mapping is to the most recent version (at least as of last week) of the iNat taxonomy.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôè Oisin Mac Aodha
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-08-19 03:37:53">
            
                <img src="https://avatars.slack-edge.com/2022-05-05/3483237601330_048808caf564d5089c7c_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Nicholas Osner
                     <span class="print-only user-email">(nicholasosner@gmail.com)</span>
                </div>
                <a href="#2022-08-19 03:37:53"><div class="time">2022-08-19 03:37:53</div></a>
                <div class="msg">
                    <p>Hi all, as most of you are probably aware, a new version of MegaDetector was released recently. Since TrapTagger uses MegaDetector as our animal-detector, we have now integrated it into the platform, and did a bit of a benchmarking exercise on one our reference datasets (from Botswana) to see how it fared against both the previous version, and a human annotator. For those that are interested, this was all compiled into a short report that we have published on our website <a href="https://wildeyeconservation.org/megadetector-version-5/">here</a>.</p>

<p>A summary of our findings is as follows:
‚Ä¢ MDv5 does indeed outperform MDv4, and is now on a par with a human annotator in it's recall of animal-containing images.
‚Ä¢ MDv5 is far better at detecting vehicles and humans then the previous version
‚Ä¢ It also runs 2.6 times faster in our archtecture without optimisation.
‚Ä¢ MDv5a and MDv5b performed equally well on our data.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Stephanie O&#39;Donnell, »òtefan Istrate, Oisin Mac Aodha, Carly Batist, Omiros Pantazis, Fagner Cunha, Dan Morris, Peter van Lunteren, Anton Alvarez, Mitch Fennell
                        </div>
                    
                        <div class="message-reaction">
                        üëÄ Anton Alvarez
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-08-19 09:31:20">
            
                <img src="https://avatars.slack-edge.com/2023-08-10/5721228585203_075088cb99a4c3c39a3e_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Timm Haucke
                     <span class="print-only user-email">(timm@haucke.xyz)</span>
                </div>
                <a href="#2022-08-19 09:31:20"><div class="time">2022-08-19 09:31:20</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* May I ask how you implemented the inference on AWS? I am currently trying to optimize MegaDetector v5 for embedded devices (and ease of deployment) using yolort (see <a href="https://github.com/timmh/MegaDetectorLite">https://github.com/timmh/MegaDetectorLite</a>), that's why I'm interested</p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">timmh/MegaDetectorLite</a></div>
                                <div class="link-text">
                                    MegaDetector 5.0 for Embedded Devices
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        Python
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Last updated</div>
                                        6 days ago
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-08-24 09:34:35">
            
                <img src="https://avatars.slack-edge.com/2022-05-05/3483237601330_048808caf564d5089c7c_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Nicholas Osner
                     <span class="print-only user-email">(nicholasosner@gmail.com)</span>
                </div>
                <a href="#2022-08-24 09:34:35"><div class="time">2022-08-24 09:34:35</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Unfortunately, I'm not entirely sure what information to give you since I think most of it won't be relevent to implementation on embedded devices. The best option would probably be to actually dig around in our implementation on our repository:</p>

<p><a href="https://github.com/WildEyeConservation/TrapTagger">https://github.com/WildEyeConservation/TrapTagger</a></p>

<p>We run inference on a number of temporary workers that consist of GPU-equipped AWS EC2 servers. They run what's in the megadetectorworker folder - essentially a launch script that kicks off a docker container that runs inference based in the functions in megaDetector.py (which in turn just pulls functions directly from MegaDetector). I haven't gotten around to really trying to optimise anything too heavily.</p>

<p>Let me know if you'd like me to expand on anything.</p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">WildEyeConservation/TrapTagger</a></div>
                                <div class="link-text">
                                    AI-Powered Camera-Trap Image Processing
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        3
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        Python
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-08-24 10:36:25">
            
                <img src="https://avatars.slack-edge.com/2023-08-10/5721228585203_075088cb99a4c3c39a3e_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Timm Haucke
                     <span class="print-only user-email">(timm@haucke.xyz)</span>
                </div>
                <a href="#2022-08-24 10:36:25"><div class="time">2022-08-24 10:36:25</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Sorry for being imprecise, I was primarily interested in the implementation you used and whether you performed any quantization. Thank you for clarifying!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-08-24 09:25:08">
            
                <img src="https://avatars.slack-edge.com/2022-05-05/3483237601330_048808caf564d5089c7c_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Nicholas Osner
                     <span class="print-only user-email">(nicholasosner@gmail.com)</span>
                </div>
                <a href="#2022-08-24 09:25:08"><div class="time">2022-08-24 09:25:08</div></a>
                <div class="msg">
                    <p>Hi all, I would just like to inform you that I have re-issued the above report - I have since identified errors in my results caused by some config not being shared with all of the servers in my processing pool which resulted in them still using MDV5a when they should have been using MDv5b. The findings remain mostly the same, except that MDv5b actually out-performs MDv5a on our reference dataset by producing fewer false detections for the same recall rate (MDv5b seems to favour a slightly lower threshold in comparison to MDv5a). As such, we will be switching over to MDv5b with a threshold of 0.1 going forward. However, it must be noted that we are really getting into the weeds here - the differences between the two models is pretty minor and the switch over results in an increase in animal-containing-image recall from 99.30% to 99.37%, where the difference is almost entirely down to challenging, low quality images with arguably little value.</p>

<p>The revised report can be found <a href="https://wildeyeconservation.org/megadetector-version-5/">here</a>.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Dan Morris, Sara Beery, Carly Batist, Mitch Fennell, Monty Ammar, Peter van Lunteren, Anton Alvarez
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-14 18:05:57">
            
                <img src="https://secure.gravatar.com/avatar/4247dd9e36bf1ad0ccccb95a7ea75b4b.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Peter Bull
                     <span class="print-only user-email">(peter@drivendata.org)</span>
                </div>
                <a href="#2022-09-14 18:05:57"><div class="time">2022-09-14 18:05:57</div></a>
                <div class="msg">
                    <p>Hi all! Is anyone working on camera trapping projects capturing video in the Northeastern US? We‚Äôre looking to expand our <a href="https://www.zambacloud.com/">Zamba Cloud</a> out-of-the-box models geographically and wanted to talk to folks working on those in that region. If you know of any particular projects with video, let me know.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-14 23:11:44">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-09-14 23:11:44"><div class="time">2022-09-14 23:11:44</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* <a href="https://wildlabs.net/feed">WILDLABS</a> may also be a good place to post üôÇ</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôá Peter Bull
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-18 17:22:11">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-09-18 17:22:11"><div class="time">2022-09-18 17:22:11</div></a>
                <div class="msg">
                    <p>Hi, I've been reviewing the current state of existing platforms and tools for analysing camera trap data (annotating, analysing, classifying etc). I've come across the current plethora of available tools. I have been trying to find the "perfect" platform/tool for my current project which would ideally satisfy the following criteria:</p>

<ol><li>Has a UI for tagging images</li><li>Allows to use object detection to filter out empties (for ex megadetector)</li><li>Allows to edit bounding boxes generated by the detection algorithm (for correction)</li><li>Allows to export the bounding boxes  along with the tagged images (for further model training)</li><li>Is open source (at least the platform, I'm fine if models are proprietary)
Does this platform exist? Do you know of anything that comes close to it? So far, my best candidates would be <a href="https://github.com/WildEyeConservation/TrapTagger">TrapTagger</a>, as well as the <a href="https://github.com/persts/BBoxEE">BBoxEE</a>/<a href="https://github.com/persts/IL2BB">IL2BB</a> toolset. Is there a combination of platform/tools that would achieve the above? Would appreciate any thoughts or help!</li>
</ol>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-18 17:24:52">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-09-18 17:24:52"><div class="time">2022-09-18 17:24:52</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Maybe AIDE? @Benjamin Kellenberger </p>

<p>Though AIDE has some internal model training functionality that you wouldn't need</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Valentin Lucet
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-18 17:31:41">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-18 17:31:41"><div class="time">2022-09-18 17:31:41</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Not OSS AFAIK, but I think meets your other requirements:</p>

<p><a href="https://www.wildid.app/">https://www.wildid.app/</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">wildid.app</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.wildid.app/">WildID</a></div>
                                <div class="link-text">
                                    Camera trap image processing - Online detection and identification of Southern African wildlife species in camera trap images using machine learning software.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://www.wildid.app/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-18 17:34:21">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-09-18 17:34:21"><div class="time">2022-09-18 17:34:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sara Beery I don't know how I didn't find AIDE in my search. On my way to try it out, thanks!
@Dan Morris Thanks as well!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-18 19:08:13">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2361920803907_ad849dc380fc3d3470dc_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Daniel Davila
                     <span class="print-only user-email">(daniel.davila@kitware.com)</span>
                </div>
                <a href="#2022-09-18 19:08:13"><div class="time">2022-09-18 19:08:13</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I'm always hawking it here, but you should check put VIAME. One of my colleagues supports NOAA fisheries with almost this exact same workflow. It's completely FOSS, we're just always looking for new users and use cases. Happy to put you in contact with lead</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-18 19:13:00">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2361920803907_ad849dc380fc3d3470dc_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Daniel Davila
                     <span class="print-only user-email">(daniel.davila@kitware.com)</span>
                </div>
                <a href="#2022-09-18 19:13:00"><div class="time">2022-09-18 19:13:00</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* <a href="https://github.com/VIAME/VIAME">https://github.com/VIAME/VIAME</a></p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">VIAME/VIAME</a></div>
                                <div class="link-text">
                                    Video and Image Analytics for Multiple Environments
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Website</div>
                                        &lt;http://www.viametoolkit.org/&gt;
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        187
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-18 20:48:23">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-09-18 20:48:23"><div class="time">2022-09-18 20:48:23</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Daniel Davila This tool is amazing, it might be my silver bullet!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Daniel Davila
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-19 04:59:59">
            
                <img src="https://avatars.slack-edge.com/2022-02-09/3075038202214_f9ee2a2a94dcc3815f28_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Peter van Lunteren
                     <span class="print-only user-email">(contact@pvanlunteren.com)</span>
                </div>
                <a href="#2022-09-19 04:59:59"><div class="time">2022-09-19 04:59:59</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Valentin, seems like <a href="https://github.com/PetervanLunteren/EcoAssist">https://github.com/PetervanLunteren/EcoAssist</a> might also suit your needs. </p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">PetervanLunteren/EcoAssist</a></div>
                                <div class="link-text">
                                    An application for detecting animals in camera trap images
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        13
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        Python
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Valentin Lucet
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-19 07:45:32">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-09-19 07:45:32"><div class="time">2022-09-19 07:45:32</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Peter van Lunteren This looks great, I'd be happy to be a test user for Linux</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Peter van Lunteren
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-19 16:35:26">
            
                <img src="https://avatars.slack-edge.com/2022-09-14/4085609422212_0be35bb86f58e99d445f_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Bunsen
                     <span class="print-only user-email">(notbot@gmail.com)</span>
                </div>
                <a href="#2022-09-19 16:35:26"><div class="time">2022-09-19 16:35:26</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks for spending time to review all of the projects out there! We are working on an app for reviewing images from light-based moth traps. But it would be ideal to not reinvent the wheel. Here are a couple other relevant open source desktop apps I have come across. These don't have integrated ML (yet), but have more mature graphical interfaces for reviewing and annotating -- which I find to be the more time consuming part to develop.</p>

<p>Timelapse Image Analyzer
<a href="https://saul.cpsc.ucalgary.ca/timelapse/">https://saul.cpsc.ucalgary.ca/timelapse/</a></p>

<p>Naturtag
<a href="https://github.com/pyinat/naturtag">https://github.com/pyinat/naturtag</a></p>

<p>The MegaDector readme has a longer list of web-based platforms here as well:
<a href="https://github.com/microsoft/CameraTraps/blob/main/megadetector.md#is-there-a-gui">https://github.com/microsoft/CameraTraps/blob/main/megadetector.md#is-there-a-gui</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-19 16:46:27">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-19 16:46:27"><div class="time">2022-09-19 16:46:27</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* If we relax the constraint of editing bounding boxes and ask the more general question "what tools do people use to review camera trap images?", I try to keep updated lists of ML-accelerated tools:</p>

<p><a href="https://agentmorris.github.io/camera-trap-ml-survey/#camera-trap-platforms-using-ml-or-at-least-thinking-about-ml">https://agentmorris.github.io/camera-trap-ml-survey/#camera-trap-platforms-using-ml-or-at-least-thinking-about-ml</a></p>

<p>...and non-ML-accelerated tools:</p>

<p><a href="https://agentmorris.github.io/camera-trap-ml-survey/#manual-labeling-tools-people-use-for-camera-traps">https://agentmorris.github.io/camera-trap-ml-survey/#manual-labeling-tools-people-use-for-camera-traps</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Michael Bunsen, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-19 20:59:42">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-09-19 20:59:42"><div class="time">2022-09-19 20:59:42</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Michael Bunsen Timelapse has the drawback of not working on Linux AFAIK. Didnt know about Naturtag, thanks!
And as always thanks @Dan Morris for curating this amazing page. It was indeed my starting point in my search.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Michael Bunsen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-20 14:03:32">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-20 14:03:32"><div class="time">2022-09-20 14:03:32</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* After reading this thread, I made a <strong>very</strong> half-hearted effort to run Timelapse on Linux via WINE.  I think I got... 70% of the way there?  I saw an actual functioning Timelapse window, but then got a stream of incomprehensible .net errors, which seems to be par for the course if you don't know WINE, which I don't.  But Timelapse is just a well-behaved .net application, and <strong>Photoshop</strong> runs in WINE, so I know there's a way.  If there are any WINE experts lurking on this Slack and looking for a project...</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ÄºÔ∏è Michael Bunsen, Valentin Lucet, Anton Alvarez
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-20 14:10:45">
            
                <img src="https://avatars.slack-edge.com/2022-09-14/4085609422212_0be35bb86f58e99d445f_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Bunsen
                     <span class="print-only user-email">(notbot@gmail.com)</span>
                </div>
                <a href="#2022-09-20 14:10:45"><div class="time">2022-09-20 14:10:45</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks for giving that a try @Dan Morris! The <a href="https://forum.winehq.org/viewforum.php?f=8">Wine HQ forum</a> still looks active if you want to give that a try. Otherwise I'd like to get to know Timelapse better, the features that folks like, and then contribute to porting those to another cross-platform app.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-20 19:50:52">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-09-20 19:50:52"><div class="time">2022-09-20 19:50:52</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris I was wondering, Is there a step-by-step guide on how to deploy the Megadetector batch API on a virtual machine? The readme of the batch API assumes a little more knowledge than I have</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-20 20:24:08">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-20 20:24:08"><div class="time">2022-09-20 20:24:08</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Valentin Lucet No, sorry, there's not a step-by-step guide.  We never documented it to the degree that we document the standard script-based approach to running MD, since it was meant for a relatively small number of deployments that were either internal to Microsoft or internal to collaborators working closely with us (when Siyu and I were at Microsoft).</p>

<p>But... more often than not, the batch API is overkill, and any time you spin up lots of GPUs, you are taking on a high risk of accidental overspend, and you have to really be on top of things to make sure you're not firing off dozens of expensive jobs left and right... what do you anticipate your daily image load will be?  If you're not turning around tens of millions of images per day, it's likely far easier to do everything on a single VM, which will get you close to 1M images per day with MDv5 (assuming a V100 GPU).  That's a lot of images!</p>

<p>It's also very Azure-specific (unlike the real-time API, which is quite generic)... are you working on Azure?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-20 20:48:58">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-09-20 20:48:58"><div class="time">2022-09-20 20:48:58</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris Oh np, yes it would definitely be an overkill, I see I misjudged the use case. We have an initial need to process 2-3TB of images before the end of the year.
I was starting to consider the implications of using Azure for our project... But what would be much easier for us would be run MD on a Linux VM of the type described <a href="https://docs.alliancecan.ca/wiki/Cloud_RAS_Allocations">here</a> (with vGPUs).</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-20 21:53:21">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-20 21:53:21"><div class="time">2022-09-20 21:53:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Indeed, IMO that falls into the category of "more than you want to do on a laptop without a GPU, but easy to churn through on a single machine anywhere you can get a decent GPU".  If you're on Azure, assuming that's around 2M-3M images, that's probably ~3-4 days on a V100 GPU.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Valentin Lucet, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-12-05 23:42:04">
            
                <img src="https://avatars.slack-edge.com/2022-09-14/4085609422212_0be35bb86f58e99d445f_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Bunsen
                     <span class="print-only user-email">(notbot@gmail.com)</span>
                </div>
                <a href="#2022-12-05 23:42:04"><div class="time">2022-12-05 23:42:04</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi @Valentin Lucet, I'm curious if VIAME or any of the software you discovered ended up working for.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-12-14 09:09:22">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-12-14 09:09:22"><div class="time">2022-12-14 09:09:22</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Michael Bunsen we went with Label Studio and overall it's going okay but I'm not sure I would recommend it. It seemed the best for our use case (CVAT looks good too but I had lots of issues setting this one up) but I dont think its great. I dont believe there is a solution that tick all thoses boxes and is also not too complicated to set up.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-12-14 09:11:14">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-12-14 09:11:14"><div class="time">2022-12-14 09:11:14</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* we also ran MD on our own</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-12-14 16:24:50">
            
                <img src="https://avatars.slack-edge.com/2022-09-14/4085609422212_0be35bb86f58e99d445f_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Bunsen
                     <span class="print-only user-email">(notbot@gmail.com)</span>
                </div>
                <a href="#2022-12-14 16:24:50"><div class="time">2022-12-14 16:24:50</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks for the update @Valentin Lucet! I may give Label Studio a try and customize it for our use case. I like the tech stack they are using. Which aspects is it missing?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-22 05:20:58">
            
                <img src="https://avatars.slack-edge.com/2022-10-21/4258571981060_1941d7130f7b94e11bc9_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Valentin »òtefan
                     <span class="print-only user-email">(valentin.stefan.vst@gmail.com)</span>
                </div>
                <a href="#2022-09-22 05:20:58"><div class="time">2022-09-22 05:20:58</div></a>
                <div class="msg">
                    <p><strong>Hi, we are interested in camera traps for monitoring plant-insect interactions.</strong> 
<strong>Is anybody else here doing this and what hardware &amp; pipelines do you use?</strong> We plan to order such equipment for the next season.</p>

<p>We need <strong>a camera trap capable of having a sensitive trigger for insects</strong> (small object detection on cluttered/noisy backgrounds). Otherwise, we produce terabytes of images with no insect which comes with a lot of logistic challenges (data storage, transfer, handling, annotating, etc).
Also, to get a decent image of a pollinator so that we can identify it to the lowest taxa level possible, more important than image resolution is to have a <strong>good optical zoom</strong> or get closer to the flowers with the camera which we noticed that can scare some insects.
Can endure <strong>outdoor conditions</strong> under direct sun and scorching temperatures (maybe this can be solved with special casing, coolers, heat sinks, etc).
<strong>Can be moved easily</strong> from flower to flower in the field and has a <strong>low energy consumption</strong>.
Offers <strong>visual feedback when mounting it</strong> on top of a flower so that we can focus it properly on the target flower.</p>

<p>We explored with affordable mobile phones so far and got decent images and we currently test YOLOv5 &amp; v7 on the annotated dataset. However the phones have their limitations, especially when used for long hours under direct sun.</p>

<p>Not sure if edge detection would work at the moment due to the higher demand on computational power and on energy consumption (which increases easily the costs and some nano GPUs are mostly out of stock anyways). Plus I do not have currently the skills to assemble one, though I yet have to try üôÇ . However, possibly there is hardware out there to satisfy all these constraints and I would like to find out more.</p>

<p>To spark a conversation about this, here are some fascinating papers that propose camera systems for monitoring plant-insect interactions:</p><ul><li>Droissart 2021 - PICT: A low-cost, modular, open-source camera trap system to study plant‚Äìinsect <strong><a href="https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13618">https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13618</a></strong></li><li>Ratnayake, M. N., Dyer, A. G., &amp; Dorin, A. (2021). Tracking individual honeybees among wildflower clusters with computer vision-facilitated pollinator monitoring. Plos One, 16(2), e0239504.</li><li>Bjerge, K., Mann, H. M. R., &amp; H√∏ye, T. T. (2022). Real‚Äêtime insect tracking and monitoring with computer vision and deep learning. Remote Sensing in Ecology and Conservation, 8(3), 315‚Äì327. <strong><a href="https://doi.org/10.1002/rse2.245">https://doi.org/10.1002/rse2.245</a></strong>
-Naqvi 2022 - Camera traps are an effective tool for monitoring insect‚Äìplant interactions <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/ece3.8962">https://onlinelibrary.wiley.com/doi/pdf/10.1002/ece3.8962</a></li>
</ul>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-22 13:07:50">
            
                <img src="https://avatars.slack-edge.com/2022-09-14/4085609422212_0be35bb86f58e99d445f_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Bunsen
                     <span class="print-only user-email">(notbot@gmail.com)</span>
                </div>
                <a href="#2022-09-22 13:07:50"><div class="time">2022-09-22 13:07:50</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Valentin, thanks for sparking the conversation. I am working on an insect monitoring project, partly in collaboration with Kim Bjerge from the 2nd paper you cited. Our current project is focused on machine learning for moth monitoring using images captured by the Easy RIDER system. I see you already found our discussion thread on Wildlabs!
<a href="https://wildlabs.net/groups/autonomous-camera-traps-insects">https://wildlabs.net/groups/autonomous-camera-traps-insects</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">wildlabs.net</div>
                            
                            
                                
                                <div class="link-title"><a href="https://wildlabs.net/groups/autonomous-camera-traps-insects">Autonomous Camera Traps for Insects | WILDLABS</a></div>
                                <div class="link-text">
                                    Camera trapping for insects is becoming a reality using advances in camera, AI, and autonomous systems technologies. This group discusses the latest advances, shares experiences, and offers a space for anyone interested in the technology, from beginners to experts.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://wildlabs.net/groups/autonomous-camera-traps-insects</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç D√©va Sou
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-22 13:09:38">
            
                <img src="https://avatars.slack-edge.com/2022-09-14/4085609422212_0be35bb86f58e99d445f_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Bunsen
                     <span class="print-only user-email">(notbot@gmail.com)</span>
                </div>
                <a href="#2022-09-22 13:09:38"><div class="time">2022-09-22 13:09:38</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thank you for finding those other recent papers. I am curious to know more details about your mobile phone setup. I am experimenting with my own versions of that for all pollinators as well. Did you write a custom app for running YOLO on a phone? How may frames per second roughly are you able to process?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-22 13:58:08">
            
                <img src="https://avatars.slack-edge.com/2022-10-21/4258571981060_1941d7130f7b94e11bc9_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin »òtefan
                     <span class="print-only user-email">(valentin.stefan.vst@gmail.com)</span>
                </div>
                <a href="#2022-09-22 13:58:08"><div class="time">2022-09-22 13:58:08</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi @Michael Bunsen, we do not run any edge AI on the phones. They just act as a camera and try to capture one image every second. You can imagine that this produces a lot of images without insects. Therefore, I am curious if someone has developed already some affordable custom camera system that we could use. I also tried to attach some more powerful lenses to the phones to gain optical zoom, but the tests were not that successful, though there is potential. The biggest issue is to have a trigger sensitive to small objects like insects landing on the target flower and can run without the need of a nano GPU (which are almost impossible to order at the moment).</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-30 04:35:46">
            
                <img src="https://secure.gravatar.com/avatar/2f03555318868fb909a1357a357ae705.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0003-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sachith Seneviratne
                     <span class="print-only user-email">(sachith.seneviratne@unimelb.edu.au)</span>
                </div>
                <a href="#2022-09-30 04:35:46"><div class="time">2022-09-30 04:35:46</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I told @Malika Nisal Ratnayake about this slack, I think he's in the main channel. He may have some thoughts.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Malika Nisal Ratnayake
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-30 04:58:10">
            
                <img src="https://avatars.slack-edge.com/2022-09-28/4147698391524_eddca7c1f87aa1bb46ab_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Malika Nisal Ratnayake
                     <span class="print-only user-email">(Malika.Ratnayake@monash.edu)</span>
                </div>
                <a href="#2022-09-30 04:58:10"><div class="time">2022-09-30 04:58:10</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sachith Seneviratne, thank you very much. These days both I and @Valentin »òtefan are working together on this problem (image capturing and species classification) at iDiv.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-30 05:04:42">
            
                <img src="https://secure.gravatar.com/avatar/2f03555318868fb909a1357a357ae705.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0003-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sachith Seneviratne
                     <span class="print-only user-email">(sachith.seneviratne@unimelb.edu.au)</span>
                </div>
                <a href="#2022-09-30 05:04:42"><div class="time">2022-09-30 05:04:42</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Ah I see, wasn't aware, just saw your name on the first message üôÇ</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Malika Nisal Ratnayake
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-30 15:35:25">
            
                <img src="https://avatars.slack-edge.com/2022-09-14/4085609422212_0be35bb86f58e99d445f_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Bunsen
                     <span class="print-only user-email">(notbot@gmail.com)</span>
                </div>
                <a href="#2022-09-30 15:35:25"><div class="time">2022-09-30 15:35:25</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks for describing what you have tried @Valentin »òtefan. I think finding the right camera and/or lens will be a good collective challenge. We have the camera pointed at a flat insect sheet and the motion detection works okay for that (although still produces more images than needed). When pointed at pollinator plants the motion picks up spiders (and lots of wind movement!) but doesn't get triggered on most insects. Close focus is a an issue too.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Malika Nisal Ratnayake, Valentin »òtefan
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-04 16:28:31">
            
                <img src="https://avatars.slack-edge.com/2022-10-21/4258571981060_1941d7130f7b94e11bc9_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin »òtefan
                     <span class="print-only user-email">(valentin.stefan.vst@gmail.com)</span>
                </div>
                <a href="#2022-10-04 16:28:31"><div class="time">2022-10-04 16:28:31</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I guess natural flower backgrounds, with wind movements, insects that do not trigger usual IR sensors of wildlife camera traps, insects that are generally tiny and also can vary a lot in dimensions (think of small pollinator flies vs large butterflies) gather to form a complex challenge. Also what works in the arctic conditions where flowers are small and in patches, doesn't work well in temperate regions (imagine a grassland with diverse flowers, of diverse heights and dimensions, especially towards eastern Europe). This year we had plants of almost 2 m height and the flowers were on top. We had to fix the phones on high tripods fixed on some boxes üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-05 12:07:33">
            
                <img src="https://avatars.slack-edge.com/2022-10-21/4258571981060_1941d7130f7b94e11bc9_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin »òtefan
                     <span class="print-only user-email">(valentin.stefan.vst@gmail.com)</span>
                </div>
                <a href="#2022-10-05 12:07:33"><div class="time">2022-10-05 12:07:33</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Otto Brookes, you wrote me an email suggesting to place the issues in the &lt;#C044MCWL1HP|camtrapai-workshops> channel, but we already started a conversation here. Not sure how to proceed now. I think that this channel is more suitable for this thread since is about camera traps in general. There is also an identical thread initiated by Tom August on Wildlabs here: <a href="https://www.wildlabs.net/discussion/cameras-pros-and-cons">https://www.wildlabs.net/discussion/cameras-pros-and-cons</a>
Currently I am really impressed by the hardware presented by @Maximilian Sittinger in that thread (The OAK models produced by Luxonis in particular).
A very interesting overview of microcomputers that can be used for our purposes is offered at this link by Q-engineering: <a href="https://qengineering.eu/deep-learning-with-raspberry-pi-and-alternatives.html">https://qengineering.eu/deep-learning-with-raspberry-pi-and-alternatives.html</a> (OAK is included there as well).</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">wildlabs.net</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.wildlabs.net/discussion/cameras-pros-and-cons">Cameras - pros and cons | WILDLABS</a></div>
                                <div class="link-text">
                                    So, what makes a good camera for an autonomous camera trap for insects?We use a web camera in our system, which seems to work well a lot of the time, it produces a high resolution image and is fairly cheap to buy but we sometimes have issues with white balance and &lt;a href=&#34;http://focus.It&#34;&gt;focus.It&lt;/a&gt; seems as though the systems being developed use a range of different cameras, so I wonder if we collated out knowledge we could help to identify the best cameras on the market for our needsI would say the key criteria are:High resolution (without going overboard)CheapLow powerGood interface for a Raspberry Pi or similarGood white balanceReliable auto focusAnd what about processing on the edge? I was recently introduced to these cameras which look super compact, and they can do image processing (e.g. detection), on the camera itself!
                                </div>
                                
                                
    
        <a href="https://www.wildlabs.net/discussion/cameras-pros-and-cons">
            <img class="preview" src="https://wildlabs.net/sites/default/files/styles/feature_full/public/square-wildlabs-logo.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.wildlabs.net/discussion/cameras-pros-and-cons</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">qengineering.eu</div>
                            
                            
                                
                                <div class="link-title"><a href="https://qengineering.eu/deep-learning-with-raspberry-pi-and-alternatives.html">Deep learning with Raspberry Pi and alternatives in 2022 - Q-engineering</a></div>
                                <div class="link-text">
                                    Deep learning with Raspberry Pi and alternatives like Jetson Nano, Google Coral and Intel Neural Stick investigated in depth.
                                </div>
                                
                                
    
        <a href="https://qengineering.eu/deep-learning-with-raspberry-pi-and-alternatives.html">
            <img class="preview" src="https://qengineering.eu/favImage.png"
                width="250"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://qengineering.eu/deep-learning-with-raspberry-pi-and-alternatives.html</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-05 16:14:21">
            
                <img src="https://secure.gravatar.com/avatar/25105e7305cb76431df43c3b67fcd8df.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0010-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ross Gardiner
                     <span class="print-only user-email">(ross.gardiner@dynaikon.com)</span>
                </div>
                <a href="#2022-10-05 16:14:21"><div class="time">2022-10-05 16:14:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi!
I look after an open-sourced AI camera trap project based on Raspberry Pi. We call it DynAikonTrap: <a href="https://dynaikon.com/trap/">https://dynaikon.com/trap/</a>
We use a motion trigger based on the vectors created from H264 encoding, suitable for small and fast-moving things without the use of PIR. An insect CNN model could also be easily trained and fit into our detection pipelines. I'm very interested to try out DynAikonTrap for insect detection. Give me an email if you'd like to collab: <a href="mailto:ross.gardiner@dynaikon.com">ross.gardiner@dynaikon.com</a>
We also have one published paper and two masters theses outlining details of our design: <a href="https://dynaikon.com/trap-docs/about.html">https://dynaikon.com/trap-docs/about.html</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-26 11:10:43">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-09-26 11:10:43"><div class="time">2022-09-26 11:10:43</div></a>
                <div class="msg">
                    <p>Hey all!! I'm looking for images where MDv5 fails (requested by a friend who is teaching a course and wants to show failure cases)</p>

<p>If you have any, can you send them in this thread?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-26 11:11:27">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-09-26 11:11:27"><div class="time">2022-09-26 11:11:27</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris @Nicholas Osner</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-26 11:39:32">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-26 11:39:32"><div class="time">2022-09-26 11:39:32</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I've mentioned the egregious, bizarre Snapshot Serengeti failures:</p>

<p><a href="https://github.com/ultralytics/yolov5/issues/9294">https://github.com/ultralytics/yolov5/issues/9294</a></p>

<p>This is closer to a singularity than an out-of-domain issue.  Basically this is what MDv5 does when you run it in the Upside-Down.  And some cameras from early seasons of Snapshot Serengeti appear to be the Upside-Down.  Still a good example, if the general theme is "machine learning can be unpredictable, so always verify on your own data".</p>

<p>Other than Snapshot Serengeti, 99% of failures I've seen fall into more expected, edge-of-the-supported-domain categories:</p>

<p>‚Ä¢ Reptiles (especially snakes)
‚Ä¢ Very very far away mammals (particularly prevalent in tundra surveys)
I don't have any of those that are publicly available, but depending on responses you get on this thread, I could reach out to the owners and ask if they can share a couple of images.</p>

<p>That's not to say those are the only failures, there are definitely just random misses on in-domain animals (@Nicholas Osner has a miss on a honey badger that will drive you crazy).  But those edge-of-domain examples are the ones I see most.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Mitch Fennell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-26 11:54:05">
            
                <img src="https://avatars.slack-edge.com/2020-05-08/1113686950322_c0e1ac2180c634f2b474_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Suzanne Stathatos
                     <span class="print-only user-email">(suzanne.stathatos@gmail.com)</span>
                </div>
                <a href="#2022-09-26 11:54:05"><div class="time">2022-09-26 11:54:05</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* might be a silly question, but are MDv5 (?) and MD5 (the hashing algorithm) the same thing?</p>

<p>also, love the Upside-Down reference üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-26 11:55:35">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-26 11:55:35"><div class="time">2022-09-26 11:55:35</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Sorry, MDv5 refers to MegaDetector version 5:</p>

<p><a href="https://github.com/microsoft/CameraTraps/releases/tag/v5.0">https://github.com/microsoft/CameraTraps/releases/tag/v5.0</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-26 11:56:05">
            
                <img src="https://avatars.slack-edge.com/2020-05-08/1113686950322_c0e1ac2180c634f2b474_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Suzanne Stathatos
                     <span class="print-only user-email">(suzanne.stathatos@gmail.com)</span>
                </div>
                <a href="#2022-09-26 11:56:05"><div class="time">2022-09-26 11:56:05</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* ah got it - thank you!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-27 10:04:10">
            
                <img src="https://avatars.slack-edge.com/2022-05-05/3483237601330_048808caf564d5089c7c_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Nicholas Osner
                     <span class="print-only user-email">(nicholasosner@gmail.com)</span>
                </div>
                <a href="#2022-09-27 10:04:10"><div class="time">2022-09-27 10:04:10</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Sara, I do have some nice examples of where MDv5 fails. I am just awaiting permission from the data owners.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-27 20:43:58">
            
                <img src="https://secure.gravatar.com/avatar/89cbe0fc12b2cc92d129f14b0a5f665e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mathias Tobler
                     <span class="print-only user-email">(matobler@gmx.net)</span>
                </div>
                <a href="#2022-09-27 20:43:58"><div class="time">2022-09-27 20:43:58</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sara Beery are you looking for false positives or false negatives? Can probably find some false positives.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-27 20:46:59">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-09-27 20:46:59"><div class="time">2022-09-27 20:46:59</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Both!!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-28 07:25:49">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-09-28 07:25:49"><div class="time">2022-09-28 07:25:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sara Beery I don't know if that counts.. but just came across this on twitter <a href="https://twitter.com/matbourbonnais/status/1574870630746722304?t=fJCFHtekIQ5pFGphgl97yA&amp;s=19|https://twitter.com/matbourbonnais/status/1574870630746722304?t=fJCFHtekIQ5pFGphgl97yA&amp;s=19">https://twitter.com/matbourbonnais/status/1574870630746722304?t=fJCFHtekIQ5pFGphgl97yA&amp;s=19|https://twitter.com/matbourbonnais/status/1574870630746722304?t=fJCFHtekIQ5pFGphgl97yA&amp;s=19</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">twitter</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="https://pbs.twimg.com/profile_images/1100226245801852928/pNwMy9TM_normal.jpg" class="icon">
                                    }
                                    <a href="https://twitter.com/matbourbonnais/status/1574870630746722304">
                                    Mathieu Bourbonnais
                                    </a><span class="print-only">(https://twitter.com/matbourbonnais/status/1574870630746722304)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href=""></a></div>
                                <div class="link-text">
                                    Bear is such a chonker &lt;b&gt;#megadetector&lt;/b&gt; thinks it‚Äôs two bears! &lt;a href=&#34;https://twitter.com/ShaneyShaneface&#34;&gt;@ShaneyShaneface&lt;/a&gt;
                                </div>
                                
                                
    
        <a href="https://twitter.com/matbourbonnais/status/1574870630746722304?t=fJCFHtekIQ5pFGphgl97yA&amp;amp;s=19">
            <img class="preview" src="https://pbs.twimg.com/media/FdsQfU5aEAAvJEk.jpg"
                width="900"
                 height="1200" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://twitter.com/matbourbonnais/status/1574870630746722304?t=fJCFHtekIQ5pFGphgl97yA&amp;amp;s=19</div>
                                
                                
                                    <div class="attachment-footer">
                                        <img src="https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png" class="icon" />
                                        Twitter
                                    </div>
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        :bearid: Dan Morris, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-28 12:15:14">
            
                <img src="https://secure.gravatar.com/avatar/89cbe0fc12b2cc92d129f14b0a5f665e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mathias Tobler
                     <span class="print-only user-email">(matobler@gmx.net)</span>
                </div>
                <a href="#2022-09-28 12:15:14"><div class="time">2022-09-28 12:15:14</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sara Beery Here you  go. A selection of false positives. Wonder what confidence people use. I found that with MDv5 one has to go pretty low to avoid false negatives, 0.1 or 0.2. I would rather have a small percentage of FP than having FN, which would require sorting through 100s of thousands of empty images. <a href="https://1drv.ms/u/s!Amz2mMAWHLF_5QDqzSppU0CYd37d?e=YVocmC">https://1drv.ms/u/s!Amz2mMAWHLF_5QDqzSppU0CYd37d?e=YVocmC</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-28 13:08:06">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-28 13:08:06"><div class="time">2022-09-28 13:08:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Good point, I realize that I don't even think of "false positives" as "failure", but there is definitely a false positive rate that can reasonably be called a "failure".  I don't see that a lot, but I'm still running MDv5 on all of LILA, and I think there is at least one Snapshot Safari camera that "fails" by this metric.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-28 13:08:36">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-28 13:08:36"><div class="time">2022-09-28 13:08:36</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hoping to release those results in a few weeks.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-28 13:11:39">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-09-28 13:11:39"><div class="time">2022-09-28 13:11:39</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Does it "fail" if you use that simple box-location-based filtering as a postprocessing step?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-28 13:12:27">
            
                <img src="https://secure.gravatar.com/avatar/89cbe0fc12b2cc92d129f14b0a5f665e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mathias Tobler
                     <span class="print-only user-email">(matobler@gmx.net)</span>
                </div>
                <a href="#2022-09-28 13:12:27"><div class="time">2022-09-28 13:12:27</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I don't have exact number, but we see FP rates of 1-2%, which means several 1000 images that need to be manually changed to Empty. Not a bit deal given that there are 100s of thousands of TN. We had some datasets from Kenya where MD (v4 at the time) regularly picked up rocks as animals in some cameras, that was an issue. We will check those again with MDv5.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-28 13:15:03">
            
                <img src="https://secure.gravatar.com/avatar/89cbe0fc12b2cc92d129f14b0a5f665e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mathias Tobler
                     <span class="print-only user-email">(matobler@gmx.net)</span>
                </div>
                <a href="#2022-09-28 13:15:03"><div class="time">2022-09-28 13:15:03</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sara Beery We have not implemented box location based filtering, but in the examples I sent you the box is no always consistent. Might need to look at box location filtering again at some point.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-28 13:17:09">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-28 13:17:09"><div class="time">2022-09-28 13:17:09</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* FWIW I would consider a FP rate of 1-2% a wild success. üôÇ. I.e., if you see much less than that, IMO you may be cutting it too close, assuming essentially zero tolerance for FNs.</p>

<p>@Sara Beery for this particular Snapshot Safari camera that I'm referring to, yes, I'm about 99% sure that the typical repeat detection elimination procedure would clean this up without issue.  @Mathias Tobler when we do this, we don't require boxes to overlap <strong>exactly</strong>, but we set a pretty high IoU threshold to consider two boxes the same:</p>

<p><a href="https://github.com/microsoft/CameraTraps/blob/main/api/batch_processing/postprocessing/repeat_detection_elimination/README.md">https://github.com/microsoft/CameraTraps/blob/main/api/batch_processing/postprocessing/repeat_detection_elimination/README.md</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-28 13:18:03">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-28 13:18:03"><div class="time">2022-09-28 13:18:03</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* But it's not perfect, and in particular it can treat sleeping animals as repeat detections, so we always treat it as a very fast but still only semi-automated process.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-28 13:19:40">
            
                <img src="https://secure.gravatar.com/avatar/89cbe0fc12b2cc92d129f14b0a5f665e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mathias Tobler
                     <span class="print-only user-email">(matobler@gmx.net)</span>
                </div>
                <a href="#2022-09-28 13:19:40"><div class="time">2022-09-28 13:19:40</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris I totally agree, 1-2% is a huge success! The performance of MD is amazing! Will take a look at the box post-processing if we find this still to be an issue with MDv5.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-30 14:48:46">
            
                <img src="https://avatars.slack-edge.com/2022-09-28/4142433643413_b5452bb1c2005207da50_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Jeff Reed
                     <span class="print-only user-email">(jeff@reedfly.com)</span>
                </div>
                <a href="#2022-09-30 14:48:46"><div class="time">2022-09-30 14:48:46</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sara Beery We're using camera traps for research on increased recreational use (people in boats) on rivers in Montana. Camera traps are labor intensive on waterways, as everyone knows, due to reflectance false positives. Our longer term solution is a PIR AI model we use in our own camera traps. In the meantime, we use MD to get rid of empty images. I've noticed that boats get classified as vehicles as an example of a false positive (boxed version is mdv5). Not a big deal for us, but an example nonetheless.</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-30 15:17:24">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-30 15:17:24"><div class="time">2022-09-30 15:17:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* FYI boats were not part of the "vehicle" class for MDv4, but they are for MDv5, so I would argue that image is a slight false <strong>negative</strong> (re: the trailing smaller rafts), depending on the threshold you're using.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-30 15:52:06">
            
                <img src="https://avatars.slack-edge.com/2022-09-28/4142433643413_b5452bb1c2005207da50_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Jeff Reed
                     <span class="print-only user-email">(jeff@reedfly.com)</span>
                </div>
                <a href="#2022-09-30 15:52:06"><div class="time">2022-09-30 15:52:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Good point Dan...I didn't know that boats are now vehicles in MDv5...so I guess the trailer tubes would be a false negative example...thanks for all of your work. On a positive note, lots of true positives from MD and elimination of a ton of empty frames, cattle walking by, and the occasional bird...since we have to run these camera traps in 1 minute time lapse intervals (at 15 locations for 5 months out of the year). Whew! You saved us a lot of time. But I'm still hopeful for our Smart Trigger which will decrease labor significantly.</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-28 13:01:20">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-09-28 13:01:20"><div class="time">2022-09-28 13:01:20</div></a>
                <div class="msg">
                    <p><a href="https://twitter.com/conservationx/status/1575166560922374144?s=20&amp;t=Nk5lOX69MhcpALGRcMMyHg">https://twitter.com/conservationx/status/1575166560922374144?s=20&amp;t=Nk5lOX69MhcpALGRcMMyHg</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">twitter</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="https://pbs.twimg.com/profile_images/1284166601642835968/M2itiV4w_normal.jpg" class="icon">
                                    }
                                    <a href="https://twitter.com/conservationx/status/1575166560922374144">
                                    Conservation X Labs
                                    </a><span class="print-only">(https://twitter.com/conservationx/status/1575166560922374144)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href=""></a></div>
                                <div class="link-text">
                                    &#34;Nature conservation is one of the biggest drivers of AI.&#34;
&lt;a href=&#34;https://twitter.com/EdgeImpulse&#34;&gt;@EdgeImpulse&lt;/a&gt; just announced a new product in collaboration with Conservation X Labs: an AI-powered camera for conservation &amp;amp; field research! #2022Imagine
                                </div>
                                
                                
    
        <a href="https://twitter.com/conservationx/status/1575166560922374144?s=20&amp;amp;t=Nk5lOX69MhcpALGRcMMyHg">
            <img class="preview" src="https://pbs.twimg.com/media/FdwdohSWIAYxTUp.jpg"
                width="1200"
                 height="672" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://twitter.com/conservationx/status/1575166560922374144?s=20&amp;amp;t=Nk5lOX69MhcpALGRcMMyHg</div>
                                
                                
                                    <div class="attachment-footer">
                                        <img src="https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png" class="icon" />
                                        Twitter
                                    </div>
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Jon Van Oast, Sara Beery, Kakani Katija, Timm Haucke, Lucia Gordon, Henrik Cox (Sentinel), Sam Kelly, Ed Miller, Dan Morris
                        </div>
                    
                        <div class="message-reaction">
                        üëç Rowan Converse
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2022-09-30 04:35:51">
            
                <img src="https://avatars.slack-edge.com/2022-09-28/4147698391524_eddca7c1f87aa1bb46ab_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Malika Nisal Ratnayake
                     <span class="print-only user-email">(Malika.Ratnayake@monash.edu)</span>
                </div>
                <a href="#2022-09-30 04:35:51"><div class="time">2022-09-30 04:35:51</div></a>
                <div class="msg">
                    <p>@Malika Nisal Ratnayake has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-03 13:54:37">
            
                <img src="https://avatars.slack-edge.com/2020-08-03/1284586180260_ce5ba282733f34b0aeba_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sam Kelly
                     <span class="print-only user-email">(sam@conservationxlabs.org)</span>
                </div>
                <a href="#2022-10-03 13:54:37"><div class="time">2022-10-03 13:54:37</div></a>
                <div class="msg">
                    <p>Hi All! I'm at Conservation X Labs and will be working with Edge Impulse to bring the nature camera to conservationists (alongside several partners). I know I'm not the most active in this community, but super happy to field any questions/comments here or via email <a href="mailto:sam@conservationxlabs.org">sam@conservationxlabs.org</a>!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Stephanie O&#39;Donnell, David Will, Dan Morris, Carly Batist, Lucia Gordon, Henrik Cox (Sentinel), Dhruv Sheth, Valentin »òtefan
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Jon Van Oast, Sara Beery, Michael Procko, Henrik Cox (Sentinel), Dhruv Sheth
                        </div>
                    
                        <div class="message-reaction">
                        üëç Dante Wasmuht, Mitch Fennell, Ed Miller, Thijs, Jeff Reed, Valentin »òtefan, Henrik Cox (Sentinel), Dhruv Sheth
                        </div>
                    
                        <div class="message-reaction">
                        üôè Michael Bunsen, Dhruv Sheth
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-15 18:44:47">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-10-15 18:44:47"><div class="time">2022-10-15 18:44:47</div></a>
                <div class="msg">
                    <p>Some folks have asked whether MD results are available for LILA datasets; they are now:</p>

<p><a href="https://lila.science/megadetector-results-for-camera-trap-datasets/">https://lila.science/megadetector-results-for-camera-trap-datasets/</a></p>

<p>(For everything except Snapshot Serengeti, which is still pending investigation of the issue discussed elsewhere in this channel.)</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Sara Beery, Valentin Lucet, Henrik Cox (Sentinel), Fagner Cunha, Timm Haucke, Mitch Fennell
                        </div>
                    
                        <div class="message-reaction">
                        üôå:skin_tone_2: Manish Rai
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-28 11:11:08">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-10-28 11:11:08"><div class="time">2022-10-28 11:11:08</div></a>
                <div class="msg">
                    <p>Anyone working on Reconyx camera trap with temperature sensors? I can't seen to be able to extract the temperature metadata from images (the EXIF tag dont carry it). Is there another metadata format stored in the images beyond Exif?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-28 13:51:43">
            
                <img src="https://avatars.slack-edge.com/2022-08-31/4012229393526_dfb97e82305b3683f037_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Procko
                     <span class="print-only user-email">(xprockox@gmail.com)</span>
                </div>
                <a href="#2022-10-28 13:51:43"><div class="time">2022-10-28 13:51:43</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* The EXIF data should store this... are you seeing a temperature reading in the frame around your images? I believe it should be in the top right corner. e.g.:</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëç Valentin Lucet
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-28 19:51:18">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-10-28 19:51:18"><div class="time">2022-10-28 19:51:18</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I'm about 97% sure this is stored in the EXIF "makernotes" field for Reconyx cameras, as fields called "Ambient Temperature" and "Ambient Temperature Farenheit".  exiftool (<a href="https://exiftool.org/">https://exiftool.org/</a>) knows about lots of binary makernotes fields, so if you run exiftool my_image.jpg, it will print out all those fields as if they were standard EXIF.  exiv2, for example, does not have this magical property.  Try exiftool and see if that shows you the temperature properties?</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Valentin Lucet, Mitch Fennell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-28 19:52:47">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-10-28 19:52:47"><div class="time">2022-10-28 19:52:47</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* If exiftool shows you the temperature values, we have a script to run exiftool on a folder of images and write the results (all available properties) to .json or .csv:</p>

<p><a href="https://github.com/microsoft/CameraTraps/blob/main/data_management/read_exif.py">https://github.com/microsoft/CameraTraps/blob/main/data_management/read_exif.py</a></p>

<p>YMMV, this has been run a total of 1.5 times.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-29 12:03:44">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-10-29 12:03:44"><div class="time">2022-10-29 12:03:44</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yup, I get the makernotes in exiftool. Was using the exifread package in python but for some reason it doesn't output many of the tags...</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-29 12:05:16">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-10-29 12:05:16"><div class="time">2022-10-29 12:05:16</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks for your help :)</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Dan Morris
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-29 16:48:31">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-10-29 16:48:31"><div class="time">2022-10-29 16:48:31</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* FYI as I understand it, exifread misses this because "makernotes" is by definition binary gibberish unless you have a library of manufacturer-specific decoders.  exiftool is the only thing I've found that does this well, so even when I need to read EXIF data from a million images, I fork a million invocations of exiftool.exe.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-11-09 04:52:16">
            
                <img src="https://avatars.slack-edge.com/2022-11-09/4345761822595_8ddb0ad25ec671ccef4d_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Anton Alvarez
                     <span class="print-only user-email">(aalvarez@wwf.es)</span>
                </div>
                <a href="#2022-11-09 04:52:16"><div class="time">2022-11-09 04:52:16</div></a>
                <div class="msg">
                    <p>Hi All!  Today is the <a href="https://www.gbif.org/event/f68927-b5c1-4ac8-a4ac-7d47645/exploring-camera-trap-data">GBIF webinar about exploring Camera Trap data</a> from the diversifying the GBIF Data .
Maybe it could be interesting to have your AI expertise involved in this Data Model to publish CT data.
As far as I know, J√ºrgen Niedballa has already suggested the possibility of integrating the AI model/format especially based in COCO Camera Traps format. <a href="https://github.com/tdwg/camtrap-dp/issues/203">https://github.com/tdwg/camtrap-dp/issues/203</a></p>

<p>Do you know if there has been another attempt to integrate the COCO Camera Trap with the Camera Trap Data Package?</p>
                    <div class="message-attachment"
                            style="border-color: #36a64f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">&lt;https://github.com/tdwg/camtrap-dp/issues/203|#203 Restructuring the model&gt;</a></div>
                                <div class="link-text">
                                    &lt;p&gt;In a discussion with &lt;a href=&#34;https://github.com/tucotuco&#34;&gt;@tucotuco&lt;/a&gt; on how to better align Camtrap DP with a common model for biodiversity data, a proposal came up on how to better structure &lt;strong&gt;sequences&lt;/strong&gt; in Camtrap DP.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Preamble&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;&lt;li&gt;&lt;p&gt;For the purpose of this discussion, I want to clarify what we mean by a &lt;strong&gt;sequence&lt;/strong&gt; here:&lt;/p&gt;

&lt;ol&gt;&lt;li&gt;It is a group of media files&lt;/li&gt;&lt;li&gt;It &lt;em&gt;can&lt;/em&gt; be used as the basis of an observation (i.e. the group of image files was assessed as a whole, not unlike the frames of a video). The alternative is image-based observations, which come with some benefits (see point 4).&lt;/li&gt;&lt;li&gt;It is &lt;em&gt;created&lt;/em&gt; after the media files were captured, based on a pre-defined &lt;code&gt;sequence interval&lt;/code&gt; &#34;Maximum number of seconds between timestamps of successive media files to be considered part of a single sequence&#34;. As a result, a sequence can contain multiple triggers/bursts. &lt;code&gt;sequence interval&lt;/code&gt; is not a camera setting, but one by the programme used to manage the images afterwards.&lt;/li&gt;&lt;li&gt;It can be used as an &#34;event&#34; for biological analysis. The downside of sequence-based observations is that you are stuck with the &lt;code&gt;sequence interval&lt;/code&gt; settings that were chosen. With image-based observations you can choose yourself how to group images together in logical events based on their timestamp.&lt;/li&gt;&lt;li&gt;Sequences typically don&#39;t result in a physical file. If they were, they would be like a gif/video looping through the originating files.&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;This proposal is not about whether image-based observations are better than sequence-based observations. The current situation is that both approaches exists (and likely will for a while) and Camtrap DP wants to support both.&lt;/li&gt;&lt;li&gt;The examples show a how the data would look for 3 images, using image-based vs sequence-based observations. In the first 2 images a wild boar (&lt;em&gt;Sus scrofa&lt;/em&gt;) can be seen.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Current situation 0&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/600993/154131962-583c9d78-c44d-4cf4-a48d-8f0b02a60ba3.png&#34;&gt;Screenshot 2022-02-15 at 20 10 11&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;&lt;li&gt;Sequences only consists as identifiers (&lt;code&gt;sequenceID&lt;/code&gt;), in both media and observations.&lt;/li&gt;&lt;li&gt;Observations have a &lt;code&gt;sequenceID&lt;/code&gt; and &lt;code&gt;mediaID&lt;/code&gt;, which are both foreign keys to the media table. Image-based observations need to populate both, sequence-based observations only &lt;code&gt;sequenceID&lt;/code&gt;. As a result, joins between observations and media are conditional: you kinda need to know what key to use to make a join that will yield results. &lt;strong&gt;That is not great.&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;Because the join over media is conditional, we added the convenience terms &lt;code&gt;deploymentID&lt;/code&gt; and &lt;code&gt;timestamp&lt;/code&gt; to observations, so that they can be easily joined with deployments - without having to go over media - to get useful biological data (location, time, species).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Image-based observations&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;media.csv
mediaID | sequenceID | deploymentID | timestamp           | filePath
------- | ---------- | ------------ | ------------------- | --------
med1    | void_seq1  | dep1         | 2020-01-01T00:00:00 | med1.jpg
med2    | void_seq1  | dep1         | 2020-01-01T00:00:01 | med2.jpg
med3    | void_seq1  | dep1         | 2020-01-01T00:00:02 | med3.jpg

observations.csv
observationID | sequenceID | mediaID | deploymentID | timestamp           | observationType | scientificName | count | countNew
------------- | ---------- | ------- | ------------ | ------------------- | --------------- | -------------- | ----- | --------
obs1          | void_seq1  | med1    | dep1         | 2020-01-01T00:00:00 | animal          | Sus scrofa     | 1     | 1
obs2          | void_seq1  | med2    | dep1         | 2020-01-01T00:00:01 | animal          | Sus scrofa     | 1     | 0
obs3          | void_seq1  | med3    | dep1         | 2020-01-01T00:00:02 | blank           | NULL           | NULL  | NULL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Sequence-based observations&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;media.csv
mediaID | sequenceID | deploymentID | timestamp           | filePath
------- | ---------- | ------------ | ------------------- | --------
med1    | seq1       | dep1         | 2020-01-01T00:00:00 | med1.jpg
med2    | seq1       | dep1         | 2020-01-01T00:00:01 | med2.jpg
med3    | seq1       | dep1         | 2020-01-01T00:00:02 | med3.jpg

observations.csv
observationID | sequenceID | mediaID | deploymentID | timestamp           | observationType | scientificName | count | countNew
------------- | ---------- | ------- | ------------ | ------------------- | --------------- | -------------- | ----- | --------
obs1          | seq1       | NULL    | dep1         | 2020-01-01T00:00:00 | animal          | Sus scrofa     | 1     | NULL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Suggested change 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/600993/154665355-6111e9b6-1541-4d1c-9ec5-2a6dcc851344.png&#34;&gt;Screenshot 2022-02-18 at 11 28 02&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In media.csv&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sequences are considered media&lt;/strong&gt; (not unlike videos), &lt;strong&gt;they get their own rows in media.csv&lt;/strong&gt;. The definition of that table becomes something along the lines of:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Table with media files associated with a deployment (&lt;code&gt;deploymentID&lt;/code&gt;). Media files can be captured by the camera trap (images/videos) or created afterwards by grouping files.&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;&lt;li&gt;Image and video files are still listed in media.csv. They have an optional &lt;code&gt;parentMediaID&lt;/code&gt; to associate them with sequences. That allows joins to find the images that belong to a sequence.&lt;/li&gt;&lt;li&gt;Including sequence rows is entirely optional: there is no need to include them if you only have image-based observations. You &lt;em&gt;could&lt;/em&gt;, if you want to convey somehow what grouping the system &#34;used&#34;, but since they are not used as a basis of observation, you can leave the grouping into &#34;events&#34; entirely up to the user. All the information is there to do it.&lt;/li&gt;&lt;li&gt;&lt;code&gt;filePath&lt;/code&gt; and &lt;code&gt;fileMediaType&lt;/code&gt; become &lt;em&gt;optional&lt;/em&gt; fields. They are typically not populated for sequence rows.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;In observations.csv&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Observations are &lt;em&gt;only&lt;/em&gt; linked via &lt;code&gt;mediaID&lt;/code&gt;&lt;/strong&gt;. That media row can be a single image (image-based observations) or a sequence. This is a huge benefit, as it no longer required conditional joins.&lt;/li&gt;&lt;li&gt;Observations are no longer directly linked to deployments, to make it clear that they are derived from media objects. Since joins with media.csv are no longer conditional, it&#39;s quite easy to join observations -&gt; media -&gt; deployments. You do have to download the media.csv to do the join though.&lt;/li&gt;&lt;li&gt;Observations no longer require a timestamp field. That information can be found in media.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Most importantly, we think this model better represents the actual situation with camera traps: deployments ‚Üí generate media ‚Üí generate observations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Image-based observations&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;media.csv
mediaID | parentMediaID | deploymentID | timestamp           | filePath
------- | ------------- | ------------ | ------------------- | --------
med1    | NULL          | dep1         | 2020-01-01T00:00:00 | med1.jpg
med2    | NULL          | dep1         | 2020-01-01T00:00:01 | med2.jpg
med3    | NULL          | dep1         | 2020-01-01T00:00:02 | med3.jpg

observations.csv
observationID | mediaID | observationType | scientificName | count | countNew
------------- | ------- | --------------- | -------------- | ----- | --------
obs1          | med1    | animal          | Sus scrofa     | 1     | 1
obs2          | med2    | animal          | Sus scrofa     | 1     | 0
obs3          | med3    | blank           | NULL           | NULL  | NULL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Sequence-based observations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;```
media.csv
mediaID | parentMediaID | deploymentID | timestamp           | filePath
------- | ------------- | ------------ | ------------------- | --------
seq1    | NULL          | dep1         | 2020-01-01T00:00:00 | NULL      &amp;lt;---- NEW ROW
med1    | seq1          | dep1         | 2020-01-01T00:00:00 | med1.jpg
med2    | seq1          | dep1         | 2020-01-01T00:00:01 | med2.jpg
med3    | seq1          | dep1         | 2020-01-01T00:00:02 | med3.jpg&lt;/p&gt;

&lt;p&gt;observations.csv
observationID | mediaID | observationType | scientificName | count | countNew
------------- | ------- | --------------- | -------------- | ----- | --------
obs1          | seq1    | animal   ‚Ä¶&lt;/p&gt;
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Assignees</div>
                                        &lt;a href=&#34;https://github.com/peterdesmet&#34;&gt;@peterdesmet&lt;/a&gt;
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Labels</div>
                                        level:media, level:observations, structure:update, term:deprecate, term:new, term:update
                                    </div>
                                
                                
    
        <a href="None">
            <img class="preview" src="https://user-images.githubusercontent.com/600993/154131962-583c9d78-c44d-4cf4-a48d-8f0b02a60ba3.png"
                width="1672"
                 height="750" />
        </a>
    
                                
                                
                                    <div class="attachment-footer">
                                        <img src="https://slack.github.com/static/img/favicon-neutral.png" class="icon" />
                                        &lt;a href=&#34;https://github.com/tdwg/camtrap-dp&#34;&gt;tdwg/camtrap-dp&lt;/a&gt;
                                    </div>
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">gbif.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.gbif.org/event/f68927-b5c1-4ac8-a4ac-7d47645/exploring-camera-trap-data">Exploring camera-trap data</a></div>
                                <div class="link-text">
                                    Global Biodiversity Information Facility. Free and Open Access to Biodiversity Data.
                                </div>
                                
                                
    
        <a href="https://www.gbif.org/event/f68927-b5c1-4ac8-a4ac-7d47645/exploring-camera-trap-data">
            <img class="preview" src="http://api.gbif.org/v1/image/unsafe/1200x627/http%3A%2F%2Fimages.ctfassets.net%2Fuo17ejk9rkwj%2F12Jl4Qhh2HblmuayZweh9q%2Ff6278dfaa0a135e0d1886d9498d1bb0e%2Fwebinar-cameratrap-03.png"
                width="478"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.gbif.org/event/f68927-b5c1-4ac8-a4ac-7d47645/exploring-camera-trap-data</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Josh Seltzer, Kakani Katija, Sara Beery, Kai Waddington, Dan Morris
                        </div>
                    
                        <div class="message-reaction">
                        üòé Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-12-13 17:43:00">
            
                <img src="https://secure.gravatar.com/avatar/c81b76e44701eb2e833047e020d6fdc5.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0010-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sasha Luccioni
                     <span class="print-only user-email">(sasha.luccioni@huggingface.co)</span>
                </div>
                <a href="#2022-12-13 17:43:00"><div class="time">2022-12-13 17:43:00</div></a>
                <div class="msg">
                    <p>Hi all!
I'm totally new to this, but @Dan Morris told me this is the place where new datasets are announced!
We just finished adding the <a href="https://huggingface.co/datasets/society-ethics/lila_camera_traps">LILA camera trap data</a> to the HuggingFace Hub (the central place where people can share resources), and I'm eager to add other datasets ü§ó
Let me know if there's anything missing that would help make this more usable for y'all! :face<em>with</em>cowboy_hat:</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">huggingface.co</div>
                            
                            
                                
                                <div class="link-title"><a href="https://huggingface.co/datasets/society-ethics/lila_camera_traps">society-ethics/lila_camera_traps ¬∑ Datasets at Hugging Face</a></div>
                                <div class="link-text">
                                    We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.
                                </div>
                                
                                
    
        <a href="https://huggingface.co/datasets/society-ethics/lila_camera_traps">
            <img class="preview" src="https://thumbnails.huggingface.co/social-thumbnails/datasets/society-ethics/lila_camera_traps.png"
                width="463"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://huggingface.co/datasets/society-ethics/lila_camera_traps</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üòç Sara Beery, Ben Weinstein, Josh Seltzer, Timm Haucke, Carly Batist, Lucia Gordon, Andrzej Bia≈Ça≈õ, aruna, Sam Kelly, Lindsey Dukles
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Jon Van Oast, Timm Haucke, Omiros Pantazis, Michael Bunsen, Dan Morris, aruna, Sam Kelly, Aakash Gupta
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-01-06 17:30:55">
            
                <img src="https://avatars.slack-edge.com/2020-08-03/1284586180260_ce5ba282733f34b0aeba_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sam Kelly
                     <span class="print-only user-email">(sam@conservationxlabs.org)</span>
                </div>
                <a href="#2023-01-06 17:30:55"><div class="time">2023-01-06 17:30:55</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Woah this is great @Sasha Luccioni!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-01-20 06:36:04">
            
                <img src="https://avatars.slack-edge.com/2023-08-10/5721228585203_075088cb99a4c3c39a3e_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Timm Haucke
                     <span class="print-only user-email">(timm@haucke.xyz)</span>
                </div>
                <a href="#2023-01-20 06:36:04"><div class="time">2023-01-20 06:36:04</div></a>
                <div class="msg">
                    <p>Does anyone happen to have spare Bushnell Impulse camera trap(s)? They are discontinued but great for experimenting with custom firmware. I would of course cover the original cost + shipping. They look like this:</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-01-25 06:08:34">
            
                <img src="https://secure.gravatar.com/avatar/468f7dde51c033f09186b59492208d97.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0018-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Simon Chamaill√©
                     <span class="print-only user-email">(simon.chamaille@cefe.cnrs.fr)</span>
                </div>
                <a href="#2023-01-25 06:08:34"><div class="time">2023-01-25 06:08:34</div></a>
                <div class="msg">
                    <p>Hi everyone,
maybe it's time to share some info on our French DeepFaune initiative, co-led with my colleague @Vincent Miele CNRS. Started with an internship by @Noa Rigoudy, we have developed a species recognition model for the French mammalian fauna, to be used on camera-traps pictures (no surprise here...). It might be useful for other Europeans (and possibly beyond to get rid of empty pictures), so please try it out. There is an English version available. You can download a software (windows/linux/mac) that runs the model on the project's website: <a href="https://www.deepfaune.cnrs.fr">https://www.deepfaune.cnrs.fr</a>. It works on a standard computer and on images stored locally, so no need to upload your photos on the cloud.
It also allows processing videos, although performance is a bit lower than on pictures. We are working on this. Actually, we are working on many things as @Gaspard Dussert recently joined us for his PhD. I will post here when we get significant updates, new species and so on. Stay tuned! (we have just released a new version that display the classical 'box' on pictures, so I couldn't resist posting a pic üòÖ).</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üòç Gaspard Dussert, Carly Batist, Timm Haucke, Fagner Cunha, Tiziana Gelmi Candusso, Sam Kelly
                        </div>
                    
                        <div class="message-reaction">
                        üëç Dante Wasmuht, Dan Morris, Valentin Gabeff, Kai Waddington
                        </div>
                    
                        <div class="message-reaction">
                        üòé Jon Van Oast, Meredith Palmer, Rebecca Wilks
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-01-25 06:54:18">
            
                <img src="https://avatars.slack-edge.com/2021-07-27/2328648358305_c6f10f351ae5296c3ca1_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Vincent Miele CNRS
                     <span class="print-only user-email">(vincent.miele@univ-lyon1.fr)</span>
                </div>
                <a href="#2023-01-25 06:54:18"><div class="time">2023-01-25 06:54:18</div></a>
                <div class="msg">
                    <p>Very easy to test our software on your PC (Windows):
1/ download the zip file  <a href="https://pbil.univ-lyon1.fr/software/download/deepfaune/deepfaune-latest.zip">https://pbil.univ-lyon1.fr/software/download/deepfaune/deepfaune-latest.zip</a>
2/ unzip this file on your Desktop
3/ click on deepfauneGUI.exe
For Linux/Mac, see our gitlab <a href="https://plmlab.math.cnrs.fr/deepfaune/software/">https://plmlab.math.cnrs.fr/deepfaune/software/</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-20 12:39:17">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5729572396613_37c6726ad5d913013f67_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Aakash Gupta
                     <span class="print-only user-email">(aakash@thinkevolveconsulting.com)</span>
                </div>
                <a href="#2023-03-20 12:39:17"><div class="time">2023-03-20 12:39:17</div></a>
                <div class="msg">
                    <p>We are using MDv5 ( version A), and this has run over 4.5 mn images. The algo filters the output, so that only prediction boxes which have higher than 0.4 probability are taken. However we are noticing that a lot of images with no animal or human species are being identified with high probability. 
What could be the reason behind this behaviour?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-20 12:44:49">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2361920803907_ad849dc380fc3d3470dc_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Daniel Davila
                     <span class="print-only user-email">(daniel.davila@kitware.com)</span>
                </div>
                <a href="#2023-03-20 12:44:49"><div class="time">2023-03-20 12:44:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I'm not familiar with this model, but in general this is usually indicative of a mis configuration. Either your model is not set up correctly, or you may not be preprocessing your imagery correctly and therefore the data you are giving it is out of distribution from how it was trained. Does it give halfway decent results (confidence wise and bbox localization accuracy) when you give it an image with a know positive target?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-20 13:06:24">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-03-20 13:06:24"><div class="time">2023-03-20 13:06:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* What is "a lot"?  FWIW 0.4 is actually a pretty <strong>high</strong> threshold for MDv5; we usually use 0.15 or 0.2. So if you're seeing, e.g., 10% false positives, I'm going to talk you into trying to get <em>more</em> false positives. üôÇ</p>

<p>If you are using the recommended MDv5 inference code, and the false positives are in sensible places on rocks and sticks that maybe kind of look like part of an animal, I would say this is just the cost of doing business with any AI model, and - as I think Michael Jordan said - "if you're not missing, you're not shooting enough" (or maybe he never said that, but he could have).  The recommend approach to those false positives is just good-old-fashioned human review, but you can also experiment with automatically or semi-automatically removing detections that occur over and over in the same place on a given camera, a la:</p>

<p><a href="https://github.com/microsoft/CameraTraps/tree/main/api/batch_processing/postprocessing/repeat_detection_elimination">https://github.com/microsoft/CameraTraps/tree/main/api/batch_processing/postprocessing/repeat_detection_elimination</a></p>

<p>If the false positives are in totally random places in the middle of the sky, something is probably up, and I'm happy to take a look at some of those images.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-20 13:11:54">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-03-20 13:11:54"><div class="time">2023-03-20 13:11:54</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Blame it on all the animals that are literally <strong>trying</strong> to look like rocks and sticks.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üòÇ »òtefan Istrate, Cara Appel, Sepand Dyanatkar, Sara Beery, David Will, Tiziana Gelmi Candusso, Felipe Parodi, Sam Kelly, Anton Alvarez, Cathy Atkinson, Rowan Converse, Mitch Fennell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-30 13:28:45">
            
                <img src="https://avatars.slack-edge.com/2022-04-28/3438134738247_2a5422e6f6dd1910e6d0_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Stephanie O&#39;Donnell
                     <span class="print-only user-email">(stephanie.odonnell@wildlabs.net)</span>
                </div>
                <a href="#2023-03-30 13:28:45"><div class="time">2023-03-30 13:28:45</div></a>
                <div class="msg">
                    <p>Hi folks! AI featured in the Variety Hour a lot yesterday so the whole show might be of interest to folks here. But Tom's talk about their work to build a community around camera trapping for insects was a standout - and maybe it'll get some of you as excited about AI applications for insects as the cute and fluffy animals? More here: <a href="https://www.youtube.com/watch?v=z7RVU8lsWi8&amp;ab_channel=WILDLABS.NET">https://www.youtube.com/watch?v=z7RVU8lsWi8&amp;ab_channel=WILDLABS.NET</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">YouTube</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="" class="icon">
                                    }
                                    <a href="https://www.youtube.com/@WILDLABSNET">
                                    WILDLABS.NET
                                    </a><span class="print-only">(https://www.youtube.com/@WILDLABSNET)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.youtube.com/watch?v=z7RVU8lsWi8&amp;amp;ab_channel=WILDLABS.NET">Tom August: Developing Autonomous Camera Traps for Insects</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                
    
        <a href="https://www.youtube.com/watch?v=z7RVU8lsWi8&amp;amp;ab_channel=WILDLABS.NET">
            <img class="preview" src="https://i.ytimg.com/vi/z7RVU8lsWi8/hqdefault.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.youtube.com/watch?v=z7RVU8lsWi8&amp;amp;ab_channel=WILDLABS.NET</div>
                                
                                
                            
                        </div>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üéâ Carly Batist, Andrew Schulz, Dan Morris, Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üôå John Martinsson, Aakash Gupta
                        </div>
                    
                        <div class="message-reaction">
                        üêû Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-30 20:33:41">
            
                <img src="https://avatars.slack-edge.com/2022-09-14/4085609422212_0be35bb86f58e99d445f_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Bunsen
                     <span class="print-only user-email">(notbot@gmail.com)</span>
                </div>
                <a href="#2023-03-30 20:33:41"><div class="time">2023-03-30 20:33:41</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Fantastic! Thank you for sharing the recording.</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Stephanie O&#39;Donnell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-28 15:41:58">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-04-28 15:41:58"><div class="time">2023-04-28 15:41:58</div></a>
                <div class="msg">
                    <p>For folks who are using MegaDetector... the repo has moved to a new GitHub organization, so the new URL is:</p>

<p><a href="https://github.com/ecologize/CameraTraps">https://github.com/ecologize/CameraTraps</a></p>

<p>Everything redirects automatically, so there's no need to change anything right away, but over time, it would be great to get links updated to point to the new URL, especially links that appear in other repos or in public documentation.  Thanks!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Jon Van Oast, Timm Haucke, Oisin Mac Aodha, Fagner Cunha, Sara Beery, Mitch Fennell, Valentin Gabeff, Aakash Gupta, Dimitri Korsch, Tiziana Gelmi Candusso, Lucia Gordon, Andrzej Bia≈Ça≈õ
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-03 17:24:47">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-05-03 17:24:47"><div class="time">2023-05-03 17:24:47</div></a>
                <div class="msg">
                    <p>The Wildlife Insights team is running a survey to learn more about camera trap data management practices, and in particular to understand potential barriers to data sharing, as well as potential barriers to the adoption of AI and cloud-based tools:</p>

<p><a href="https://docs.google.com/forms/d/1DspWERjAc6gDx4hP-pQlwSg6xKj6SMPZ29VTeD15PF4/">https://docs.google.com/forms/d/1DspWERjAc6gDx4hP-pQlwSg6xKj6SMPZ29VTeD15PF4/</a></p>

<p>Please circulate to your network of collaborators!  We recognize that our networks (including, e.g., this Slack channel) are super-duper-biased toward people who are already using AI and the cloud, and love sharing data, so please help us by circulating this link to a diverse set of ecologists.</p>

<p>Thanks!</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery, Carly Batist, »òtefan Istrate, Aakash Gupta, Mitch Fennell, Andrzej Bia≈Ça≈õ, Peter Bull, Timm Haucke, Tiziana Gelmi Candusso
                        </div>
                    
                        <div class="message-reaction">
                        ‚úÖ Andrzej Bia≈Ça≈õ
                        </div>
                    
                        <div class="message-reaction">
                        üëç Michael Bunsen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-06-06 22:38:14">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-06-06 22:38:14"><div class="time">2023-06-06 22:38:14</div></a>
                <div class="msg">
                    <p>I don't normally post super-duper-way-into-the-weeds features we add to the MegaDetector code base, but two things I like are (a) neat camera trap pictures and (b) effective but super-duper-inelegant uses of machine learning that would make proper machine learning people sad at the very thought of such ickiness.  To that end, something I've been meaning to do for a while... and buckle in, this is <em>waaaaay</em> in the weeds.  This is what you were getting into when you signed up for the camera_traps channel, eh?</p>

<p>One of the useful "pro tips" for getting the most out of MegaDetector is using the <a href="https://github.com/agentmorris/MegaDetector/tree/main/api/batch_processing/postprocessing/repeat_detection_elimination">repeat detection elimination</a> process, which takes advantage of the fact that if an "animal" is detected at <em>exactly</em> the same location in like 100 images, it's almost definitely a rock/stick/etc.  But <em>sometimes</em> it's, e.g., a sleeping elk, so we don't automatically remove these, rather, we have a semi-manual process for very quickly reviewing one example from each of those "suspicious detections", and this is so super-fast that you can often get rid of tends of thousands of false detections in just a minute or two.</p>

<p>But one of the risks of doing this is that if there's a detection that happened 100 times, you're seeing the highest-confidence example, but it's <em>possible</em> that one of the 99 you're not seeing is actually an animal that managed to line itself up <em>exactly</em> with that rock, and you would be de facto removing that from your universe.  Until now!  @Doantam Phan added a new feature that lets us render the same sample image, but with a grid next to it that shows the cropped detection for <em>all</em> of those 100 images, like this:</p>

<p><a href="https://raw.githubusercontent.com/agentmorris/MegaDetector/main/api/batch_processing/postprocessing/images/rde_tiles_all_fps.jpg">https://raw.githubusercontent.com/agentmorris/MegaDetector/main/api/batch_processing/postprocessing/images/rde_tiles_all_fps.jpg</a></p>

<p>...when it's a bush/rock/etc. (which is 99% of the time), or like this:</p>

<p><a href="https://raw.githubusercontent.com/agentmorris/MegaDetector/main/api/batch_processing/postprocessing/images/rde_tiles_sleeping_elk.jpg">https://raw.githubusercontent.com/agentmorris/MegaDetector/main/api/batch_processing/postprocessing/images/rde_tiles_sleeping_elk.jpg</a></p>

<p>...when it's the proverbial (or in this case literal) sleeping elk.</p>

<p>More details here:</p>

<p><a href="https://github.com/agentmorris/MegaDetector/tree/main/api/batch_processing/postprocessing/repeat_detection_elimination#visualizing-the-stuff-youre-throwing-away">https://github.com/agentmorris/MegaDetector/tree/main/api/batch<em>processing/postprocessing/repeat</em>detection_elimination#visualizing-t[‚Ä¶]throwing-away</a></p>

<p>These images are mesmerizing to look at when you're looking at 10,000 in a row.  It's hard to describe why they're so mesmerizing, but they are, I swear.</p>
                    <div class="message-attachment"
                            >
                            
                            
                            
                                
                                <div class="link-title"><a href=""></a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                
    
        <a href="https://raw.githubusercontent.com/agentmorris/MegaDetector/main/api/batch_processing/postprocessing/images/rde_tiles_all_fps.jpg">
            <img class="preview" src="https://raw.githubusercontent.com/agentmorris/MegaDetector/main/api/batch_processing/postprocessing/images/rde_tiles_all_fps.jpg"
                width="3200"
                 height="1500" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://raw.githubusercontent.com/agentmorris/MegaDetector/main/api/batch_processing/postprocessing/images/rde_tiles_all_fps.jpg</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            
                            
                            
                                
                                <div class="link-title"><a href=""></a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                
    
        <a href="https://raw.githubusercontent.com/agentmorris/MegaDetector/main/api/batch_processing/postprocessing/images/rde_tiles_sleeping_elk.jpg">
            <img class="preview" src="https://raw.githubusercontent.com/agentmorris/MegaDetector/main/api/batch_processing/postprocessing/images/rde_tiles_sleeping_elk.jpg"
                width="3200"
                 height="1500" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://raw.githubusercontent.com/agentmorris/MegaDetector/main/api/batch_processing/postprocessing/images/rde_tiles_sleeping_elk.jpg</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ü¶å Rowan Converse, Aakash Gupta, Timm Haucke, Sara Beery, Cara Appel, »òtefan Istrate, Alexander Dungate, Tiziana Gelmi Candusso, Aim√©e
                        </div>
                    
                        <div class="message-reaction">
                        üëç Aakash Gupta, Timm Haucke, Rebecca Wilks, Michael Bunsen
                        </div>
                    
                        <div class="message-reaction">
                        üòé Timm Haucke
                        </div>
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Jon Van Oast
                        </div>
                    
                        <div class="message-reaction">
                        üôå Alexander Dungate, Mitch Fennell, Tiziana Gelmi Candusso
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2023-06-06 22:38:20">
            
                <img src="https://secure.gravatar.com/avatar/2b6fc55325956635cf83df408aa5682d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0018-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Doantam Phan
                     <span class="print-only user-email">(doantam@doantamphan.com)</span>
                </div>
                <a href="#2023-06-06 22:38:20"><div class="time">2023-06-06 22:38:20</div></a>
                <div class="msg">
                    <p>@Doantam Phan has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-06-06 22:40:30">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-06-06 22:40:30"><div class="time">2023-06-06 22:40:30</div></a>
                <div class="msg">
                    <p>And another random MD-related thing... on a thread on this channel a few weeks ago, someone asked about MD failure cases, i.e. the scenarios that really break MD.  I said I had a bunch lined up and would make a page summarizing those, and then I didn't, but it wasn't because I totally flaked, it was because I needed to secure some image permissions.  Voila:</p>

<p><a href="https://github.com/agentmorris/MegaDetector/blob/main/megadetector-challenges.md">https://github.com/agentmorris/MegaDetector/blob/main/megadetector-challenges.md</a></p>

<p>Basically the failure modes for MD (other than things that are way out of domain, like drone images, or fish) are reptiles, a few other random things, and more reptiles.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Aakash Gupta, Timm Haucke, Sara Beery, »òtefan Istrate, Mitch Fennell, Tiziana Gelmi Candusso, Rosho
                        </div>
                    
                        <div class="message-reaction">
                        üòé Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-06-07 12:16:21">
            
                <img src="https://avatars.slack-edge.com/2023-05-21/5283978847047_6dfe29e62ff090fa3306_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Jon Van Oast
                     <span class="print-only user-email">(jon@wildme.org)</span>
                </div>
                <a href="#2023-06-07 12:16:21"><div class="time">2023-06-07 12:16:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* thanks so much for this tour of oddities. these edge cases and failure cases are always good for some head scratching.</p>

<p>i am sorta curious about the "moved" annotation cases - i wonder if it is something <em>off</em> in the <strong>image metadata</strong>. we once saw this where the <em>rotation/orientation</em> metadata (exif or xmp or whatever) was incorrect. (we actually have had a history of <em>huge</em> headaches with orientation! see: phones) ... also, there has been some weird math when the <em>pixel</em> size (or aspect ratio) is funky in the metadata.  it would not be all that surprising (depending on which tool you used) if <em>rescaling</em> it simple did away with the questionable metadata, or fixed it in some way.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-06-07 12:17:29">
            
                <img src="https://avatars.slack-edge.com/2023-05-21/5283978847047_6dfe29e62ff090fa3306_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Jon Van Oast
                     <span class="print-only user-email">(jon@wildme.org)</span>
                </div>
                <a href="#2023-06-07 12:17:29"><div class="time">2023-06-07 12:17:29</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* (though, if these <em>same cameras</em> have produced images that worked fine in other cases, it would be <em>very</em> weird that only some of the exif would be off.)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-06-12 21:44:00">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-06-12 21:44:00"><div class="time">2023-06-12 21:44:00</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* My first instinct was something about rotation or metadata as well, but I've ruled this out in every way I know how... if I literally screenshot the pixels and save to a new image, the problem persists on these pathological images.  Ditto if I convert to .png, or resample from the original size (which is larger than 1280px on the long side) to 1280 px on the long side.  It seems to be something about the images themselves, not a metadata issue.  This was also a good reminder to check whether Magical New Fixes in more recent versions of YOLOv5 and PyTorch have fixed this, but alas, no luck.  (The official MD release doesn't support newer versions of PyTorch, but I did that test using the strategy discussed <a href="https://github.com/agentmorris/MegaDetector/issues/64">here</a>, using PyTorch 2.0+ and a current YOLOv5).</p>

<p>The only good news is that in running MegaDetector on literally around 300M images, I have never seen this issue on any other dataset.  The closest analogy I can think of is the examples we see in talks about adversarial attacks where imperceptible pixel changes create radical changes in output; these images seem to have the perfect adversarial attack for YOLOv5.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Jon Van Oast
                        </div>
                    
                        <div class="message-reaction">
                        üòÆ Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-07-13 10:54:10">
            
                <img src="https://avatars.slack-edge.com/2022-07-26/3866854467025_2afebcb071df6d73e6cd_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Toryn Schafer
                     <span class="print-only user-email">(tschafer@tamu.edu)</span>
                </div>
                <a href="#2023-07-13 10:54:10"><div class="time">2023-07-13 10:54:10</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I'm working on classification for reptile camera traps and am new to this slack. I have not played with megadector yet, but would love to connect!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-07-13 19:17:13">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-07-13 19:17:13"><div class="time">2023-07-13 19:17:13</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Toryn Schafer, what reptiles are you studying?  Specifically, where do your reptiles land along the axis of "big things you can easily see them in camera trap images" to "tiny things that could land on your head and you wouldn't notice".  Asking because I'm sort of ambiently curating training data to hypothetically fine-tune MD to work better on reptiles.  Tiny geckos are always going to be out of domain for MegaDetector, but, e.g., the tegus I show on that page <em>should</em> be in-domain, we just need training data to fine-tune a little.  In theory.  Message me if you have a pile of big-reptile pictures you can share!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-07-19 11:18:31">
            
                <img src="https://avatars.slack-edge.com/2023-05-18/5301866833265_bfac1e636e9bc4dd85a5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">David McClosky
                     <span class="print-only user-email">(david.mcclosky@gmail.com)</span>
                </div>
                <a href="#2023-07-19 11:18:31"><div class="time">2023-07-19 11:18:31</div></a>
                <div class="msg">
                    <p>Naive question: Is there existing work on using ML to detect foggy conditions in camera trap images? (would MegaDetector work well in this case? I'm guessing it wouldn't be great, but maybe someone has tried it?)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-07-19 11:48:56">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-07-19 11:48:56"><div class="time">2023-07-19 11:48:56</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* There are two questions here... (1) will MD work in foggy conditions? and (2) is there work on <strong>detecting</strong> foggy conditions?</p>

<p>To (1), there's not a simple answer; I would go with "better than you might think, but fog doesn't help".  Overall we haven't seen a significant number of cases where a human could see animals through fog/snow that MD misses.  MD has plenty of failure cases that I'm always happy to rant about (I just added a new one to the challenges page, I'll link below!), but this hasn't been a huge issue.</p>

<p>To (2), AFAIK the answer is "no", but this has been something we've been thinking about on the backburner for a long time.  The goal would be to count operational days automatically, and generally to differentiate "no animals detected because nothing is there" from "no animals detected because the lens is obscured".  My first instinct was that detecting fog/rain/snow (maybe to the degree of "none", "partially obscuring", "totally obscured") might not even require ML, but we weren't able to do this reliably with simple CV heuristics.  Idaho F&amp;G provided a snow dataset with rain/snow labels a few years ago, and it was enough to show that our heuristics didn't work, but not really enough to train a model.  I just re-started this discussion a few weeks ago with @Mitch Fennell to see if we could assemble a dataset.</p>

<p>If folks have images labeled with rain/fog/snow, and someone wants to take a crack at this, I think it would be a useful and relatively straightforward model!  Data is the hard part.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-07-19 11:50:46">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-07-19 11:50:46"><div class="time">2023-07-19 11:50:46</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Oh, and I promised a new MD failure case... courtesy of <a href="http://skyislandalliance.org">skyislandalliance.org</a>:</p>

<p><a href="https://github.com/agentmorris/MegaDetector/blob/main/megadetector-challenges.md#mega-occlusion-that-humans-are-smart-enough-to-parse-but-ai-is-not">https://github.com/agentmorris/MegaDetector/blob/main/megadetector-challenges.md#mega-occlusion-that-humans-are-smart-enough-to-parse-but-ai-is-not</a></p>

<p>tl;dr: animals are sometimes behind a fence and about 75% obscured by vertical bars, but in a way that human eyes are really good at ignoring.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-07-19 11:54:09">
            
                <img src="https://avatars.slack-edge.com/2023-05-18/5301866833265_bfac1e636e9bc4dd85a5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">David McClosky
                     <span class="print-only user-email">(david.mcclosky@gmail.com)</span>
                </div>
                <a href="#2023-07-19 11:54:09"><div class="time">2023-07-19 11:54:09</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thank you Dan, this is really helpful! Agree that simple CV heuristics might be sufficient in this case. I'll check we can share our dataset (though note that it is currently unlabeled...it's also animal-free images of skyline in SF since the camera is trying to document when an air sensor is being disrupted by fog)</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Dan Morris
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-07-19 14:48:33">
            
                <img src="https://avatars.slack-edge.com/2022-08-31/4012229393526_dfb97e82305b3683f037_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Procko
                     <span class="print-only user-email">(xprockox@gmail.com)</span>
                </div>
                <a href="#2023-07-19 14:48:33"><div class="time">2023-07-19 14:48:33</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Katie Breen was doing weather detection models at CV4E last year and might also have additional insight on the obstacles/areas of promise. </p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-07-19 15:09:47">
            
                <img src="https://avatars.slack-edge.com/2023-01-28/4699069512215_ddf34adc0693fc2690dd_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Peter Bermant
                     <span class="print-only user-email">(pcbermant@gmail.com)</span>
                </div>
                <a href="#2023-07-19 15:09:47"><div class="time">2023-07-19 15:09:47</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* At Conservation X Labs, we've been working on a few downstream tasks that tend to depend on image quality. @Dan Morris We also initially tried CV heuristics but didn't have much luck. We spun up a quick web app to annotate image quality but we could always add/modify labels. <a href="https://cct-image-annotation.streamlit.app/">https://cct-image-annotation.streamlit.app/</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Dan Morris
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-07-19 17:25:56">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-07-19 17:25:56"><div class="time">2023-07-19 17:25:56</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Peter Bermant Very cool!  I think I just gave you three annotations. üôÇ That's super-relevant, let me know if at some point you are able to share those annotations publicly, I think a lot of folks here would be interested in playing with that dataset.</p>

<p>I think the ideal dataset for image occlusion due to weather probably looks a little different, i.e. I don't think for that dataset there's a need to crop animals, it's more about the gestalt of the image and pretty specific to weather (or other whole-image camera malfunctions).  The one animal-related thing that the hypothetical ideal perfect unicorn of a dataset would really need is a decent distribution of animals smushed right up against the camera lens; that is a common phenomenon in places where snow is an issue, and one of the major reasons that simple heuristics weren't enough in the images I was looking at.  Grrrr, curious elk.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Peter Bermant
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-09-19 21:02:28">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-09-19 21:02:28"><div class="time">2023-09-19 21:02:28</div></a>
                <div class="msg">
                    <p>A few weeks ago we posted to this channel to indicate that we were doing a survey on data management and AI tools for camera trap data... we've summarized the results here:</p>

<p><a href="https://wildlabs.net/discussion/camera-trap-data-management-survey-results">https://wildlabs.net/discussion/camera-trap-data-management-survey-results</a></p>

<p>Set your expectations low: there is some interesting stuff there, but <em>mostly</em> what we learned is that despite our best efforts, we failed to find a way to distribute the survey that didn't represent the bias of a bunch of tech-y people sending out a survey.  The results indicate a much  higher adoption of AI than we believe is realistic (by like 10x), based on our experiences in settings that don't have a tech-y bias (like ecology conferences).  So, YMMV, but we think there is some interesting discussing fodder.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Suzanne Stathatos, Talia Speaker, Mitch Fennell, Henrik Cox (Sentinel)
                        </div>
                    
                        <div class="message-reaction">
                        üòé Jon Van Oast, Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëç Michael Bunsen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-09-22 18:40:38">
            
                <img src="https://avatars.slack-edge.com/2022-01-13/2948421492629_5f2be72d235c0802b87c_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ian Ingram
                     <span class="print-only user-email">(iingram@sandiegozoo.org)</span>
                </div>
                <a href="#2023-09-22 18:40:38"><div class="time">2023-09-22 18:40:38</div></a>
                <div class="msg">
                    <p>Is there already a model zoo of regional image classifier models trained for camera trap image data (and perhaps object detector and other sorts of models, too) collected somewhere?  Folks here at the Conservation Technology Lab at SDZWA have a few and will continue to make more and a) we want to share them and b) want to put them in the place folks are the most likely to find them.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-09-22 22:25:38">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-09-22 22:25:38"><div class="time">2023-09-22 22:25:38</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Good question... I'm not aware of anything... model zoos are hard!  Everyone's environment is different, even the structure of what's being classified is fundamentally different across classifiers (images, crops, sequences, videos), so it's hard to have something super-standard.  Plus I think a slight majority of regional classifiers that exist are available as part of a platform, but not for direct download, and therefore are not quite model-zoo-compatible.</p>

<p>But (a) I'd love to try your classifiers, please share links! and (b) I do keep a list of <strong>repos</strong> in this area, which I think is <strong>almost</strong> a superset of a hypothetical list of models one could include in a hypothetical model zoo:</p>

<p><a href="https://agentmorris.github.io/camera-trap-ml-survey/#oss-repos-about-ml-for-camera-traps">https://agentmorris.github.io/camera-trap-ml-survey/#oss-repos-about-ml-for-camera-traps</a></p>

<p>It wouldn't be too much work to click through those and see which repos include model weights, then either create a separate list or just add an "includes models" tag to that list.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Matthias Zuerl, Sara Beery, Ian Ingram
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-09-25 20:13:29">
            
                <img src="https://avatars.slack-edge.com/2022-01-13/2948421492629_5f2be72d235c0802b87c_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ian Ingram
                     <span class="print-only user-email">(iingram@sandiegozoo.org)</span>
                </div>
                <a href="#2023-09-25 20:13:29"><div class="time">2023-09-25 20:13:29</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks! Yeah, the variation in everyone's systems does make it tough to serve drop-in models. But having some kind of place to share models where folks know to look for them seems worthwhile...and then maybe in a backwards way find the system that they were designed for. Maybe that would more aptly be described as a "model wilderness" üôÇ</p>

<p>The list you have put together is pretty great.</p>

<p>We'll figure out where to put our models in the short-term and we'll share links so that you can have a look.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-09-25 21:51:31">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-09-25 21:51:31"><div class="time">2023-09-25 21:51:31</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Did you just invent "model wilderness"?  That's good.  I'm going to steal that.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-09-26 15:22:49">
            
                <img src="https://secure.gravatar.com/avatar/89cbe0fc12b2cc92d129f14b0a5f665e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mathias Tobler
                     <span class="print-only user-email">(matobler@gmx.net)</span>
                </div>
                <a href="#2023-09-26 15:22:49"><div class="time">2023-09-26 15:22:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* That's a great resource Dan, thanks for putting that together. As for the usefulness of a "model zoo", I would assume that most people who work on camera trap image classification still train standard image classifiers either on cropped (usually with MegaDetector) or non-cropped images. If those are based on the standard models (Resnet, ImageNet, EfficientNet etc.) then they could be integrated into different frameworks pretty easily. So having a "model zoo" might actually encourage people to somewhat standardize their tools, share models and make them more accessible to practitioners. Maybe?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-09-26 23:26:46">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2023-09-26 23:26:46"><div class="time">2023-09-26 23:26:46</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Ian Ingram, I believe Conservation X Labs are working on a model zoo of sorts. The aim in mainly for models compatible with their Sentinel smart cameras, but perhaps for general download as well. @Henrik Cox (Sentinel)?</p>

<p>I am also interested in object detectors and species classifiers for <a href="http://bearid.org/">BearID Project</a>. Currently we assume images contain only bears. Eventually we will need to add a detector and/or classifier before hand. We are mainly focused on brown bears in western Canada and Alaska, but are also looking into other bears species like Andean bears.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-09-27 05:01:17">
            
                <img src="https://avatars.slack-edge.com/2023-02-02/4755946525105_67b7d4b150cfbaf4357f_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Henrik Cox (Sentinel)
                     <span class="print-only user-email">(henrik@conservationxlabs.org)</span>
                </div>
                <a href="#2023-09-27 05:01:17"><div class="time">2023-09-27 05:01:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks @Ed Miller, hi @Ian Ingram, yes we're working on a model marketplace as part of the <a href="https://conservationxlabs.com/the-sentinel">Sentinel system</a> we're building out to have pre-trained models ready for download, and also as a hub for third party models to be hosted. Right now it's in MVP and only found on the <code>Model Marketplace</code> page if you have an account on our dashboard: <a href="http://mysentinel.info">mysentinel.info</a>, so there's a lot of work we need to do to populate the zoo with more of our own models. But we do want to make this it's own platform (no need to log into a dashboard) once we've done a few more major deployments of Sentinel hardware devices.</p>

<p>As for hosting third party models, it's able to do that now - we're currently hosting MegaDetector v5a and v5b on there as a proof of concept to it.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-10-27 00:53:30">
            
                <img src="https://avatars.slack-edge.com/2022-09-14/4085609422212_0be35bb86f58e99d445f_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Bunsen
                     <span class="print-only user-email">(notbot@gmail.com)</span>
                </div>
                <a href="#2023-10-27 00:53:30"><div class="time">2023-10-27 00:53:30</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* MBARI recently started putting their detectors and models for ocean life on Hugging Face. I am considering doing the same! It is becoming a familiar home and interface for practitioners on the ML implementation side of things <a href="https://huggingface.co/FathomNet">https://huggingface.co/FathomNet</a></p>

<p>And you get a free basic page for inference! which is very helpful to get a quick idea of a model's performance on your own images.
<a href="https://huggingface.co/spaces/FathomNet/MBARI_Monterey_Bay_Benthic">https://huggingface.co/spaces/FathomNet/MBARI_Monterey_Bay_Benthic</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">huggingface.co</div>
                            
                            
                                
                                <div class="link-title"><a href="https://huggingface.co/spaces/FathomNet/MBARI_Monterey_Bay_Benthic">MBARI Monterey Bay Benthic - a Hugging Face Space by FathomNet</a></div>
                                <div class="link-text">
                                    Discover amazing ML apps made by the community
                                </div>
                                
                                
    
        <a href="https://huggingface.co/spaces/FathomNet/MBARI_Monterey_Bay_Benthic">
            <img class="preview" src="https://cdn-thumbnails.huggingface.co/social-thumbnails/spaces/FathomNet/MBARI_Monterey_Bay_Benthic.png"
                width="1200"
                 height="648" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://huggingface.co/spaces/FathomNet/MBARI_Monterey_Bay_Benthic</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Kakani Katija
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-03 14:33:23">
            
                <img src="https://avatars.slack-edge.com/2021-02-23/1809933377808_8dc18744741ad7500d94_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Mitch Fennell
                     <span class="print-only user-email">(mitchell.fennell@gmail.com)</span>
                </div>
                <a href="#2023-11-03 14:33:23"><div class="time">2023-11-03 14:33:23</div></a>
                <div class="msg">
                    <p>Hi all,</p>

<p>I‚Äôm curious if anyone has ever experimented with detecting amphibians (mostly toads) in camera trap images using MegaDetector? We have a dataset captured using timed images from amphibian crossing structures (tunnels), and are interested to hear if anyone else has tried this, and if so how the model performed out of the box?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-03 21:27:21">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-11-03 21:27:21"><div class="time">2023-11-03 21:27:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Even if they're large enough to be in the size range of what MegaDetector can do, it's definitely hit or miss for both reptiles and amphibians.  They're so infrequently studied with camera traps that they're significantly under-represented in MD's training data, so... hit or miss.  See:</p>

<p><a href="https://github.com/agentmorris/MegaDetector/blob/main/megadetector-challenges.md#reptiles-and-other-under-represented-species">https://github.com/agentmorris/MegaDetector/blob/main/megadetector-challenges.md#reptiles-and-other-under-represented-species</a></p>

<p>I should say that sometimes it totally just works, and lots of users have used MD for reptile or amphibian studies.  But I'd say for whatever "good enough to be useful" is, if someone really cares about reptiles or amphibians, MD is "good enough" maybe 50% of the time.  So we try to make sure to really thoroughly review results on some unlabeled data before recommending that someone should use MD for those use cases.</p>

<p>But this is something I've been really trying to improve lately, not by fixing MD per se, but by making it pretty efficient to train bespoke one-off fine-tuned versions of MD.  Do you have a labeled dataset (not boxes, presumably, just image-level labels) with amphibians from your ecosystem?  If so, around how many examples do you think you have?  And how big are your amphibians?</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Alan Stenhouse
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-04 02:31:00">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5729572396613_37c6726ad5d913013f67_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Aakash Gupta
                     <span class="print-only user-email">(aakash@thinkevolveconsulting.com)</span>
                </div>
                <a href="#2023-11-04 02:31:00"><div class="time">2023-11-04 02:31:00</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* As Dan suggested you can run MDv5 on some sample images, just to see if it identifies the amphibians in it. 
Try running other detectors like Yolov5 or higher versions to see if they can help. 
In case you have an annotated dataset. Here is a list of open-source tools, in case you wish to annotate the dataset.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-08 12:33:30">
            
                <img src="https://avatars.slack-edge.com/2022-07-26/3866854467025_2afebcb071df6d73e6cd_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Toryn Schafer
                     <span class="print-only user-email">(tschafer@tamu.edu)</span>
                </div>
                <a href="#2023-11-08 12:33:30"><div class="time">2023-11-08 12:33:30</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I have a team working on classification of timed images for snakes. We went away from megadetector and are training our own model. We are still in preliminary stages, but are trying to characterize the potential for a CNN in the backend to reduce human workload</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-19 13:06:45">
            
                <img src="https://avatars.slack-edge.com/2021-02-23/1809933377808_8dc18744741ad7500d94_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mitch Fennell
                     <span class="print-only user-email">(mitchell.fennell@gmail.com)</span>
                </div>
                <a href="#2023-11-19 13:06:45"><div class="time">2023-11-19 13:06:45</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks for the info all! @Dan Morris we‚Äôre actually still waiting to receive the data, and will be doing some initial testing/playing around once we have it in hand. I‚Äôll shoot you a message to let you know how it works, as well as a couple of sample images. We don‚Äôt have anything labelled at this point, but might be interested in training up something bespoke after data is processed from this year!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üê∏ Dan Morris
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-26 02:31:47">
            
                <img src="https://avatars.slack-edge.com/2023-11-26/6271497607856_ed052afd9c0eaaf11da0_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Casey Clifton
                     <span class="print-only user-email">(caseyclifton@proton.me)</span>
                </div>
                <a href="#2023-11-26 02:31:47"><div class="time">2023-11-26 02:31:47</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Not a toad but ive seen MD able to do australian reptiles! Dont have an accuracy score yet though</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëç Mitch Fennell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-17 03:15:56">
            
                <img src="https://avatars.slack-edge.com/2022-02-09/3075038202214_f9ee2a2a94dcc3815f28_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Peter van Lunteren
                     <span class="print-only user-email">(contact@pvanlunteren.com)</span>
                </div>
                <a href="#2023-11-17 03:15:56"><div class="time">2023-11-17 03:15:56</div></a>
                <div class="msg">
                    <p>Does anyone have experience with using hand-help images as training data for a camera trap model? I need to include some species which are not available on LILA BC, nor are there (enough) images of similar species. I was thinking of scraping image databases like Google Images, Gettyimages, Shutterstock, Bing and iNaturalist. This is of course not ideal, but I figured it at least gives me a a few hundred images to start with. Has anyone ever tried this?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-17 06:47:11">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2023-11-17 06:47:11"><div class="time">2023-11-17 06:47:11</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* There's a paper doing this exact thing for pigs I think? sus scrofa</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-17 06:48:13">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2023-11-17 06:48:13"><div class="time">2023-11-17 06:48:13</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8093655/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8093655/</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">PubMed Central (PMC)</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8093655/">Automated location invariant animal detection in camera trap images using publicly available data sources</a></div>
                                <div class="link-text">
                                    Achieve location invariant camera trap object detectors by using publicly available image data. Optimize object detectors for domain‚Äêspecific application using infusion of small subsets of camera trap images.
                                </div>
                                
                                
    
        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8093655/">
            <img class="preview" src="https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0"
                width="1600"
                 height="836" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8093655/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-17 06:48:59">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2023-11-17 06:48:59"><div class="time">2023-11-17 06:48:59</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I think it wouldn't be very different from using synthetic images a la <a href="https://arxiv.org/abs/1904.05916">https://arxiv.org/abs/1904.05916</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/1904.05916">Synthetic Examples Improve Generalization for Rare Classes</a></div>
                                <div class="link-text">
                                    The ability to detect and classify rare occurrences in images has important applications - for example, counting rare and endangered species when studying biodiversity, or detecting infrequent traffic scenarios that pose a danger to self-driving cars. Few-shot learning is an open problem: current computer vision systems struggle to categorize objects they have seen only rarely during training, and collecting a sufficient number of training examples of rare events is often challenging and expensive, and sometimes outright impossible. We explore in depth an approach to this problem: complementing the few available training images with ad-hoc simulated data.
 Our testbed is animal species classification, which has a real-world long-tailed distribution. We analyze the effect of different axes of variation in simulation, such as pose, lighting, model, and simulation method, and we prescribe best practices for efficiently incorporating simulated data for real-world performance gain. Our experiments reveal that synthetic data can considerably reduce error rates for classes that are rare, that as the amount of simulated data is increased, accuracy on the target class improves, and that high variation of simulated data provides maximum performance gain.
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/1904.05916">
            <img class="preview" src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/1904.05916</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-17 06:50:17">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2023-11-17 06:50:17"><div class="time">2023-11-17 06:50:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* If you want to get clever you could probably use SAM to segment the animals in the handheld images and use copy-paste augmentation to put them on camera trap backgrounds, which <strong>might</strong> help avoid the classifier learning that a non-camera-trap image is that rare species</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-17 11:03:08">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-11-17 11:03:08"><div class="time">2023-11-17 11:03:08</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* MDv5a uses images from iNat and COCO, and overall this has improved performance relative to MDv5b (which does not use iNat/COCO images).  I would be cautious about using this approach for species that may appear at night in camera trap images (but probably not on the Web or in iNat images); i.e., this is probably "safer" for birds and reptiles that don't typically appear in nighttime images.  If you are training on MD crops (which I think you are), that also probably helps; one of the major differences between camera trap images and handheld images is framing, and that <em>sort of</em> goes away when you're cropping anyway.</p>

<p>Out of curiosity, what are your key species of interest?  Mostly asking in case there's someone we can buy a granola bar for to get you more data.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Mitch Fennell
                        </div>
                    
                        <div class="message-reaction">
                        üòÇ Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-20 04:49:40">
            
                <img src="https://avatars.slack-edge.com/2022-02-09/3075038202214_f9ee2a2a94dcc3815f28_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Peter van Lunteren
                     <span class="print-only user-email">(contact@pvanlunteren.com)</span>
                </div>
                <a href="#2023-11-20 04:49:40"><div class="time">2023-11-20 04:49:40</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sara Beery @Dan Morris Perfect, thanks for the papers and insights! Yes, I'm working with MD crops. I'm asking for a project where I need to classify <em>Vuples cana</em> and <em>Canis aureus</em>, amongst others. I could of course take related species from LILA BC to train on, but the thing is that for the same project we need to be able to classify these related species too. SAM segmentation with CT backgrounds would be a good idea. I was also thinking of making the hand-held images 'look' like CT images, by grey-scaling a a proportion of the images. Anyway, if I will share my findings once I have experimented with it üòâ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-20 11:38:48">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-11-20 11:38:48"><div class="time">2023-11-20 11:38:48</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* FWIW when I talk about the general idea of using visually similar species as examples to train a model, coincidentally, the golden jackal is literally the example I use.  So now we can test whether my hypothetical example actually makes sense!</p>

<p>There are <em>lots</em> of coyotes on LILA, and a decent number of African jackals, though I would say coyotes look even more like golden jackals than African jackals do, and neither co-occur with golden jackals AFAIK.  Consider using coyotes to train your golden jackal class, and island foxes to train your Blanford's fox class?  Both of those are present in large quantities on LILA.  I think that will be easier than getting into more research-y territory or using iNat images.  I.e., I would say a coyote in a camera trap image on average looks a lot more like a golden jackal in a camera trap image than a golden jackal in an iNat image looks like a golden jackal in a camera trap image.  Plus I don't think iNat is going to be flush with golden jackals.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôè Peter van Lunteren, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-21 00:51:06">
            
                <img src="https://avatars.slack-edge.com/2022-02-09/3075038202214_f9ee2a2a94dcc3815f28_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Peter van Lunteren
                     <span class="print-only user-email">(contact@pvanlunteren.com)</span>
                </div>
                <a href="#2023-11-21 00:51:06"><div class="time">2023-11-21 00:51:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks for the tip. Will try that out üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-04 05:08:55">
            
                <img src="https://avatars.slack-edge.com/2022-10-21/4258571981060_1941d7130f7b94e11bc9_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Valentin »òtefan
                     <span class="print-only user-email">(valentin.stefan.vst@gmail.com)</span>
                </div>
                <a href="#2024-01-04 05:08:55"><div class="time">2024-01-04 05:08:55</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi @Peter van Lunteren, did you try out the copy-paste approach with SAM segmentation? I am curious if you achieved successful results. I attempted something similar for rare insect species that exist in our lab collection, but for which there are minimal images available on the internet. However, I was not successful. I think the model learns the "artificial" edges of the segmented insect more than the features of the insect or that the insects are dead and their coloration differs, among other variables (it's hard to disentangle the problem, as there are many variables). I am curious what results did you get and about similar studies as well.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-19 04:33:36">
            
                <img src="https://avatars.slack-edge.com/2022-02-09/3075038202214_f9ee2a2a94dcc3815f28_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Peter van Lunteren
                     <span class="print-only user-email">(contact@pvanlunteren.com)</span>
                </div>
                <a href="#2024-03-19 04:33:36"><div class="time">2024-03-19 04:33:36</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi @Valentin »òtefan, sorry for the late reply! For some reason it didn't notify me of this message.... But to answer your question, no I haven't tried the SAM method. I did try to incorporate Facebook's segment anything model to the automated camera trap classification pipeline (localise, crop, segment, remove background, stretch to fill square, classify), but that didn't yield very promising results because the SAM model wan't very good in segmenting blurry, black-black-and-white camera trap animals... But if you help the model find the object of interest it's actually pretty good.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Valentin »òtefan
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-22 10:13:13">
            
                <img src="https://secure.gravatar.com/avatar/a77b4c56a70382505cd40190557c02ed.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0008-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Tom Wye (Fishial.ai)
                     <span class="print-only user-email">(twye@fishial.ai)</span>
                </div>
                <a href="#2023-11-22 10:13:13"><div class="time">2023-11-22 10:13:13</div></a>
                <div class="msg">
                    <p>Any recommendations on any open source frameworks to take under water video (live stream) as input and frame grab moving objects to send to  into  <a href="http://Fishial.AI">Fishial.AI</a> API to identify the fish species?</p>
                    
                    
                    
                        <div class="message-reaction">
                        üêü Jon Van Oast, Kalindi Fonda
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-12-14 20:02:14">
            
                <img src="https://avatars.slack-edge.com/2021-04-30/2023568692212_f6aa1057696f5b133848_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Barry Brook
                     <span class="print-only user-email">(barry.brook@utas.edu.au)</span>
                </div>
                <a href="#2023-12-14 20:02:14"><div class="time">2023-12-14 20:02:14</div></a>
                <div class="msg">
                    <p>As noted in the <b>#new_papers</b> channel, we've released a new tool called MEWC (the Mega-Efficient Wildlife Classifier), which uses MegaDetector for object detection and EfficientNet for classification. Why is this interesting? Because you can do end-to-end training of your own custom model, with a few very simple steps! Preprint is here: <a href="https://doi.org/10.32942/X2ZW3D">https://doi.org/10.32942/X2ZW3D</a> The GitHub repo is here: <a href="https://github.com/zaandahl/mewc">https://github.com/zaandahl/mewc</a>  Would love to get feedback from users!</p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">zaandahl/mewc</a></div>
                                <div class="link-text">
                                    MEWC: Mega Efficient Wildlife Classifier
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Last updated</div>
                                        2 months ago
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Dan Morris, Piotr Tynecki, Sara Beery, Valentin Gabeff, Jon Van Oast, Sarah, Ed Miller, Timm Haucke
                        </div>
                    
                        <div class="message-reaction">
                        üôå Casey Clifton, Mitch Fennell, Sara Beery, Timm Haucke, Dan Watson, Rebecca Wilks
                        </div>
                    
                        <div class="message-reaction">
                        üëç:skin_tone_3: Alan Stenhouse
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-12-14 20:19:12">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-12-14 20:19:12"><div class="time">2023-12-14 20:19:12</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Really excited to try this!  Your documentation is excellent, including the fantastic logo.</p>

<p>First random question... the main page refers to using the TF object detection API, i.e., under "mewc-train", it says:</p>

<p>"This Docker image is used to train an EfficientNetV2 model using the TensorFlow Object Detection API."</p>

<p>...but it also says (consistent with what you wrote in your message here) that you're using EfficientNet for classification.  How does the TFODAPI fit in to the training process?</p>

<p>Second random question... you've jumped through some hoops to support both MDv4 and MDv5.  Have you found cases where MDv4 performs better, that make it worth all those hoops (and slower inference)?</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Barry Brook
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-12-14 20:26:30">
            
                <img src="https://avatars.slack-edge.com/2021-04-30/2023568692212_f6aa1057696f5b133848_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Barry Brook
                     <span class="print-only user-email">(barry.brook@utas.edu.au)</span>
                </div>
                <a href="#2023-12-14 20:26:30"><div class="time">2023-12-14 20:26:30</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks Dan, I'll ask Zach (who maintains the GitHub repo) about that inconsistency. We're definitely using EfficientNet in the classifier training, although it would be straightforward to plug-in other CNN. I'm currently working on the next version of MEWC which will use JAX as a back-end, and include option for a ViT classifier, but what we have up right now, using Tensorflow 2.11, works, so we froze it at that during development.</p>

<p>We kept the v4 option in there as more of a legacy, as we initially had problems with v5 on newer GPUs due to some PyTorch incompatibilities. We've since fixed that, but the option to use v4 remains. We default to v5a though, and that's all I use now.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Dan Morris, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-12-14 23:27:48">
            
                <img src="https://avatars.slack-edge.com/2021-04-30/2023568692212_f6aa1057696f5b133848_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Barry Brook
                     <span class="print-only user-email">(barry.brook@utas.edu.au)</span>
                </div>
                <a href="#2023-12-14 23:27:48"><div class="time">2023-12-14 23:27:48</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yep, that was a residual. Fixed on GitHub now, thanks Dan!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Dan Morris, Jon Van Oast
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-08 13:17:11">
            
                <img src="https://secure.gravatar.com/avatar/a0360ba0d982f9ce7905e6b242b3c672.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Tim Helming
                     <span class="print-only user-email">(timothy.helming@gmail.com)</span>
                </div>
                <a href="#2024-01-08 13:17:11"><div class="time">2024-01-08 13:17:11</div></a>
                <div class="msg">
                    <p>Hi all! I‚Äôm looking for suggestions for storing camera trap data that is easily transferable and accessible to multiple parties. I am working on a wildlife conflict effort. Ideally academics/wildlife managers help run the cameras and manage the data then give photos back to private landowners along with relevant discoveries. The functionality of Wildlife Insights is appealing, However I prefer the interface of Timelapse2. Excuse me if this is a rather basic question that has been beat to death.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-08 14:10:57">
            
                <img src="https://avatars.slack-edge.com/2023-12-05/6293495957653_b94076ee446fdfa7cf83_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Piotr Tynecki
                     <span class="print-only user-email">(piotr@tynecki.pl)</span>
                </div>
                <a href="#2024-01-08 14:10:57"><div class="time">2024-01-08 14:10:57</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Have you explored leveraging an end-to-end solution like the <strong>TRAPPER web application</strong>? It offers the flexibility to be installed on your local machine or server, providing customizable access for your stakeholders. TRAPPER boasts the capability to detect various objects, including humans, animals, vehicles, and blank images.. Additionally, it extends beyond detection, offering classification capabilities for over 20 European mammal species.</p>

<p>The Citizen Science UI is designed for user-friendly human annotation and expert review processes, making it particularly useful for non-technical and non-ecology-oriented users.</p>

<p>With its robust functionality, open source TRAPPER stands out as a comprehensive tool to optimize your camera trap initiatives</p>

<p><strong>Paper (2016)</strong>
<a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12571">https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12571</a></p>

<p><strong>Documentation</strong>
<a href="https://trapper-project.readthedocs.io/">https://trapper-project.readthedocs.io/</a></p>

<p><strong>Gitlab repository</strong>
<a href="https://gitlab.com/trapper-project/trapper">https://gitlab.com/trapper-project/trapper</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-09 23:04:10">
            
                <img src="https://avatars.slack-edge.com/2023-11-26/6271497607856_ed052afd9c0eaaf11da0_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Casey Clifton
                     <span class="print-only user-email">(caseyclifton@proton.me)</span>
                </div>
                <a href="#2024-01-09 23:04:10"><div class="time">2024-01-09 23:04:10</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hey @Piotr Tynecki - do you know how i can access the demo?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-10 00:39:04">
            
                <img src="https://avatars.slack-edge.com/2023-12-05/6293495957653_b94076ee446fdfa7cf83_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Piotr Tynecki
                     <span class="print-only user-email">(piotr@tynecki.pl)</span>
                </div>
                <a href="#2024-01-10 00:39:04"><div class="time">2024-01-10 00:39:04</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Casey Clifton <a href="https://demo.trapper-project.org/">https://demo.trapper-project.org/</a> register a new account, I will active it</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚úÖ Casey Clifton
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-16 01:15:14">
            
                <img src="https://avatars.slack-edge.com/2022-09-14/4085609422212_0be35bb86f58e99d445f_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Bunsen
                     <span class="print-only user-email">(notbot@gmail.com)</span>
                </div>
                <a href="#2024-02-16 01:15:14"><div class="time">2024-02-16 01:15:14</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi @Piotr Tynecki, is it possible to activate my account as well? I've been very curious to try the demo. <a href="mailto:notbot@gmail.com">notbot@gmail.com</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-16 03:09:52">
            
                <img src="https://avatars.slack-edge.com/2023-12-05/6293495957653_b94076ee446fdfa7cf83_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Piotr Tynecki
                     <span class="print-only user-email">(piotr@tynecki.pl)</span>
                </div>
                <a href="#2024-02-16 03:09:52"><div class="time">2024-02-16 03:09:52</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Michael Bunsen sure, I shared data access on PW</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Michael Bunsen
                        </div>
                    
                        <div class="message-reaction">
                        üôè Michael Bunsen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-10 13:19:59">
            
                <img src="https://avatars.slack-edge.com/2022-03-01/3199474286960_ef65c4e2a89448f18475_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Anna Willoughby
                     <span class="print-only user-email">(arwill19@gmail.com)</span>
                </div>
                <a href="#2024-01-10 13:19:59"><div class="time">2024-01-10 13:19:59</div></a>
                <div class="msg">
                    <p>Hello! Do folks have experience selling your porjects' camera trap photos as prints, to raise funds for your project? I'm a PhD student hoping to raise funds for undergrads, which frequently are ineligible for stipends through typical small grant avenues. I realize this needs to be appropriately done based permit permissions etc...Looking for an easy to function service. I do have a newsletter through mailchimp which can be linked to shopify. Any other comment on this topic would be appreciate. Thanks!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-10 14:54:18">
            
                <img src="https://avatars.slack-edge.com/2022-08-31/4012229393526_dfb97e82305b3683f037_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Procko
                     <span class="print-only user-email">(xprockox@gmail.com)</span>
                </div>
                <a href="#2024-01-10 14:54:18"><div class="time">2024-01-10 14:54:18</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Not exactly an answer to your question, but I‚Äôve heard of some labs allowing people to ‚Äúadopt‚Äù a camera to support grad research. When someone adopts a camera, they pay some flat rate and all the images taken by that camera (minus human photos for privacy purposes) are delivered to the person who adopted the camera. Makes it a little more exciting when you can email someone saying ‚Äúyou‚Äôll never guess what YOUR camera just caught!!‚Äù</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ Dan Watson
                        </div>
                    
                        <div class="message-reaction">
                        üôå Dan Watson
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-11 14:28:47">
            
                <img src="https://avatars.slack-edge.com/2022-03-01/3199474286960_ef65c4e2a89448f18475_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Anna Willoughby
                     <span class="print-only user-email">(arwill19@gmail.com)</span>
                </div>
                <a href="#2024-01-11 14:28:47"><div class="time">2024-01-11 14:28:47</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* ooh, thanks! This is a great idea</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-12 08:58:39">
            
                <img src="https://secure.gravatar.com/avatar/a6bfc38f4b96788a07dfceb5c5497aa1.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Phuc Le
                     <span class="print-only user-email">(phuc.le@ug.fuv.edu.vn)</span>
                </div>
                <a href="#2024-01-12 08:58:39"><div class="time">2024-01-12 08:58:39</div></a>
                <div class="msg">
                    <p>Hi, I‚Äôm sorry if this question has been raised before, but has anyone tried using the out-of-the-box open-set GroundingDINO for animal detection in camera traps? I‚Äôve tested it with several camera trap images using the text prompt ‚Äúanimal,‚Äù and it seems quite good ü§î. Sample images in üßµ
<a href="https://github.com/IDEA-Research/GroundingDINO">https://github.com/IDEA-Research/GroundingDINO</a></p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">IDEA-Research/GroundingDINO</a></div>
                                <div class="link-text">
                                    Official implementation of the paper &#34;Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection&#34;
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Website</div>
                                        &lt;https://arxiv.org/abs/2303.05499&gt;
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        4061
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üòé Ed Miller, Sara Beery, Aakash Gupta
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-12 09:01:01">
            
                <img src="https://secure.gravatar.com/avatar/a6bfc38f4b96788a07dfceb5c5497aa1.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Phuc Le
                     <span class="print-only user-email">(phuc.le@ug.fuv.edu.vn)</span>
                </div>
                <a href="#2024-01-12 09:01:01"><div class="time">2024-01-12 09:01:01</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* These are images from MD repo, with the reptile ones are those reported failed by MD</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-15 04:49:36">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-01-15 04:49:36"><div class="time">2024-01-15 04:49:36</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Wow, that looks promising! Do you know the model size and overall inference time performance? I expect that using a foundational model might be heavier than using a YOLO-based Megadetector</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-15 12:42:50">
            
                <img src="https://secure.gravatar.com/avatar/a6bfc38f4b96788a07dfceb5c5497aa1.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Phuc Le
                     <span class="print-only user-email">(phuc.le@ug.fuv.edu.vn)</span>
                </div>
                <a href="#2024-01-15 12:42:50"><div class="time">2024-01-15 12:42:50</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* You are right, it is much heavier, 662Mb for the weight. I ran it 2 months ago with a batch of 7,000 images, and its execution time was 1.5 hour on a T4. They have crafted an easy-to-follow <a href="https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/zero-shot-object-detection-with-grounding-dino.ipynb">Colab notebook</a>, you can give it a try with your data.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">colab.research.google.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/zero-shot-object-detection-with-grounding-dino.ipynb">Google Colaboratory</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                
    
        <a href="https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/zero-shot-object-detection-with-grounding-dino.ipynb">
            <img class="preview" src="https://colab.research.google.com/img/colab_favicon_256px.png"
                width="260"
                 height="260" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/zero-shot-object-detection-with-grounding-dino.ipynb</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-15 12:44:31">
            
                <img src="https://secure.gravatar.com/avatar/a6bfc38f4b96788a07dfceb5c5497aa1.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Phuc Le
                     <span class="print-only user-email">(phuc.le@ug.fuv.edu.vn)</span>
                </div>
                <a href="#2024-01-15 12:44:31"><div class="time">2024-01-15 12:44:31</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I have recently done a project working with detecting tortoises and freshwater turtles. I had 20,000+ images and I used GroundingDINO to generate automatic annotations to train smaller and faster YOLOv8 network (with <code>text_prompt = 'a turtle'</code>). And to my surprise it worked very well. I manually annotated 500 images as ground-truth to evaluate GroundingDINO‚Äôs annotation, and the average IoU was around 0.9</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-16 04:34:06">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-01-16 04:34:06"><div class="time">2024-01-16 04:34:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Wow that sounds like a great idea! Will take that as an inspiration for my project. Thanks!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üòé Phuc Le
                        </div>
                    
                        <div class="message-reaction">
                        üôå Anton Alvarez
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-27 23:33:17">
            
                <img src="https://secure.gravatar.com/avatar/6889494ed025f18b701f2fb4dc71632f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0007-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Nate Harada
                     <span class="print-only user-email">(nharada1@gmail.com)</span>
                </div>
                <a href="#2024-02-27 23:33:17"><div class="time">2024-02-27 23:33:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I actually built an open source tool that does something like this! Uses a text model to generate a dataset and then applies a smaller DINO model for inference. It works pretty well, and I‚Äôm able to get it running in real time on an iPhone. Classification not object detection though</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-15 05:05:46">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-01-15 05:05:46"><div class="time">2024-01-15 05:05:46</div></a>
                <div class="msg">
                    <p>Hi, does anyone have experience in making your CV model robust to objects occlusion?
I remember @Dan Morris mentioned a similar problem in MDv4 - any tips to overcome it?</p>

<p>I am developing a Shark Detector but it suffers greatly from occlusions like the one attached?</p>

<p>So far I have implemented Cutout and Cutmix for 500 of the 5k training images, but there has been no specific gain.</p>

<p>Thanks a lot!</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-15 05:40:16">
            
                <img src="https://avatars.slack-edge.com/2021-05-08/2030294018551_55c7e50192aabb4d0794_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">»òtefan Istrate
                     <span class="print-only user-email">(stefan.istrate@gmail.com)</span>
                </div>
                <a href="#2024-01-15 05:40:16"><div class="time">2024-01-15 05:40:16</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* We (at Wildlife Insights) have seen significant robustness improvements by using RandAugment with the default parameters: <a href="https://keras.io/api/keras_cv/layers/augmentation/rand_augment/">https://keras.io/api/keras_cv/layers/augmentation/rand_augment/</a> (the paper is linked in the <code>References</code> section). We didn't experiment with Cutout and Cutmix specifically, but there's a way to include them as well in the RandAugment policy if needed: <a href="https://keras.io/api/keras_cv/layers/augmentation/random_augmentation_pipeline/#randomaugmentationpipeline-class">https://keras.io/api/keras_cv/layers/augmentation/random_augmentation_pipeline/#randomaugmentationpipeline-class</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-15 10:37:22">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2024-01-15 10:37:22"><div class="time">2024-01-15 10:37:22</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* My first instinct is not to overthink this, i.e. not to do anything special to handle occlusion.  If that image is representative of the type of occlusion you're seeing, and that type of occlusion is well-represented in training, I expect that any modern object detector will do fine.  For my two cents, if that's also representative of the size of the objects in your image, I would start with the largest YOLOv8 model that your training data will support.  Then I would only worry about specifically addressing occlusion if you have some evidence this is presenting a problem.  Since I assume the object is present in every image, I think your model will have no trouble learning to ignore it.</p>

<p>Re: MD... MDv4 didn't really have a problem with that kind of occlusion, the problem MDv4 had was different (though equally annoying, and probably more embarrassing), it was the case where small animals consistently appeared <em>in front of</em> an object like that (typically a bait post), and it got confused and suppressed the animal, basically because of inadequate representation in training.  It did OK on animals that are occluded (but clearly visible on both sides of the occlusion, like on your image) by trees and other animals.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-16 04:30:20">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-01-16 04:30:20"><div class="time">2024-01-16 04:30:20</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks Dan and Stefan for the hints!
Dan, my problem is that the training data (as attached) doesn‚Äôt well-represent the bait occlusion. So I have two avenues:</p>

<ol><li>Data-augment it to pseudo-represent it in the training</li><li>Manually collate and annotate a 200-500 dataset with such occlusions
What avenue would you go to?</li>
</ol>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-16 04:36:38">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-01-16 04:36:38"><div class="time">2024-01-16 04:36:38</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* </p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-16 05:14:24">
            
                <img src="https://avatars.slack-edge.com/2021-05-08/2030294018551_55c7e50192aabb4d0794_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">»òtefan Istrate
                     <span class="print-only user-email">(stefan.istrate@gmail.com)</span>
                </div>
                <a href="#2024-01-16 05:14:24"><div class="time">2024-01-16 05:14:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Personally I'm tempted to say that avenue (2) would give you better results. Also, how diverse are the bait objects (shape, angle, position etc)? Does your model perform poorly on occluded sharks (false negatives) or on empty bait-only images (false positives)? If the latter, maybe just showing the model some baits in training and say they are empty images without any shark in them would be enough.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-16 09:30:37">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2024-01-16 09:30:37"><div class="time">2024-01-16 09:30:37</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I agree with Stefan, my guess is that you already have enough data to train a preliminary model to make annotation faster in the cases where it works, and if you have plenty of unlabeled data available, annotating a few hundred images should be very fast with small numbers of objects present in each image.</p>

<p>I did some annotation recently for a related issue where objects could be split across an occlusion (in this case, very small pieces of the object on either side of a large occlusion), and it helped a lot to set up a hotkey to merge the boxes (i.e., delete all the boxes on the screen and create a new box that surrounds both boxes).  If you have a bunch of occlusions in a row and your detector is getting the objects but splitting them into two, now it's just two keystrokes per image (merge, next, merge, next, etc.).</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-16 09:34:07">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2024-01-16 09:34:07"><div class="time">2024-01-16 09:34:07</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris and I have been discussing annotation alot. @»òtefan Istrate can you tell us your annotation process in a very literal way. How did you go about annotating these images, what tools did you use, how did you decide what would be the highest value images to annotate?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-16 10:06:06">
            
                <img src="https://avatars.slack-edge.com/2021-05-08/2030294018551_55c7e50192aabb4d0794_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">»òtefan Istrate
                     <span class="print-only user-email">(stefan.istrate@gmail.com)</span>
                </div>
                <a href="#2024-01-16 10:06:06"><div class="time">2024-01-16 10:06:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Ben Weinstein: I guess you wanted to tag @Filippo Varini instead, to explain his annotation process.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-16 12:38:28">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-01-16 12:38:28"><div class="time">2024-01-16 12:38:28</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi @Ben Weinstein I have not performed any manual annotation. I have collated open source annotated datasets of sharks together.
I have then performed the data augmentation suggested in <a href="https://arxiv.org/abs/1906.11172">this paper</a> for 20% of images.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-16 13:25:12">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5729572396613_37c6726ad5d913013f67_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Aakash Gupta
                     <span class="print-only user-email">(aakash@thinkevolveconsulting.com)</span>
                </div>
                <a href="#2024-01-16 13:25:12"><div class="time">2024-01-16 13:25:12</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Why don't you try inserting those "bait boxes" in images where they are not present. Let the model learn the features.</p>

<p>This would be similar to generating new images with bait-occlusions being added in the pipeline.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-16 13:43:39">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2024-01-16 13:43:39"><div class="time">2024-01-16 13:43:39</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Filippo Varini, what is your test domain?  I.e., where do you want to run this model?  Are you running it on images that <strong>all</strong> have the occluding objects in them?  And do you already have lots of unlabeled data from those cameras?</p>

<p>If that's your target domain and you have unlabeled data, IMO the best marginal use of your time is labeling some of that data.</p>

<p>If that's your target domain and you don't have unlabeled data (in which case I would set your expectations low for your initial model), then I agree with Aakash's suggestion to paste that bait box over the fish in your training data, and - just as important - in images where they <strong>don't</strong> occlude the fish.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-17 07:29:19">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-01-17 07:29:19"><div class="time">2024-01-17 07:29:19</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi @Dan Morris and @Aakash Gupta, thanks for the tips.
Yes Dan, I have loads of unlabelled data and my test domain always has the occlusion, so I will try that avenue - thanks for the advice!
How many images do you suggest labelling, considering an existing training dataset of ~5k images?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-17 10:53:30">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2024-01-17 10:53:30"><div class="time">2024-01-17 10:53:30</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Personally I would set aside maybe 3-4 hours for your first round of adding boxes, not counting the time it takes you to set up your workflow.  If you have to create boxes from scratch, and you have ~1 object per image, and you already have long runs of images that you know have sharks, that's ~5 seconds per image, so that's maybe 3k boxes, after which I would train at least a preliminary model, then repeat the process one more time.  If you already have a preliminary model that works OK, and mostly you're confirming/merging/deleting boxes, you can probably get that down to &lt;1 second per image, but once you're doing it, the marginal cost of doing a bunch more is pretty low, so I would still set aside 3-4 hours and get maybe 10k-20k boxes.  I would prioritize diversity across sites as much as you can, even if it results in slightly lower volume.  You may or may not even end up using your current labeled dataset once you have a bunch of boxes from your target domain.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-17 17:21:14">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-01-17 17:21:14"><div class="time">2024-01-17 17:21:14</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* That makes total sense. Thanks @Dan Morris!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-31 10:45:06">
            
                <img src="https://secure.gravatar.com/avatar/a77b4c56a70382505cd40190557c02ed.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0008-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Tom Wye (Fishial.ai)
                     <span class="print-only user-email">(twye@fishial.ai)</span>
                </div>
                <a href="#2024-01-31 10:45:06"><div class="time">2024-01-31 10:45:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Filippo Varini we have a segmentation model at <a href="https://github.com/fishial/fish-identification">https://github.com/fishial/fish-identification</a> you maybe able to use for labeling. Also <a href="http://Fishial.ai">Fishial.ai</a> is a non profit project that has created a labeling portal that you can checkout at <a href="http://fishial.ai">fishial.ai</a> if you share your annotations back to the public usage is free</p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">fishial/fish-identification</a></div>
                                <div class="link-text">
                                    Object Detection Model
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        20
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        Jupyter Notebook
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-31 10:48:22">
            
                <img src="https://secure.gravatar.com/avatar/a77b4c56a70382505cd40190557c02ed.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0008-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Tom Wye (Fishial.ai)
                     <span class="print-only user-email">(twye@fishial.ai)</span>
                </div>
                <a href="#2024-01-31 10:48:22"><div class="time">2024-01-31 10:48:22</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Here's a example of the segmentation</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-27 23:31:16">
            
                <img src="https://secure.gravatar.com/avatar/6889494ed025f18b701f2fb4dc71632f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0007-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Nate Harada
                     <span class="print-only user-email">(nharada1@gmail.com)</span>
                </div>
                <a href="#2024-02-27 23:31:16"><div class="time">2024-02-27 23:31:16</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I‚Äôm late to the party but do you just need to know if a shark is in frame or is the bounding box important?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-28 06:25:58">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-02-28 06:25:58"><div class="time">2024-02-28 06:25:58</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Nate! bbox is important because we need to extract the patch for a downstream classifier. How come?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-16 03:13:30">
            
                <img src="https://avatars.slack-edge.com/2022-09-26/4155235320544_f9486cd5599ee07073a1_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Paul Bodesheim
                     <span class="print-only user-email">(paul.bodesheim@uni-jena.de)</span>
                </div>
                <a href="#2024-01-16 03:13:30"><div class="time">2024-01-16 03:13:30</div></a>
                <div class="msg">
                    <p>üì£ Hi all! Please note that the paper submission deadline for the Special Issue on "Camera traps, AI, and ecology" in the IET Computer Vision Journal has been extended to March 4th. More details can be found <a href="https://ietresearch.onlinelibrary.wiley.com/hub/journal/17519640/homepage/call-for-papers/si-2023-000769">here</a>. Looking forward to receiving your contributions and to read about your latest research.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Piotr Tynecki, Meredith Palmer, Sara Beery, Jon Van Oast, Dan Morris, Rita Pucci, Timm Haucke
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-15 09:03:39">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-02-15 09:03:39"><div class="time">2024-02-15 09:03:39</div></a>
                <div class="msg">
                    <p>Hi all, do you have any suggestion for a simple UI tool to visualise and clean annotations of an object detector?</p>

<p>Input:
‚Ä¢ frames with detection
‚Ä¢ detection csv with 5 highest-confidence species
Requirements:
‚Ä¢ visualise the bboxed image
‚Ä¢ accept, reject or select (using the 5 species suggestions) the speceis
Very happy to use an off-the-shelf solution if it exists!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-15 09:13:21">
            
                <img src="https://avatars.slack-edge.com/2023-12-05/6293495957653_b94076ee446fdfa7cf83_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Piotr Tynecki
                     <span class="print-only user-email">(piotr@tynecki.pl)</span>
                </div>
                <a href="#2024-02-15 09:13:21"><div class="time">2024-02-15 09:13:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Filippo Varini Did you try to look at the Roboflow / CVAT software? How they resolve this kind of situation could inspire you.</p>

<p>I know how it was resolved in <strong>TRAPPER</strong> software but the old UI is not so fancy and robus as the new one "Citizen Science" (not published yet).</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-15 09:57:31">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-02-15 09:57:31"><div class="time">2024-02-15 09:57:31</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Piotr, thanks for the suggestion, I will have a look at it!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-15 10:31:39">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2024-02-15 10:31:39"><div class="time">2024-02-15 10:31:39</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I use labelme for this:</p>

<p><a href="https://github.com/labelmeai/labelme">https://github.com/labelmeai/labelme</a></p>

<p>I found labelme to be very easy to modify for minor workflow customizations, and it was easy to get data into the format it likes.  IMO the goal in making a review workflow efficient is always to get your hands off the mouse entirely, and for what you're describing, I think you could easily get everything down to keyboard shortcuts with minor changes to labelme.  I did this for a few camera trap data sets, though I expect the specific changes I made are particular to the fact that I had a small number of objects in each image, and if you have lots of objects in each image, you might need slightly different tweaks:</p>

<p><a href="https://github.com/agentmorris/labelme">https://github.com/agentmorris/labelme</a></p>

<p>I also really like BoundingBoxEditor, though I mostly only use it as a viewer, and my lack of Java-ness makes it hard for me to modify, but it's quite slick:</p>

<p><a href="https://github.com/mfl28/BoundingBoxEditor">https://github.com/mfl28/BoundingBoxEditor</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üòé Jon Van Oast
                        </div>
                    
                        <div class="message-reaction">
                        üôè Filippo Varini
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-18 11:04:41">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5729572396613_37c6726ad5d913013f67_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Aakash Gupta
                     <span class="print-only user-email">(aakash@thinkevolveconsulting.com)</span>
                </div>
                <a href="#2024-02-18 11:04:41"><div class="time">2024-02-18 11:04:41</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Robo-flow and labelme are both great solutions.</p>

<p>Here's a longer list of freely available annotation tools:
<a href="https://www.thinkevolveconsulting.com/list-of-open-source-annotation-tools-for-machine-learning-research/">https://www.thinkevolveconsulting.com/list-of-open-source-annotation-tools-for-machine-learning-research/</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå:skin_tone_3: Alan Stenhouse
                        </div>
                    
                        <div class="message-reaction">
                        üôå Filippo Varini, Don Cosseboom
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-29 18:57:35">
            
                <img src="https://avatars.slack-edge.com/2023-02-14/4789365285895_d9006f78362bdea6ce1c_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Cara Appel
                     <span class="print-only user-email">(appelc@oregonstate.edu)</span>
                </div>
                <a href="#2024-02-29 18:57:35"><div class="time">2024-02-29 18:57:35</div></a>
                <div class="msg">
                    <p>Hello! Is anyone is aware of attempts to detect fire in images (camera traps or otherwise)? I am working in a system that has frequent, short-duration fires that are regularly captured on camera. It would be useful to be able to detect when these events happen. We use a YOLO multiclass model for species ID, and I suppose we could draw bounding boxes around flames and add a new class, but this doesn't quite seem like the right approach. I am also not convinced that training a model would be any more efficient than scrolling through to find fire images manually (although we do have a LOT of false triggers), but I thought it could be interesting üòÑ Some example images attached. Thanks everyone!</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üî• Sara Beery, Michael Bunsen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-29 19:42:49">
            
                <img src="https://avatars.slack-edge.com/2022-08-31/4012229393526_dfb97e82305b3683f037_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Michael Procko
                     <span class="print-only user-email">(xprockox@gmail.com)</span>
                </div>
                <a href="#2024-02-29 19:42:49"><div class="time">2024-02-29 19:42:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Given how drastically different fire looks from most other things in the photos, I would imagine running a classification algorithm (something akin to the <a href="https://github.com/CV4EcologySchool/ct_classifier">ct_classifier</a> we used this summer) would suffice. Just a binary classifier to say fire vs. no fire?</p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">CV4EcologySchool/ct_classifier</a></div>
                                <div class="link-text">
                                    Example repository for the CV4Ecology 2022 Summer School (lecture 4)
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        6
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        Python
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üôè:skin_tone_2: Cara Appel
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-01 08:13:25">
            
                <img src="https://avatars.slack-edge.com/2022-01-11/2931207259445_5de57e9f4cb02eddd519_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Lukas Picek
                     <span class="print-only user-email">(lukaspicek@gmail.com)</span>
                </div>
                <a href="#2024-03-01 08:13:25"><div class="time">2024-03-01 08:13:25</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Cara, try Yolo World ‚Äî zero shot object detector. It should work well on your data. Here is a link --&gt; <a href="https://github.com/AILab-CVC/YOLO-World">https://github.com/AILab-CVC/YOLO-World</a></p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">AILab-CVC/YOLO-World</a></div>
                                <div class="link-text">
                                    [CVPR 2024] Real-Time Open-Vocabulary Object Detection
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Website</div>
                                        &lt;https://www.yoloworld.cc&gt;
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        2431
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç:skin_tone_2: Cara Appel
                        </div>
                    
                        <div class="message-reaction">
                        üëç Anton Alvarez
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-01 15:55:24">
            
                <img src="https://avatars.slack-edge.com/2023-02-14/4789365285895_d9006f78362bdea6ce1c_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Cara Appel
                     <span class="print-only user-email">(appelc@oregonstate.edu)</span>
                </div>
                <a href="#2024-03-01 15:55:24"><div class="time">2024-03-01 15:55:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* thank you both üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-04 13:11:15">
            
                <img src="https://secure.gravatar.com/avatar/e580d2cbeb30d149ef50bc735767289f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0025-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Matt Hron
                     <span class="print-only user-email">(matt.hron@wildlifeprotectionsolutions.org)</span>
                </div>
                <a href="#2024-03-04 13:11:15"><div class="time">2024-03-04 13:11:15</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Cara. We've thought about doing something similar in adding another class for 'fire' to our YOLO multiclass model for species ID but haven't tried it yet due to limited resources, wanting to build a bigger training dataset (we have about 200 images with fire or smoke), and uncertainty whether it would be a useful approach. Our use case is real-time detection, and I'd be very interested if you come up with something. I'd be happy to contribute our data for training, and I'll let you know if/when we try it out.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç:skin_tone_2: Cara Appel
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-06 08:22:22">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5729572396613_37c6726ad5d913013f67_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Aakash Gupta
                     <span class="print-only user-email">(aakash@thinkevolveconsulting.com)</span>
                </div>
                <a href="#2024-03-06 08:22:22"><div class="time">2024-03-06 08:22:22</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I used a different approach in one of our projects. I use a small ViT Q&amp;A model. You need to prompt it with the image an a simple query on whether there is a fire in the image. And it will give you a relevant output.</p>

<p>This is what you will call as a zero-shot approach</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Lukas Picek
                        </div>
                    
                        <div class="message-reaction">
                        üëç:skin_tone_2: Cara Appel
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-04-18 17:16:28">
            
                <img src="https://secure.gravatar.com/avatar/2a41b678b0e80a5d037cf16a0b7d8592.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0022-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Arthur Caillau
                     <span class="print-only user-email">(arthur@caillau.me)</span>
                </div>
                <a href="#2024-04-18 17:16:28"><div class="time">2024-04-18 17:16:28</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* There are some companies and NGOs doing this already. Here is one example: <a href="https://pyronear.org/en/">https://pyronear.org/en/</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">pyronear.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://pyronear.org/en/">Pyronear</a></div>
                                <div class="link-text">
                                    D√©tection pr√©coce de feux de for√™t
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://pyronear.org/en/</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-04-18 18:10:02">
            
                <img src="https://avatars.slack-edge.com/2023-02-14/4789365285895_d9006f78362bdea6ce1c_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Cara Appel
                     <span class="print-only user-email">(appelc@oregonstate.edu)</span>
                </div>
                <a href="#2024-04-18 18:10:02"><div class="time">2024-04-18 18:10:02</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Arthur Caillau thank you!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-04-22 14:35:30">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5729572396613_37c6726ad5d913013f67_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Aakash Gupta
                     <span class="print-only user-email">(aakash@thinkevolveconsulting.com)</span>
                </div>
                <a href="#2024-04-22 14:35:30"><div class="time">2024-04-22 14:35:30</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Added a HF space using a VQA model</p>

<p><a href="https://huggingface.co/spaces/skylord/FireDetector">https://huggingface.co/spaces/skylord/FireDetector</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">huggingface.co</div>
                            
                            
                                
                                <div class="link-title"><a href="https://huggingface.co/spaces/skylord/FireDetector">FireDetector - a Hugging Face Space by skylord</a></div>
                                <div class="link-text">
                                    Discover amazing ML apps made by the community
                                </div>
                                
                                
    
        <a href="https://huggingface.co/spaces/skylord/FireDetector">
            <img class="preview" src="https://cdn-thumbnails.huggingface.co/social-thumbnails/spaces/skylord/FireDetector.png"
                width="1200"
                 height="648" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://huggingface.co/spaces/skylord/FireDetector</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-25 06:56:53">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-03-25 06:56:53"><div class="time">2024-03-25 06:56:53</div></a>
                <div class="msg">
                    <p>Hi all, has anyone faced an issue with <strong>reading GoPro videos with OpenCV</strong>?
Basically, by using the <https://stackoverflow.com/questions/78039408/cv2-ffmpeg-grabframe-packet-read-max-attempts-exceeded-error-after-exactly-rea#:~:text=success%2C%20frame%20%3D%20capture.read()|standard video-reading workflow>, CV2 issues the following warning
<code>[ WARN:0@2.186] global cap_ffmpeg_impl.hpp:1505 grabFrame packet read max attempts exceeded, if your video have multiple streams (video, audio) try to increase attempt limit by setting environment variable OPENCV_FFMPEG_READ_ATTEMPTS (current value is 4096)</code></p>

<p>As recorded <a href="https://answers.opencv.org/question/189349/known-issue-with-gopro-movie-codec-stops-reading-after-26-frames/">here</a> and <a href="https://stackoverflow.com/questions/78039408/cv2-ffmpeg-grabframe-packet-read-max-attempts-exceeded-error-after-exactly-rea">here</a>, apparently this is a known issue where OpenCV fails with GoPro‚Äôs audio, encoded as GoPro AAC.</p>

<p>In fact, removing all the streams but video with <code>ffmpeg -i &amp;lt;input_video&amp;gt; -map 0:v -c copy &amp;lt;output&amp;gt;</code> solves the issue.</p>

<p>I would like to find a more elegant solution that does not require creating a whole new video.</p>

<p>Has anyone encountered a similar problem?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-25 10:14:14">
            
                <img src="https://avatars.slack-edge.com/2023-08-10/5721228585203_075088cb99a4c3c39a3e_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Timm Haucke
                     <span class="print-only user-email">(timm@haucke.xyz)</span>
                </div>
                <a href="#2024-03-25 10:14:14"><div class="time">2024-03-25 10:14:14</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* If you‚Äôre using Python, I recommend trying <a href="https://github.com/PyAV-Org/PyAV">https://github.com/PyAV-Org/PyAV</a> which is much more flexible compared to OpenCVs video support</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-25 10:20:34">
            
                <img src="https://avatars.slack-edge.com/2023-11-21/6229085551651_3e574356e54886399567_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Filippo Varini
                     <span class="print-only user-email">(fppvrn@gmail.com)</span>
                </div>
                <a href="#2024-03-25 10:20:34"><div class="time">2024-03-25 10:20:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thank you Timm!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-25 15:42:50">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2024-03-25 15:42:50"><div class="time">2024-03-25 15:42:50</div></a>
                <div class="msg">
                    <p>Hi All, As part of extending the work we are doing at the <a href="https://bearid.org/">BearID Project</a>, we are thinking about integrating the models we are developing into open source camera trap project. This could include MegaDetector, swappable specias detectors and swappable individual reID. I'd like to aim for something that could be run locally or as a service, and possibly across platforms. I'd like to support images and videos. My leading candidates at the moment are <a href="https://trapper-project.readthedocs.io/en/latest/">TRAPPER</a> and <a href="https://camelot-project.readthedocs.io/en/latest/">Camelot</a>.</p>

<p>Any thoughts? Is someone already doing this?</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Piotr Tynecki, Dante Wasmuht, Matthias Zuerl, Sara Beery, Anton Alvarez, Ian Ingram
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-25 16:40:03">
            
                <img src="https://avatars.slack-edge.com/2023-12-05/6293495957653_b94076ee446fdfa7cf83_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Piotr Tynecki
                     <span class="print-only user-email">(piotr@tynecki.pl)</span>
                </div>
                <a href="#2024-03-25 16:40:03"><div class="time">2024-03-25 16:40:03</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Ed Miller I'm available to discuss <strong>TRAPPER</strong> and <strong>TrapperAI</strong> with you (as a Trapper core developer). Our platform now supports object detection, anonymization of humans/vehicles, and species classification (european mammals and birds) for both images and videos as well as Citizen Science mode. TrapperAI module is able to execute any kind of AI model for wildlife in the cloud/standalone, so it should not be a problem to dockerize your models and include them in the pipeline.</p>

<p>Happy to talk üôÇ.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ed Miller, Anton Alvarez, Michael Bunsen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-25 17:55:49">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2024-03-25 17:55:49"><div class="time">2024-03-25 17:55:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* One other option I would take a look at, at least for workflow inspiration, even if you don't use the actual code... TrapTagger is also open-source, and their workflow incorporates an individual ID stage (based on HotSpotter that last time I looked, I don't know how modular it is):</p>

<p><a href="https://wildeyeconservation.org/traptagger/">https://wildeyeconservation.org/traptagger/</a>
<a href="https://github.com/WildEyeConservation/TrapTagger">https://github.com/WildEyeConservation/TrapTagger</a></p>

<p>I can't really speak to the ease of deployment, but the workflow is nice.  That said, Piotr's quick response is a good reason to focus on TRAPPER first. üôÇ</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ed Miller, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-25 20:11:48">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2024-03-25 20:11:48"><div class="time">2024-03-25 20:11:48</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Piotr Tynecki Thank you for the quick response! I will follow up with you via DM.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-25 20:12:49">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2024-03-25 20:12:49"><div class="time">2024-03-25 20:12:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris Thanks for the link to WildEye. I didn't realize they had open source. I'll check it out.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-26 09:58:18">
            
                <img src="https://avatars.slack-edge.com/2022-11-09/4345761822595_8ddb0ad25ec671ccef4d_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Anton Alvarez
                     <span class="print-only user-email">(aalvarez@wwf.es)</span>
                </div>
                <a href="#2024-03-26 09:58:18"><div class="time">2024-03-26 09:58:18</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi @Ed Miller, I have used TrapTagger a little and incorporate a fancy workflow for the re-id, and also a early integration with Wildbook. But I think only support images, not videos.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ed Miller
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-05-20 16:22:51">
            
                <img src="https://secure.gravatar.com/avatar/cba4e76eb3f3e069749448611f87336c.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0004-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Kyra Swanson
                     <span class="print-only user-email">(tswanson@sdzwa.org)</span>
                </div>
                <a href="#2024-05-20 16:22:51"><div class="time">2024-05-20 16:22:51</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi @Ed Miller we are also developing a pipeline at SDZWA</p>

<p><a href="https://github.com/conservationtechlab/animl-r">https://github.com/conservationtechlab/animl-r</a>
<a href="https://github.com/conservationtechlab/animl-py">https://github.com/conservationtechlab/animl-py</a></p>

<p>with integration with CameraBase and eventually other forms of ReID.  We process videos by extracting a small number of frames first. It currently uses MegaDetector for bounding boxes and our own trained models for classification, but they are swappable.</p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">conservationtechlab/animl-r</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        18
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        R
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">conservationtechlab/animl-py</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        3
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        Jupyter Notebook
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Ed Miller
                        </div>
                    
                        <div class="message-reaction">
                        ü¶è Ian Ingram
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-05-20 17:03:03">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2024-05-20 17:03:03"><div class="time">2024-05-20 17:03:03</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi @Kyra Swanson. I spoke with @Ian Ingram a while back (via Russ V.). I am very famliar with your great work! In fact, we have used animl-py to test some of your existing models on some of our data. I was not familiar with CameraBase. Is this still under active development?</p>

<p>I am looking to potentially integrate AI packages with <a href="https://trapper-project.readthedocs.io/en/latest/index.html">TRAPPER</a>, using the <a href="https://gitlab.com/trapper-project/trapper-ai">TRAPPER AI</a> package they will release soon. TRAPPER already has some integration with MegaDetector and species classifiers like <a href="https://huggingface.co/OSCF/TrapperAI-v02.2024">their own model for Europe</a>. What I like about TRAPPER is it is platform independent (runs on Docker), uses a web browser interface, and can be run locally or in the cloud.</p>

<p>It would be great if we can collaborate to build out more models for the Americas and integrate them with relevant software packages like TRAPPER or CameraBase. I believe you are already extending your S. America models, which would be beneficial for work we are starting in Ecuador. We also have data for Western Canada we could use for training.</p>

<p>Happy to discuss here, via email and/or on a call!</p>

<p>Ed</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">GitLab</div>
                            
                            
                                
                                <div class="link-title"><a href="https://gitlab.com/trapper-project/trapper-ai">trapper-project / trapper-ai ¬∑ GitLab</a></div>
                                <div class="link-text">
                                    Module responsible for the integration and configuration of AI models for object detection and species classification. This component is organized using the Trapper AI Manager web-based component and...
                                </div>
                                
                                
    
        <a href="https://gitlab.com/trapper-project/trapper-ai">
            <img class="preview" src="https://gitlab.com/uploads/-/system/project/avatar/57669846/Zrzut_ekranu_z_2024-04-11_11-57-40.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://gitlab.com/trapper-project/trapper-ai</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">huggingface.co</div>
                            
                            
                                
                                <div class="link-title"><a href="https://huggingface.co/OSCF/TrapperAI-v02.2024">OSCF/TrapperAI-v02.2024 ¬∑ Hugging Face</a></div>
                                <div class="link-text">
                                    We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.
                                </div>
                                
                                
    
        <a href="https://huggingface.co/OSCF/TrapperAI-v02.2024">
            <img class="preview" src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/OSCF/TrapperAI-v02.2024.png"
                width="1200"
                 height="648" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://huggingface.co/OSCF/TrapperAI-v02.2024</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Piotr Tynecki
                        </div>
                    
                        <div class="message-reaction">
                        ü¶¨ Piotr Tynecki
                        </div>
                    
                        <div class="message-reaction">
                        ü¶è Ian Ingram
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-05-20 17:08:59">
            
                <img src="https://secure.gravatar.com/avatar/cba4e76eb3f3e069749448611f87336c.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0004-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Kyra Swanson
                     <span class="print-only user-email">(tswanson@sdzwa.org)</span>
                </div>
                <a href="#2024-05-20 17:08:59"><div class="time">2024-05-20 17:08:59</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yeah we're a little behind in terms of gui, but I'm more than happy to talk to you about a specially trained model that might incorporate species from the other models we have. If you'd like to chat directly im at <a href="mailto:tswanson@sdzwa.org">tswanson@sdzwa.org</a>.
 Camera Base was made by our own Mathias Tobler about a decade ago and while it is still technically under development, we have long term plans to completely redo it and fully integrate aniML.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-05-20 17:12:40">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2024-05-20 17:12:40"><div class="time">2024-05-20 17:12:40</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I'll follow up by email soon!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Kyra Swanson
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-05-21 03:01:04">
            
                <img src="https://avatars.slack-edge.com/2023-12-05/6293495957653_b94076ee446fdfa7cf83_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Piotr Tynecki
                     <span class="print-only user-email">(piotr@tynecki.pl)</span>
                </div>
                <a href="#2024-05-21 03:01:04"><div class="time">2024-05-21 03:01:04</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Ed Miller @Kyra Swanson From my experience, joining forces is always the best and optimal solution. TRAPPER team is always open to meeting with a larger group of researchers and engineers. For your information, we are working on a next version of TrapperAI Model and have also added initial support for <strong>MegaDetector v6</strong> (beta). Happy to share more details during the meeting.</p>
                    
                    
                    
                        <div class="message-reaction">
                        ü¶è Ian Ingram
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-07-16 04:42:26">
            
                <img src="https://avatars.slack-edge.com/2024-06-26/7346257133377_8c66898cf803e85d6604_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Alba M√°rquez-Rodr√≠guez
                     <span class="print-only user-email">(albamrqz751@gmail.com)</span>
                </div>
                <a href="#2024-07-16 04:42:26"><div class="time">2024-07-16 04:42:26</div></a>
                <div class="msg">
                    <p>Hi! We have camera trap video data annotated with Bounding Boxes and we would like to publish them in a repo, do you have any recommendations on where to publish them? Thanks!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-07-16 04:56:58">
            
                <img src="https://avatars.slack-edge.com/2022-02-09/3075038202214_f9ee2a2a94dcc3815f28_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Peter van Lunteren
                     <span class="print-only user-email">(contact@pvanlunteren.com)</span>
                </div>
                <a href="#2024-07-16 04:56:58"><div class="time">2024-07-16 04:56:58</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Alba, the <a href="https://lila.science/">Labeled Information Library of Alexandria: Biology and Conservation</a> would be perfect for that! It is maintained by @Dan Morris, but you can also send an email to <a href="mailto:info@lila.science">info@lila.science</a> for upload instructions or more info.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="https://lila.science/">LILA BC (Labeled Image Library of Alexandria: Biology and Conservation)</a></div>
                                <div class="link-text">
                                    LILA BC is a repository for archival data sets related to biology and conservation. Our intention is to create a valuable resource for the scientific community, including for machine learning researchers and/or those that want to harness machine learning for biology and conservation. Machine learning depends on labeled data, but getting access to such data in biology and conservation is a challenge. Consequently, everyone benefits when more labeled data is made available.
                                </div>
                                
                                
    
        <a href="https://lila.science/">
            <img class="preview" src="http://lila.science/wp-content/uploads/2018/10/IMG_1881_web.jpg"
                width="600"
                 height="450" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://lila.science/</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-07-16 05:04:14">
            
                <img src="https://avatars.slack-edge.com/2024-06-26/7346257133377_8c66898cf803e85d6604_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Alba M√°rquez-Rodr√≠guez
                     <span class="print-only user-email">(albamrqz751@gmail.com)</span>
                </div>
                <a href="#2024-07-16 05:04:14"><div class="time">2024-07-16 05:04:14</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* great! thank you ‚ò∫Ô∏è</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-07-16 11:09:21">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5729572396613_37c6726ad5d913013f67_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Aakash Gupta
                     <span class="print-only user-email">(aakash@thinkevolveconsulting.com)</span>
                </div>
                <a href="#2024-07-16 11:09:21"><div class="time">2024-07-16 11:09:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Place it on HuggingFace dataset for greater visibility!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç michele volpi
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
        
    </div>
</div>

<script>
(function() {
  var sidebar = document.querySelector('#sidebar');
  var selected = document.querySelector('.active');
  sidebar.scrollTop = selected.offsetTop - 200;

  // make dropdown from channel title
  var channel_title = document.querySelector("#channel-title");
  var channel_dropdown = document.querySelector("#channel-list");
  channel_title.addEventListener('click', function() {
    channel_title.classList.toggle('arrow');
    channel_dropdown.classList.toggle('close');
  });

  // make dropdown from group title
  var group_title = document.querySelector("#group-title");
  var group_dropdown = document.querySelector("#group-list");
  group_title.addEventListener('click', function() {
    group_title.classList.toggle('arrow');
    group_dropdown.classList.toggle('close');
  });

  // make dropdown from dm title
  var dm_title = document.querySelector("#dm-title");
  var dm_dropdown = document.querySelector("#dms-list");
  dm_title.addEventListener('click', function() {
    dm_title.classList.toggle('arrow');
    dm_dropdown.classList.toggle('close');
  });

  // make dromdown from group dm title
  var mpim_title = document.querySelector("#mpim-title");
  var mpim_dropdown = document.querySelector("#mpims-list");
  mpim_title.addEventListener('click', function() {
    mpim_title.classList.toggle('arrow');
    mpim_dropdown.classList.toggle('close');
  });
})()
</script>
</body>
</html>