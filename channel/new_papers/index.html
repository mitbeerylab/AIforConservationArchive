<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Slack Export - #new_papers</title>
    
    <link rel=stylesheet type=text/css
          href="../../static/viewer.css">
    
</head>
<body>
<div id="slack-archive-viewer">
    
    <div id="sidebar">
        <h3 id="channel-title">Public Channels</h3>
        <ul class="list" id="channel-list">
            
                <li class="channel">
                    <a href="../ai4pacificislandseabirds/index.html">
                        # ai4pacificislandseabirds
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../animal_re-id/index.html">
                        # animal_re-id
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../audio/index.html">
                        # audio
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../camera-traps-hardware/index.html">
                        # camera-traps-hardware
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../camera_traps/index.html">
                        # camera_traps
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../camtrapai-workshops/index.html">
                        # camtrapai-workshops
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../cv4animals/index.html">
                        # cv4animals
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../cvml-solutions-for-challenging-real-world-conservation-problems/index.html">
                        # cvml-solutions-for-challenging-real-world-conservation-problems
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../cvpr2023/index.html">
                        # cvpr2023
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../datasets/index.html">
                        # datasets
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../elephant_id_database_general/index.html">
                        # elephant_id_database_general
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../esa_2023_happy_hour/index.html">
                        # esa_2023_happy_hour
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../general/index.html">
                        # general
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../help_needed/index.html">
                        # help_needed
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../jobs/index.html">
                        # jobs
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../marine/index.html">
                        # marine
                    </a>
                </li>
            
                <li class="channel active">
                    <a href="index.html">
                        # new_papers
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../news/index.html">
                        # news
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../petitions/index.html">
                        # petitions
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../proj-id-and-count-salmon/index.html">
                        # proj-id-and-count-salmon
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../public-engagement/index.html">
                        # public-engagement
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../random/index.html">
                        # random
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../region-pnw/index.html">
                        # region-pnw
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../region-us-ne/index.html">
                        # region-us-ne
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../region-us-sw/index.html">
                        # region-us-sw
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../resources/index.html">
                        # resources
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../seadronesee/index.html">
                        # seadronesee
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../tdwg_ml/index.html">
                        # tdwg_ml
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../upcoming_events/index.html">
                        # upcoming_events
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../what-is-that/index.html">
                        # what-is-that
                    </a>
                </li>
            
                <li class="channel">
                    <a href="../wildlifeinsights/index.html">
                        # wildlifeinsights
                    </a>
                </li>
            
        </ul>
        <h3 id="group-title">Private Channels</h3>
        <ul class="list" id="group-list">
            
        </ul>
        <h3 id="dm-title">Direct Messages</h3>
        <ul class="list" id="dms-list">
            
        </ul>
        <h3 id="mpim-title">Group Direct Messages</h3>
        <ul class="list" id="mpims-list">
            
        </ul>
    </div>
    
    <div class="messages">
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-09 13:20:38">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-08-09 13:20:38"><div class="time">2019-08-09 13:20:38</div></a>
                <div class="msg">
                    <p>@Sara Beery has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_purpose ">
        <div id="2019-08-09 13:20:38">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-08-09 13:20:38"><div class="time">2019-08-09 13:20:38</div></a>
                <div class="msg">
                    <p>set the channel description: Share new conservation-related papers with the community</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-09 13:45:17">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/710599959587_49af2a4146e1b29a50dd_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">gvanhorn
                     <span class="print-only user-email">(grv22@cornell.edu)</span>
                </div>
                <a href="#2019-08-09 13:45:17"><div class="time">2019-08-09 13:45:17</div></a>
                <div class="msg">
                    <p>@gvanhorn has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-08-09 13:49:05">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-08-09 13:49:05"><div class="time">2019-08-09 13:49:05</div></a>
                <div class="msg">
                    <p>Interesting recent review paper: Tackling Climate Change with Machine Learning (<a href="https://arxiv.org/abs/1906.05433">https://arxiv.org/abs/1906.05433</a>)</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/1906.05433">Tackling Climate Change with Machine Learning</a></div>
                                <div class="link-text">
                                    Climate change is one of the greatest challenges facing humanity, and we, as machine learning experts, may wonder how we can help. Here we describe how machine learning can be a powerful tool in...
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/1906.05433</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-08-09 17:10:23">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/723921280647_3ee3dea8f62871f8a715_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Siyu Yang
                     <span class="print-only user-email">(yasiyu@microsoft.com)</span>
                </div>
                <a href="#2019-08-09 17:10:23"><div class="time">2019-08-09 17:10:23</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Bonnie and I are making a shorter memo summarizing the content. Will share if it turns out well</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-09 15:08:41">
            
                <img src="https://secure.gravatar.com/avatar/36fa3107bdff153bf46f9e80aefc9fbd.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0010-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Jennifer Marsman
                     <span class="print-only user-email">(jennmar@microsoft.com)</span>
                </div>
                <a href="#2019-08-09 15:08:41"><div class="time">2019-08-09 15:08:41</div></a>
                <div class="msg">
                    <p>@Jennifer Marsman has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-09 17:08:32">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/723921280647_3ee3dea8f62871f8a715_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Siyu Yang
                     <span class="print-only user-email">(yasiyu@microsoft.com)</span>
                </div>
                <a href="#2019-08-09 17:08:32"><div class="time">2019-08-09 17:08:32</div></a>
                <div class="msg">
                    <p>@Siyu Yang has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-09 20:39:47">
            
                <img src="https://avatars.slack-edge.com/2022-01-24/2986533557719_58ca8e83aa6247d0cc67_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Elijah Cole
                     <span class="print-only user-email">(ecole@caltech.edu)</span>
                </div>
                <a href="#2019-08-09 20:39:47"><div class="time">2019-08-09 20:39:47</div></a>
                <div class="msg">
                    <p>@Elijah Cole has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-12 09:00:02">
            
                <img src="https://secure.gravatar.com/avatar/b5ee72bcdb577878796ac3c6570e9397.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0026-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Nicole Flores
                     <span class="print-only user-email">(nflores@conservation.org)</span>
                </div>
                <a href="#2019-08-12 09:00:02"><div class="time">2019-08-12 09:00:02</div></a>
                <div class="msg">
                    <p>@Nicole Flores has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-13 09:56:37">
            
                <img src="https://avatars.slack-edge.com/2019-08-15/721491609553_86f1a58131c3e2b5c421_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Lily Xu
                     <span class="print-only user-email">(lily_xu@g.harvard.edu)</span>
                </div>
                <a href="#2019-08-13 09:56:37"><div class="time">2019-08-13 09:56:37</div></a>
                <div class="msg">
                    <p>@Lily Xu has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-13 11:46:38">
            
                <img src="https://secure.gravatar.com/avatar/ec0d67f19acdfa56a92eeb6313f75d11.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0000-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Manish Rai
                     <span class="print-only user-email">(rai00007@umn.edu)</span>
                </div>
                <a href="#2019-08-13 11:46:38"><div class="time">2019-08-13 11:46:38</div></a>
                <div class="msg">
                    <p>@Manish Rai has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-14 12:34:59">
            
                <img src="https://avatars.slack-edge.com/2021-05-08/2030294018551_55c7e50192aabb4d0794_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">»òtefan Istrate
                     <span class="print-only user-email">(stefan.istrate@gmail.com)</span>
                </div>
                <a href="#2019-08-14 12:34:59"><div class="time">2019-08-14 12:34:59</div></a>
                <div class="msg">
                    <p>@»òtefan Istrate has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-15 14:04:50">
            
                <img src="https://avatars.slack-edge.com/2019-08-15/727875990677_03fd5910be2133e744d2_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Bourhan
                     <span class="print-only user-email">(bourhan@rfcx.org)</span>
                </div>
                <a href="#2019-08-15 14:04:50"><div class="time">2019-08-15 14:04:50</div></a>
                <div class="msg">
                    <p>@Bourhan has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-15 22:06:38">
            
                <img src="https://secure.gravatar.com/avatar/1445528488450f1ed78373c7ac9e8b2c.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0003-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Hartwig Adam
                     <span class="print-only user-email">(hadam@google.com)</span>
                </div>
                <a href="#2019-08-15 22:06:38"><div class="time">2019-08-15 22:06:38</div></a>
                <div class="msg">
                    <p>@Hartwig Adam has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-16 12:00:50">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2019-08-16 12:00:50"><div class="time">2019-08-16 12:00:50</div></a>
                <div class="msg">
                    <p>@Ben Weinstein has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-16 12:47:53">
            
                <img src="https://secure.gravatar.com/avatar/769a58d4874cc685e8bba028ef55ba69.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0020-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Guido Muscioni
                     <span class="print-only user-email">(muscionig@gmail.com)</span>
                </div>
                <a href="#2019-08-16 12:47:53"><div class="time">2019-08-16 12:47:53</div></a>
                <div class="msg">
                    <p>@Guido Muscioni has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-16 12:55:58">
            
                <img src="https://secure.gravatar.com/avatar/42e2a91668e67236a14cf21ff5ccc9c9.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Chen Luo
                     <span class="print-only user-email">(chenluo@gmail.com)</span>
                </div>
                <a href="#2019-08-16 12:55:58"><div class="time">2019-08-16 12:55:58</div></a>
                <div class="msg">
                    <p>@Chen Luo has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-16 14:55:23">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/724265718599_47b5ad26a905c1821ecf_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Saul Greenberg
                     <span class="print-only user-email">(saul@ucalgary.ca)</span>
                </div>
                <a href="#2019-08-16 14:55:23"><div class="time">2019-08-16 14:55:23</div></a>
                <div class="msg">
                    <p>@Saul Greenberg has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-19 00:03:24">
            
                <img src="https://secure.gravatar.com/avatar/9bb4f1706c0cf159da008143ff751047.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0025-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Abdullah Khan
                     <span class="print-only user-email">(abdylan93@gmail.com)</span>
                </div>
                <a href="#2019-08-19 00:03:24"><div class="time">2019-08-19 00:03:24</div></a>
                <div class="msg">
                    <p>@Abdullah Khan has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-19 01:36:18">
            
                <img src="https://secure.gravatar.com/avatar/8044a6e062630031e71a86e15c13c2ab.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Saket Anand
                     <span class="print-only user-email">(anands@iiitd.ac.in)</span>
                </div>
                <a href="#2019-08-19 01:36:18"><div class="time">2019-08-19 01:36:18</div></a>
                <div class="msg">
                    <p>@Saket Anand has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-19 13:38:46">
            
                <img src="https://secure.gravatar.com/avatar/fad8243912668a0add63704d16e4c44f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Subhransu Maji
                     <span class="print-only user-email">(smaji@cs.umass.edu)</span>
                </div>
                <a href="#2019-08-19 13:38:46"><div class="time">2019-08-19 13:38:46</div></a>
                <div class="msg">
                    <p>@Subhransu Maji has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-19 18:43:46">
            
                <img src="https://avatars.slack-edge.com/2019-09-16/762265682192_938865162b387728244d_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Riccardo Pressiani
                     <span class="print-only user-email">(riccardo.pressiani@mail.polimi.it)</span>
                </div>
                <a href="#2019-08-19 18:43:46"><div class="time">2019-08-19 18:43:46</div></a>
                <div class="msg">
                    <p>@Riccardo Pressiani has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2019-08-20 04:35:02">
            
                <img src="https://avatars.slack-edge.com/2019-08-12/723311044288_a8ac8b8a0d085e72adf8_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Thomas Starnes
                     <span class="print-only user-email">(thomas.starnes@rspb.org.uk)</span>
                </div>
                <a href="#2019-08-20 04:35:02"><div class="time">2019-08-20 04:35:02</div></a>
                <div class="msg">
                    <p>@Thomas Starnes has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-08-21 00:01:55">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2019-08-21 00:01:55"><div class="time">2019-08-21 00:01:55</div></a>
                <div class="msg">
                    <p>measuring fish. <a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13282">https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13282</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üêü Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-08-21 00:03:23">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2019-08-21 00:03:23"><div class="time">2019-08-21 00:03:23</div></a>
                <div class="msg">
                    <p>and kenyan mammal population counts. <a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13277">https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13277</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üêê Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-08-30 10:19:08">
            
                <img src="https://secure.gravatar.com/avatar/88722d903090be6058838a3a5f8ebaf6.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Sheldon
                     <span class="print-only user-email">(sheldon@cs.umass.edu)</span>
                </div>
                <a href="#2019-08-30 10:19:08"><div class="time">2019-08-30 10:19:08</div></a>
                <div class="msg">
                    <p>We just published a paper about measuring bird migration in weather radar using ML. With @Subhransu Maji, @Garrett Bernstein, @Kevin Winner
<a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13280">https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13280</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üê• Lily Xu, Sara Beery, Siyu Yang
                        </div>
                    
                        <div class="message-reaction">
                        üê¶ Stefan Schneider
                        </div>
                    
                        <div class="message-reaction">
                        ü¶â Subhransu Maji
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-08-30 10:28:06">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-08-30 10:28:06"><div class="time">2019-08-30 10:28:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Such awesome work üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-09-03 16:48:27">
            
                <img src="https://avatars.slack-edge.com/2019-08-15/721491609553_86f1a58131c3e2b5c421_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Lily Xu
                     <span class="print-only user-email">(lily_xu@g.harvard.edu)</span>
                </div>
                <a href="#2019-09-03 16:48:27"><div class="time">2019-09-03 16:48:27</div></a>
                <div class="msg">
                    <p>Computational Sustainability faculty recently published a paper in the Communications of the ACM which was highlighted as the cover article:
-- Link to paper: <a href="https://cacm.acm.org/magazines/2019/9/238970-computational-sustainability/fulltext">https://cacm.acm.org/magazines/2019/9/238970-computational-sustainability/fulltext</a>
-- Accompanying video: <a href="https://vimeo.com/351182289">https://vimeo.com/351182289</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">cacm.acm.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://cacm.acm.org/magazines/2019/9/238970-computational-sustainability/fulltext">Computational Sustainability: Computing for a Better World and a Sustainable Future</a></div>
                                <div class="link-text">
                                    Computer and information scientists join forces with other fields to help solve societal and environmental challenges facing humanity, in pursuit of a sustainable future.
                                </div>
                                
                                
    
        <a href="https://cacm.acm.org/magazines/2019/9/238970-computational-sustainability/fulltext">
            <img class="preview" src="https://cacm.acm.org/system/assets/0003/5397/081919_CACMpg57_Computational-Sustainability1.large.jpg?1566250438&amp;1566250438"
                width="250"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://cacm.acm.org/magazines/2019/9/238970-computational-sustainability/fulltext</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Vimeo</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="" class="icon">
                                    }
                                    <a href="https://vimeo.com/user4730653">
                                    CACM
                                    </a><span class="print-only">(https://vimeo.com/user4730653)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href="https://vimeo.com/351182289">Computational Sustainability</a></div>
                                <div class="link-text">
                                    Carla Gomes discusses &#34;Computational Sustainability&#34; (), a Contributed Article in the September 2019 CACM.
                                </div>
                                
                                
    
        <a href="https://vimeo.com/351182289">
            <img class="preview" src="https://i.vimeocdn.com/video/805862490_295x166.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://vimeo.com/351182289</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery, Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-09-03 16:50:10">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-09-03 16:50:10"><div class="time">2019-09-03 16:50:10</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* This is great!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-09-06 14:05:57">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-09-06 14:05:57"><div class="time">2019-09-06 14:05:57</div></a>
                <div class="msg">
                    <p>New paper on Chimp facial recognition: <a href="https://advances.sciencemag.org/content/5/9/eaaw0736">https://advances.sciencemag.org/content/5/9/eaaw0736</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Science Advances</div>
                            
                            
                                
                                <div class="link-title"><a href="https://advances.sciencemag.org/content/5/9/eaaw0736">Chimpanzee face recognition from videos in the wild using deep learning</a></div>
                                <div class="link-text">
                                    Video recording is now ubiquitous in the study of animal behavior, but its analysis on a large scale is prohibited by the time and resources needed to manually process large volumes of data. We present a deep convolutional neural network (CNN) approach that provides a fully automated pipeline for face detection, tracking, and recognition of wild chimpanzees from long-term video records. In a 14-year dataset yielding 10 million face images from 23 individuals over 50 hours of footage, we obtained an overall accuracy of 92.5% for identity recognition and 96.2% for sex recognition. Using the identified faces, we generated co-occurrence matrices to trace changes in the social network structure of an aging population. The tools we developed enable easy processing and annotation of video datasets, including those from other species. Such automated analysis unveils the future potential of large-scale longitudinal video archives to address fundamental questions in behavior and conservation.
                                </div>
                                
                                
    
        <a href="https://advances.sciencemag.org/content/5/9/eaaw0736">
            <img class="preview" src="https://advances.sciencemag.org/sites/default/files/highwire/advances/5/9.cover-source.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://advances.sciencemag.org/content/5/9/eaaw0736</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Subhransu Maji, Siyu Yang, Stefan Schneider
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-09-16 18:32:40">
            
                <img src="https://avatars.slack-edge.com/2019-09-16/762265682192_938865162b387728244d_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Riccardo Pressiani
                     <span class="print-only user-email">(riccardo.pressiani@mail.polimi.it)</span>
                </div>
                <a href="#2019-09-16 18:32:40"><div class="time">2019-09-16 18:32:40</div></a>
                <div class="msg">
                    <p>This is the paper we recently published at KDD2019 in the Data Mining and AI for Conservation Workshop</p>

<p>A Framework for Identifying Group Behavior of Wild Animals: <a href="https://arxiv.org/abs/1907.00932">https://arxiv.org/abs/1907.00932</a></p>

<p>Activity recognition and, more generally, behavior inference tasks are gaining a lot of interest. Much of it is work in the context of human behavior. New available tracking technologies for wild animals are generating datasets that indirectly may provide information about animal behavior. In this work, we propose a method for classifying these data into behavioral annotation, particularly collective behavior of a social group. Our method is based on sequence analysis with a direct encoding of the interactions of a group of wild animals. We evaluate our approach on a real world dataset, showing significant accuracy improvements over baseline methods.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/1907.00932">A Framework For Identifying Group Behavior Of Wild Animals</a></div>
                                <div class="link-text">
                                    Activity recognition and, more generally, behavior inference tasks are gaining a lot of interest. Much of it is work in the context of human behavior. New available tracking technologies for wild...
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/1907.00932</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Lily Xu, Sara Beery, Siyu Yang
                        </div>
                    
                        <div class="message-reaction">
                        üëè Sreejith Menon
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-10-04 11:37:18">
            
                <img src="https://avatars.slack-edge.com/2022-05-20/3554472494357_822b1cb657e9243213fc_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Alex Borowicz
                     <span class="print-only user-email">(alex.borowicz@stonybrook.edu)</span>
                </div>
                <a href="#2019-10-04 11:37:18"><div class="time">2019-10-04 11:37:18</div></a>
                <div class="msg">
                    <p>Our new paper is out this week on using aerial imagery to train a CNN to detect whales in high-res satellite imagery <a href="https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0212532">https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0212532</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">journals.plos.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0212532">Aerial-trained deep learning networks for surveying cetaceans from satellite imagery</a></div>
                                <div class="link-text">
                                    Most cetacean species are wide-ranging and highly mobile, creating significant challenges for researchers by limiting the scope of data that can be collected and leaving large areas un-surveyed. Aerial surveys have proven an effective way to locate and study cetacean movements but are costly and limited in spatial extent. Here we present a semi-automated pipeline for whale detection from very high-resolution (sub-meter) satellite imagery that makes use of a convolutional neural network (CNN). We trained ResNet, and DenseNet CNNs using down-scaled aerial imagery and tested each model on 31 cm-resolution imagery obtained from the WorldView-3 sensor. Satellite imagery was tiled and the trained algorithms were used to classify whether or not a tile was likely to contain a whale. Our best model correctly classified 100% of tiles with whales, and 94% of tiles containing only water. All model architectures performed well, with learning rate controlling performance more than architecture. While the resolution of commercially-available satellite imagery continues to make whale identification a challenging problem, our approach provides the means to efficiently eliminate areas without whales and, in doing so, greatly accelerates ocean surveys for large cetaceans.
                                </div>
                                
                                
    
        <a href="https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0212532">
            <img class="preview" src="https://journals.plos.org/plosone/article/figure/image?id=10.1371/journal.pone.0212532.g005&amp;size=inline"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0212532</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üì° Sara Beery, Siyu Yang
                        </div>
                    
                        <div class="message-reaction">
                        üêã Sara Beery, Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-10-08 13:02:45">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2019-10-08 13:02:45"><div class="time">2019-10-08 13:02:45</div></a>
                <div class="msg">
                    <p>The paper I presented at KDD is up on biorxiv now, <a href="https://www.biorxiv.org/content/10.1101/790071v1">https://www.biorxiv.org/content/10.1101/790071v1</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">bioRxiv</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.biorxiv.org/content/10.1101/790071v1">Geographic Generalization in Airborne RGB Deep Learning Tree Detection</a></div>
                                <div class="link-text">
                                    Tree detection is a fundamental task in remote sensing for forestry and ecosystem ecology applications. While many individual tree segmentation algorithms have been proposed, the development and testing of these algorithms is typically site specific, with few methods evaluated against data from multiple forest types simultaneously. This makes it difficult to determine the generalization of proposed approaches, and limits tree detection at broad scales. Using data from the National Ecological Observatory Network we extend a recently developed semi-supervised deep learning algorithm to include data from a range of forest types, determine whether information from one forest can be used for tree detection in other forests, and explore the potential for building a universal tree detection algorithm. We find that the deep learning approach works well for overstory tree detection across forest conditions, outperforming conventional LIDAR-only methods in all forest types. Performance was best in open oak woodlands and worst in alpine forests. When models were fit to one forest type and used to predict another, performance generally decreased, with better performance when forests were more similar in structure. However, when models were pretrained on data from other sites and then fine-tuned using a small amount of hand-labeled data from the evaluation site, they performed similarly to local site models. Most importantly, a universal model fit to data from all sites simultaneously performed as well or better than individual models trained for each local site. This result suggests that RGB tree detection models that can be applied to a wide array of forest types at broad scales should be possible.
                                </div>
                                
                                
    
        <a href="https://www.biorxiv.org/content/10.1101/790071v1">
            <img class="preview" src="https://www.biorxiv.org/sites/default/files/images/biorxiv_logo_homepage7-5-small.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.biorxiv.org/content/10.1101/790071v1</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üå≤ Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëç Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-10-08 13:03:18">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2019-10-08 13:03:18"><div class="time">2019-10-08 13:03:18</div></a>
                <div class="msg">
                    <p>dataset available for benchmarking (paper to come soon) <a href="https://github.com/weecology/NeonTreeEvaluation">https://github.com/weecology/NeonTreeEvaluation</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">GitHub</div>
                            
                            
                                
                                <div class="link-title"><a href="https://github.com/weecology/NeonTreeEvaluation">weecology/NeonTreeEvaluation</a></div>
                                <div class="link-text">
                                    Benchmark dataset for tree detection for airborne RGB, Hyperspectral and LIDAR imagery - weecology/NeonTreeEvaluation
                                </div>
                                
                                
    
        <a href="https://github.com/weecology/NeonTreeEvaluation">
            <img class="preview" src="https://avatars1.githubusercontent.com/u/1156696?s=400&amp;v=4"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://github.com/weecology/NeonTreeEvaluation</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-10-11 06:22:17">
            
                <img src="https://secure.gravatar.com/avatar/4391c54952e1c48b6e9f3077946818bc.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0006-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Oisin Mac Aodha
                     <span class="print-only user-email">(macaodha@caltech.edu)</span>
                </div>
                <a href="#2019-10-11 06:22:17"><div class="time">2019-10-11 06:22:17</div></a>
                <div class="msg">
                    <p>High level review of deep learning in conservation.
<a href="https://www.cell.com/current-biology/fulltext/S0960-9822(19)31032-2">https://www.cell.com/current-biology/fulltext/S0960-9822(19)31032-2</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üíØ Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëç Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-12-10 16:02:59">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2019-12-10 16:02:59"><div class="time">2019-12-10 16:02:59</div></a>
                <div class="msg">
                    <p>Our recent work "Long Term Temporal Context for Per-Camera Object Detection" is now up on arxiv! <a href="https://arxiv.org/abs/1912.03538">https://arxiv.org/abs/1912.03538</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/1912.03538">Long Term Temporal Context for Per-Camera Object Detection</a></div>
                                <div class="link-text">
                                    In static monitoring cameras, useful contextual information can stretch far beyond the few seconds typical video understanding models might see: subjects may exhibit similar behavior over multiple...
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/1912.03538</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Lily Xu, Elijah Cole, Oisin Mac Aodha, Stefan Schneider, gvanhorn, Manish Rai, Mikey Tabak
                        </div>
                    
                        <div class="message-reaction">
                        üì∑ Stefan Schneider
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2019-12-14 15:46:07">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2019-12-14 15:46:07"><div class="time">2019-12-14 15:46:07</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* just downloaded it, reading it tonight.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-03 13:40:41">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-02-03 13:40:41"><div class="time">2020-02-03 13:40:41</div></a>
                <div class="msg">
                    <p><a href="https://www.sciencedirect.com/science/article/pii/S157495412030011X?via%3Dihub">https://www.sciencedirect.com/science/article/pii/S157495412030011X?via%3Dihub</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.sciencedirect.com/science/article/pii/S157495412030011X?via%3Dihub">Cross-site learning in deep learning RGB tree crown detection</a></div>
                                <div class="link-text">
                                    Tree crown detection is a fundamental task in remote sensing for forestry and ecosystem ecology. While many individual tree segmentation algorithms ha‚Ä¶
                                </div>
                                
                                
    
        <a href="https://www.sciencedirect.com/science/article/pii/S157495412030011X?via%3Dihub">
            <img class="preview" src="https://ars.els-cdn.com/content/image/S15749541.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.sciencedirect.com/science/article/pii/S157495412030011X?via%3Dihub</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üå≥ Sara Beery, Manish Rai, Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-03 14:03:22">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-02-03 14:03:22"><div class="time">2020-02-03 14:03:22</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Awesome! Looking forward to reading this</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-02-22 15:44:55">
            
                <img src="https://avatars.slack-edge.com/2020-02-22/952832651443_67816827c3bea41097de_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Holger Klinck
                     <span class="print-only user-email">(hk829@cornell.edu)</span>
                </div>
                <a href="#2020-02-22 15:44:55"><div class="time">2020-02-22 15:44:55</div></a>
                <div class="msg">
                    <p><a href="https://www.nature.com/articles/s41598-020-57549-y">https://www.nature.com/articles/s41598-020-57549-y</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Scientific Reports</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nature.com/articles/s41598-020-57549-y">Deep neural networks for automated detection of marine mammal species</a></div>
                                <div class="link-text">
                                    Deep neural networks for automated detection of marine mammal species
                                </div>
                                
                                
    
        <a href="https://www.nature.com/articles/s41598-020-57549-y">
            <img class="preview" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41598-020-57549-y/MediaObjects/41598_2020_57549_Fig1_HTML.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nature.com/articles/s41598-020-57549-y</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêã Sara Beery, Elijah Cole, Oisin Mac Aodha, gvanhorn, Ben Weinstein, Alex Borowicz, Manish Rai
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-03-03 17:32:28">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-03-03 17:32:28"><div class="time">2020-03-03 17:32:28</div></a>
                <div class="msg">
                    <p>on contextual metadata for species classification</p>
                    
                    
                    
                        <div class="message-reaction">
                        üêõ Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëç gvanhorn, Stefan Schneider, Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-03-03 17:33:53">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-03-03 17:33:53"><div class="time">2020-03-03 17:33:53</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Very cool! Good find</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-03-03 17:32:51">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-03-03 17:32:51"><div class="time">2020-03-03 17:32:51</div></a>
                <div class="msg">
                    
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëç Mikey Tabak
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-03-19 15:54:00">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-03-19 15:54:00"><div class="time">2020-03-19 15:54:00</div></a>
                <div class="msg">
                    <p>First NAS paper I've seen for wildlife applications: <a href="https://www.sciencedirect.com/science/article/abs/pii/S092523122030388X">https://www.sciencedirect.com/science/article/abs/pii/S092523122030388X</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.sciencedirect.com/science/article/abs/pii/S092523122030388X">Neural Architecture Search Based on Model Pool for Wildlife Identification</a></div>
                                <div class="link-text">
                                    Neural architecture search automates the design of deep neural network, and thus saves the costly manpower in applications like wildlife identificatio‚Ä¶
                                </div>
                                
                                
    
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S092523122030388X">
            <img class="preview" src="https://ars.els-cdn.com/content/image/S09252312.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.sciencedirect.com/science/article/abs/pii/S092523122030388X</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Lily Xu, Siyu Yang, Sam Kelly, Mikey Tabak
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2020-03-26 17:35:44">
            
                <img src="https://secure.gravatar.com/avatar/e96336d4ab1e44113cdeeb9c597c99ae.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Mikey Tabak
                     <span class="print-only user-email">(tabakma@gmail.com)</span>
                </div>
                <a href="#2020-03-26 17:35:44"><div class="time">2020-03-26 17:35:44</div></a>
                <div class="msg">
                    <p>@Mikey Tabak has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-04-10 12:24:17">
            
                <img src="https://avatars.slack-edge.com/2022-01-24/2986533557719_58ca8e83aa6247d0cc67_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Elijah Cole
                     <span class="print-only user-email">(ecole@caltech.edu)</span>
                </div>
                <a href="#2020-04-10 12:24:17"><div class="time">2020-04-10 12:24:17</div></a>
                <div class="msg">
                    <p>We‚Äôre thrilled to announce the GeoLifeCLEF 2020 dataset!
‚Ä¢ 1.9 million species observations, split between France and the US. 
‚Ä¢ Each species observation is paired with high-resolution remote sensing imagery, land cover, and altitude.
‚Ä¢ Also includes traditional climate and soil covariates.
Paper: <a href="https://arxiv.org/abs/2004.04192">https://arxiv.org/abs/2004.04192</a>
Competition: <a href="https://www.aicrowd.com/challenges/lifeclef-2020-geo">https://www.aicrowd.com/challenges/lifeclef-2020-geo</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2004.04192">The GeoLifeCLEF 2020 Dataset</a></div>
                                <div class="link-text">
                                    Understanding the geographic distribution of species is a key concern in conservation. By pairing species occurrences with environmental features, researchers can model the relationship between an...
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2004.04192</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üåç Sara Beery, Oisin Mac Aodha, Lily Xu, gvanhorn, Siyu Yang, Bj√∂rn L√ºtjens, Malte Pedersen, Omiros Pantazis
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-08-12 16:42:51">
            
                <img src="https://avatars.slack-edge.com/2020-08-19/1324116260609_a9febd2992ba427373a1_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Bj√∂rn L√ºtjens
                     <span class="print-only user-email">(bjoern.luetjens@gmail.com)</span>
                </div>
                <a href="#2020-08-12 16:42:51"><div class="time">2020-08-12 16:42:51</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @David</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ David
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-05-18 13:24:30">
            
                <img src="https://avatars.slack-edge.com/2019-08-15/721491609553_86f1a58131c3e2b5c421_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Lily Xu
                     <span class="print-only user-email">(lily_xu@g.harvard.edu)</span>
                </div>
                <a href="#2020-05-18 13:24:30"><div class="time">2020-05-18 13:24:30</div></a>
                <div class="msg">
                    <p>Interesting project from CMU's CREATE lab using computer vision to identify individual industrial smoke emissions.
project: <a href="https://smoke.createlab.org/">https://smoke.createlab.org/</a>
paper: <a href="https://arxiv.org/abs/2005.06111">https://arxiv.org/abs/2005.06111</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2005.06111">RISE Video Dataset: Recognizing Industrial Smoke Emissions</a></div>
                                <div class="link-text">
                                    Industrial smoke emissions pose a significant concern to human health. Prior works have shown that using Computer Vision (CV) techniques to identify smoke as visual evidence can influence the...
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2005.06111</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üåç Sara Beery, gvanhorn, Manish Rai
                        </div>
                    
                        <div class="message-reaction">
                        üåø Suzanne Stathatos
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-17 17:01:38">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2020-06-17 17:01:38"><div class="time">2020-06-17 17:01:38</div></a>
                <div class="msg">
                    <p><a href="https://ai.facebook.com/blog/dense-pose-for-animal-classes-using-transfer-learning">https://ai.facebook.com/blog/dense-pose-for-animal-classes-using-transfer-learning</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">ai.facebook.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://ai.facebook.com/blog/dense-pose-for-animal-classes-using-transfer-learning">Dense pose for animal classes with transfer learning</a></div>
                                <div class="link-text">
                                    The most advanced framework for dense pose estimation for chimpanzees. It will help primatologists and other scientists study how chimps across Africa behave in the wild&amp;amp;
                                </div>
                                
                                
    
        <a href="https://ai.facebook.com/blog/dense-pose-for-animal-classes-using-transfer-learning">
            <img class="preview" src="https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/103823377_1647548458730072_4685552228933489116_n.jpg?_nc_cat=105&amp;_nc_sid=ad8a9d&amp;_nc_ohc=rR62ywsq3usAX-dvvsM&amp;_nc_ht=scontent-iad3-1.xx&amp;oh=2b1cc086ab05e60dd4d23bb53a2698d5&amp;oe=5F0E590A"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://ai.facebook.com/blog/dense-pose-for-animal-classes-using-transfer-learning</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêí Omiros Pantazis, Zac Winzurk, Malte Pedersen, Jonathan Granskog, Siyu Yang, Sam Kelly
                        </div>
                    
                        <div class="message-reaction">
                        üëç Mikey Tabak
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-06-17 17:45:18">
            
                <img src="https://avatars.slack-edge.com/2022-11-07/4325264017430_1d69dc73e8586441b2af_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Omiros Pantazis
                     <span class="print-only user-email">(omiros.pantazis.16@ucl.ac.uk)</span>
                </div>
                <a href="#2020-06-17 17:45:18"><div class="time">2020-06-17 17:45:18</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* that looks very cool</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-15 22:30:56">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-10-15 22:30:56"><div class="time">2020-10-15 22:30:56</div></a>
                <div class="msg">
                    <p>@Hannah Kerner @Tony Chang @John Brandt I emailed the authors to inquire what it would take to transform their annotations (raster segmentations) into bounding boxes to train a satellite tree model for that ecotype. In general I‚Äôm incredibly suspect on individual tree modeling at 50cm resolution, but that ecotype might be more effective. Ignore all the proclamations in the paper, they overpuffed it a touch to get into nature?</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üå≥ Sara Beery, Gyri Reiersen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-27 16:25:55">
            
                <img src="https://avatars.slack-edge.com/2020-07-24/1284951962256_26c078fe9f187cb88c46_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">John Brandt
                     <span class="print-only user-email">(John.Brandt@wri.org)</span>
                </div>
                <a href="#2020-10-27 16:25:55"><div class="time">2020-10-27 16:25:55</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hey Ben! Sorry for the late response. We work with Compton Tucker - the PI for this project - rather closely. I agree I think a bit of the results are overpuffed and selected in areas where the model performs well. They have said for almost 2 years that they'd share the lat, longs and shape files of tree segmentations with us, but it hasn't happened - and we're an official partner with their lab -- so I'm doubtful that you'll get much</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-27 23:18:20">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-10-27 23:18:20"><div class="time">2020-10-27 23:18:20</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* yeah, it was quite untasteful I can be honest, I asked and they ignored me, responding to other parts of the email as if they hadn‚Äôt read the whole thing‚Ä¶</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-28 09:00:49">
            
                <img src="https://avatars.slack-edge.com/2020-07-24/1284951962256_26c078fe9f187cb88c46_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">John Brandt
                     <span class="print-only user-email">(John.Brandt@wri.org)</span>
                </div>
                <a href="#2020-10-28 09:00:49"><div class="time">2020-10-28 09:00:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* sigh - reaching out to Compton tucker this AM will let you know if we get any updates</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-28 09:01:09">
            
                <img src="https://avatars.slack-edge.com/2020-07-24/1284951962256_26c078fe9f187cb88c46_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">John Brandt
                     <span class="print-only user-email">(John.Brandt@wri.org)</span>
                </div>
                <a href="#2020-10-28 09:01:09"><div class="time">2020-10-28 09:01:09</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Have you started using the planet imagery? Would love to chat about ideas. Been working on sentinel 1/2/planet fusion for like 2 days</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-28 10:29:20">
            
                <img src="https://avatars.slack-edge.com/2020-07-24/1284951962256_26c078fe9f187cb88c46_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">John Brandt
                     <span class="print-only user-email">(John.Brandt@wri.org)</span>
                </div>
                <a href="#2020-10-28 10:29:20"><div class="time">2020-10-28 10:29:20</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* The tucker data is here: <a href="https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1832">https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1832</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">daac.ornl.gov</div>
                            
                            
                                
                                <div class="link-title"><a href="https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1832">An Unexpectedly Large Count of Trees in the West African Sahara and Sahel, https://doi.org/10.3334/ORNLDAAC/1832</a></div>
                                <div class="link-text">
                                    ORNL DAAC: This dataset provides georeferenced polygon vectors of individual tree canopy geometries for dryland areas in West African Sahara and Sahel that were derived using deep learning applied to 50 cm resolution satellite imagery. More than 1.8 billion non-forest trees (i.e., woody plants with a crown size over 3 m2) over about 1.3 million km2 were identified from panchromatic and pansharpened normalized difference vegetation index (NVDI) images at 0.5 m spatial resolution using an automatic tree detection framework based on supervised deep-learning techniques. Combined with existing and future fieldwork, these data lay the foundation for a comprehensive database that contains information on all individual trees outside of forests and could provide accurate estimates of woody carbon in arid and semi-arid areas throughout the Earth for the first time.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1832</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein, Bj√∂rn L√ºtjens
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-28 10:29:24">
            
                <img src="https://avatars.slack-edge.com/2020-07-24/1284951962256_26c078fe9f187cb88c46_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">John Brandt
                     <span class="print-only user-email">(John.Brandt@wri.org)</span>
                </div>
                <a href="#2020-10-28 10:29:24"><div class="time">2020-10-28 10:29:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* georeferencing error but it works</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-28 10:29:32">
            
                <img src="https://avatars.slack-edge.com/2020-07-24/1284951962256_26c078fe9f187cb88c46_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">John Brandt
                     <span class="print-only user-email">(John.Brandt@wri.org)</span>
                </div>
                <a href="#2020-10-28 10:29:32"><div class="time">2020-10-28 10:29:32</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* </p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üåç Bj√∂rn L√ºtjens
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-28 12:18:27">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-10-28 12:18:27"><div class="time">2020-10-28 12:18:27</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* what‚Äôs the fusion resolution, can you paste an image of what that ends up looking like?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-28 12:19:06">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2020-10-28 12:19:06"><div class="time">2020-10-28 12:19:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* i always feel like i download planet data, but it never looks quite as good as I hoped&gt; i think they do alot of nice pan sharpening and postprocessing.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-28 12:45:57">
            
                <img src="https://avatars.slack-edge.com/2020-07-24/1284951962256_26c078fe9f187cb88c46_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">John Brandt
                     <span class="print-only user-email">(John.Brandt@wri.org)</span>
                </div>
                <a href="#2020-10-28 12:45:57"><div class="time">2020-10-28 12:45:57</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Here is planet, sentinel, and 10-m labels (white = tree, black = background) for 2 random areas in Kenya</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-28 12:47:39">
            
                <img src="https://avatars.slack-edge.com/2020-07-24/1284951962256_26c078fe9f187cb88c46_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">John Brandt
                     <span class="print-only user-email">(John.Brandt@wri.org)</span>
                </div>
                <a href="#2020-10-28 12:47:39"><div class="time">2020-10-28 12:47:39</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* its 4.77 meter imagery resampled to 5 meters for planet. Thinking of running my normal convLSTM on the sentinel time series, and then fusing in the planet imagery after a 2-stride conv layer to make it the same dimensions before it goes to the normal backbone network</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-28 23:34:26">
            
                <img src="https://avatars.slack-edge.com/2020-08-19/1324116260609_a9febd2992ba427373a1_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Bj√∂rn L√ºtjens
                     <span class="print-only user-email">(bjoern.luetjens@gmail.com)</span>
                </div>
                <a href="#2020-10-28 23:34:26"><div class="time">2020-10-28 23:34:26</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thank you so much for posting the link to polygon vectors! This is pretty cool. Just to be clear this isn't the ground truth annotations though. It's rather a producted as derived from their algorithm, right?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-10-29 09:56:18">
            
                <img src="https://avatars.slack-edge.com/2020-07-24/1284951962256_26c078fe9f187cb88c46_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">John Brandt
                     <span class="print-only user-email">(John.Brandt@wri.org)</span>
                </div>
                <a href="#2020-10-29 09:56:18"><div class="time">2020-10-29 09:56:18</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yes that's true. Their ground truth data is from another paper... Martin Brandt 2018 in nature I think. hand annotations of 20,000 trees in the Sahel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2020-11-11 15:42:40">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2020-11-11 15:42:40"><div class="time">2020-11-11 15:42:40</div></a>
                <div class="msg">
                    <p>Our first paper from the <a href="http://bearresearch.org/">BearID Project</a>: <a href="https://onlinelibrary.wiley.com/doi/10.1002/ece3.6840">https://onlinelibrary.wiley.com/doi/10.1002/ece3.6840</a>. We even got some coverage in the <a href="https://www.nytimes.com/2020/11/11/science/bears-facial-recognition.html">New York Times</a>!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">The New York Times</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="" class="icon">
                                    }
                                    
                                    By Lesley Evans Ogden
                                    
                                </div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nytimes.com/2020/11/11/science/bears-facial-recognition.html">Training Facial Recognition on Some New Furry Friends: Bears</a></div>
                                <div class="link-text">
                                    In their spare time, two Silicon Valley developers aided conservationists in developing artificial intelligence to help keep track of individual bears.
                                </div>
                                
                                
    
        <a href="https://www.nytimes.com/2020/11/11/science/bears-facial-recognition.html">
            <img class="preview" src="https://static01.nyt.com/images/2020/11/11/science/11SCI-AI-BEARS/11SCI-AI-BEARS-largeHorizontalJumbo.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nytimes.com/2020/11/11/science/bears-facial-recognition.html</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Sara Beery, Ankita Shukla, Stefan Schneider, Lily Xu, »òtefan Istrate, gvanhorn, David Healey, Carly Batist, Hemal Naik, karen bakker, Ritwik, Bj√∂rn L√ºtjens, Gyri Reiersen, Rosho
                        </div>
                    
                        <div class="message-reaction">
                        :bearid: Ed Miller, Omiros Pantazis, karen bakker, Bj√∂rn L√ºtjens, Gyri Reiersen, Vanessa S
                        </div>
                    
                        <div class="message-reaction">
                        üêª Stefan Schneider, karen bakker, Gyri Reiersen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-02-11 16:09:08">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-02-11 16:09:08"><div class="time">2021-02-11 16:09:08</div></a>
                <div class="msg">
                    <p>Just reread this paper, pretty cool work in adapting human pose to animals: <a href="https://gdude.de/densepose-evolution/">https://gdude.de/densepose-evolution/</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">gdude.de</div>
                            
                            
                                
                                <div class="link-title"><a href="https://gdude.de/densepose-evolution/">Transferring Dense Pose to Proximal Animal Classes</a></div>
                                <div class="link-text">
                                    Transferring Dense Pose to Proximal Animal Classes.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://gdude.de/densepose-evolution/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ed Miller, Armin Bazarjani, Stefan Schneider, Sam Kelly, Rosho
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-04-09 17:17:23">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-04-09 17:17:23"><div class="time">2021-04-09 17:17:23</div></a>
                <div class="msg">
                    <p>not new, but @Casey Youngflesh <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174973">https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174973</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Casey Youngflesh
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-04-09 17:18:01">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-04-09 17:18:01"><div class="time">2021-04-09 17:18:01</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* This is exactly what I was thinking.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-04-09 17:42:29">
            
                <img src="https://avatars.slack-edge.com/2020-12-17/1581186769125_e0c83f0734ad684293f5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Casey Youngflesh
                     <span class="print-only user-email">(caseyyoungflesh@gmail.com)</span>
                </div>
                <a href="#2021-04-09 17:42:29"><div class="time">2021-04-09 17:42:29</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Awesome, thanks! Count those birbs</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-04-12 13:13:36">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-04-12 13:13:36"><div class="time">2021-04-12 13:13:36</div></a>
                <div class="msg">
                    <p>super interesting paper on self-supervision, might be of use to @gvanhorn @Sarra Alqahtani <a href="https://arxiv.org/pdf/2011.09980.pdf">https://arxiv.org/pdf/2011.09980.pdf</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2021-04-12 13:13:40">
            
                <img src="https://secure.gravatar.com/avatar/eb5d7b966958a6158774ecbfb3767542.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sarra Alqahtani
                     <span class="print-only user-email">(sarra-alqahtani@wfu.edu)</span>
                </div>
                <a href="#2021-04-12 13:13:40"><div class="time">2021-04-12 13:13:40</div></a>
                <div class="msg">
                    <p>@Sarra Alqahtani has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-04-12 17:41:18">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-04-12 17:41:18"><div class="time">2021-04-12 17:41:18</div></a>
                <div class="msg">
                    <p>deep learning for visual pollen analysis, really useful for plant-pollinator work. <a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13575">https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13575</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-04-12 17:42:04">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-04-12 17:42:04"><div class="time">2021-04-12 17:42:04</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* that link is UF specific</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-04-12 17:44:00">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-04-12 17:44:00"><div class="time">2021-04-12 17:44:00</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I invited the author to join the channel and asked if they wanted to upload to lila. I don't know if that is something happening elsewhere for pollen images, but you can imagine a global database kinda thing elsewhere.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-04-27 14:30:38">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-04-27 14:30:38"><div class="time">2021-04-27 14:30:38</div></a>
                <div class="msg">
                    <p><a href="https://arxiv.org/abs/2104.05107">https://arxiv.org/abs/2104.05107</a></p>

<p>"Towards a Collective Agenda on AI for Earth Science Data Analysis"</p>

<p>Awesome new paper by Devis Tuia et al from EPFL. Takeaways are that the majority of work needed isn't in deep learning but instead in reasoning, human-centric and hybrid ML models, interpretability, and causality</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2104.05107">Towards a Collective Agenda on AI for Earth Science Data Analysis</a></div>
                                <div class="link-text">
                                    In the last years we have witnessed the fields of geosciences and remote sensing and artificial intelligence to become closer. Thanks to both the massive availability of observational data,...
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2104.05107</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üåç Omiros Pantazis, Mitch Fennell, Casey Youngflesh, Ben Weinstein, Carly Batist, Gyri Reiersen, Siyu Yang, Tanya Birch, »òtefan Istrate, Burak Ekim
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-05-07 10:16:05">
            
                <img src="https://secure.gravatar.com/avatar/887e6a153d6b5eb1fb4e062f35dd26b0.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ritwik
                     <span class="print-only user-email">(rittyun@yahoo.com)</span>
                </div>
                <a href="#2021-05-07 10:16:05"><div class="time">2021-05-07 10:16:05</div></a>
                <div class="msg">
                    <p><a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13608">https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13608</a>
Happy to announce our new paper,"Automated retrieval of information on threatened species from online sources using machine learning",  which details the methodology to extract news articles on threatened species. An end‚Äêto‚Äêend pipeline that begins from searching and downloading news articles about species listed in Appendix<a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13608#support-information-section">¬†I</a> of (CITES) along with news articles from specific Twitter handles and proceeds with implementing natural language processing and machine learning methods to filter and retain only relevant articles while extracting named entities. We create a database of over 15k articles and adding more with time..</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Carly Batist
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-05-13 10:24:15">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-05-13 10:24:15"><div class="time">2021-05-13 10:24:15</div></a>
                <div class="msg">
                    <p>We released a short paper on the iWildCam competition for the FGVC Workshop: <a href="https://arxiv.org/abs/2105.03494">https://arxiv.org/abs/2105.03494</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2105.03494">The iWildCam 2021 Competition Dataset</a></div>
                                <div class="link-text">
                                    Camera traps enable the automatic collection of large quantities of image data. Ecologists use camera traps to monitor animal populations all over the world. In order to estimate the abundance of...
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2105.03494</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Holger Klinck, Declan, Oisin Mac Aodha, gvanhorn, Mitch Fennell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-05-26 12:40:05">
            
                <img src="https://avatars.slack-edge.com/2022-05-20/3554472494357_822b1cb657e9243213fc_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Alex Borowicz
                     <span class="print-only user-email">(alex.borowicz@stonybrook.edu)</span>
                </div>
                <a href="#2021-05-26 12:40:05"><div class="time">2021-05-26 12:40:05</div></a>
                <div class="msg">
                    <p>New paper - using vacation photos from Flickr to fill data gaps and understand the distribution of Antarctic seals
<a href="https://www.frontiersin.org/articles/10.3389/fmars.2021.645288/full">https://www.frontiersin.org/articles/10.3389/fmars.2021.645288/full</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Frontiers</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.frontiersin.org/articles/10.3389/fmars.2021.645288/full">Social Sensors for Wildlife: Ecological Opportunities in the Era of Camera Ubiquity</a></div>
                                <div class="link-text">
                                    Expansive study areas, such as those used by highly-mobile species, provide numerous logistical challenges for researchers. Community science initiatives have been proposed as a means of overcoming some of these challenges but often suffer from low uptake or limited long-term participation rates. Nevertheless, there are many places where the public has a much higher visitation rate than do field researchers. Here we demonstrate a passive means of collecting community science data by sourcing ecological image data from the digital public, who act as ‚Äúeco-social sensors,‚Äù via a public photo-sharing platform‚ÄîFlickr. To achieve this, we use freely-available Python packages and simple applications of convolutional neural networks. Using the Weddell seal (Leptonychotes weddellii) on the Antarctic Peninsula as an example, we use these data with field survey data to demonstrate the viability of photo-identification for this species, supplement traditional field studies to better understand patterns of habitat use, describe spatial and sex-specific signals in molt phenology, and examine behavioral differences between the Antarctic Peninsula‚Äôs Weddell seal population and better-studied populations in the species‚Äô more southerly fast-ice habitat. While our analyses are unavoidably limited by the relatively small volume of imagery currently available, this pilot study demonstrates the utility an eco-social sensors approach, the value of ad hoc wildlife photography, the role of geograp...
                                </div>
                                
                                
    
        <a href="https://www.frontiersin.org/articles/10.3389/fmars.2021.645288/full">
            <img class="preview" src="https://www.frontiersin.org/files/MyHome%20Article%20Library/645288/645288_Thumb_400.jpg"
                width="163"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.frontiersin.org/articles/10.3389/fmars.2021.645288/full</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery, Emily Charry Tissier, aruna, Ben Weinstein, Lily Xu, Malcolm Kennedy
                        </div>
                    
                        <div class="message-reaction">
                        ü¶≠ Sara Beery, Casey Youngflesh, aruna, Omiros Pantazis, Bj√∂rn L√ºtjens, Siyu Yang, Malcolm Kennedy
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-06-16 15:41:19">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-06-16 15:41:19"><div class="time">2021-06-16 15:41:19</div></a>
                <div class="msg">
                    <p>@Ben Weinstein @Elijah Cole @Ben Augustine nice paper on model calibration: <a href="https://arxiv.org/abs/2106.07998">https://arxiv.org/abs/2106.07998</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2106.07998">Revisiting the Calibration of Modern Neural Networks</a></div>
                                <div class="link-text">
                                    Accurate estimation of predictive uncertainty (model calibration) is essential for the safe application of neural networks. Many instances of miscalibration in modern neural networks have been...
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2106.07998</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Elijah Cole, Ben Augustine, Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-06-16 16:53:06">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-06-16 16:53:06"><div class="time">2021-06-16 16:53:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* particularly section 4.3 "Accuracy and Calibration Under Distribution Shift"</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2021-06-16 15:42:11">
            
                <img src="https://secure.gravatar.com/avatar/bd1eaf55a0e4c3c52bf0175cca8e23c3.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Augustine
                     <span class="print-only user-email">(ben.augustine@cornell.edu)</span>
                </div>
                <a href="#2021-06-16 15:42:11"><div class="time">2021-06-16 15:42:11</div></a>
                <div class="msg">
                    <p>@Ben Augustine has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-06-22 12:39:25">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-06-22 12:39:25"><div class="time">2021-06-22 12:39:25</div></a>
                <div class="msg">
                    <p>does anyone have experience with this <a href="http://proceedings.mlr.press/v48/gal16.pdf">http://proceedings.mlr.press/v48/gal16.pdf</a> I am reviewing a paper that leans hard on the idea that ensembling a bunch of randomly initialized models with dropout is a form of bayesian approximation. This seems fringe to me.</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-06-22 12:51:38">
            
                <img src="https://avatars.slack-edge.com/2022-01-24/2986533557719_58ca8e83aa6247d0cc67_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Elijah Cole
                     <span class="print-only user-email">(ecole@caltech.edu)</span>
                </div>
                <a href="#2021-06-22 12:51:38"><div class="time">2021-06-22 12:51:38</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I haven‚Äôt read the paper, but it‚Äôs a popular idea and I hear that claim about bayesian approximation repeated often</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-06-22 12:52:30">
            
                <img src="https://avatars.slack-edge.com/2022-01-24/2986533557719_58ca8e83aa6247d0cc67_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Elijah Cole
                     <span class="print-only user-email">(ecole@caltech.edu)</span>
                </div>
                <a href="#2021-06-22 12:52:30"><div class="time">2021-06-22 12:52:30</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* So it‚Äôs at least not fringe</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-06-22 12:53:33">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-06-22 12:53:33"><div class="time">2021-06-22 12:53:33</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* it feels somewhat a stretch? No priors, no bayes rule, the resulting distributions are not posteriors in the sense that they are not well calibrated. I guess in terms of the way ecologists engage with bayesian models, the connection isn't obvious. But good to know others have seen it. I'll dial back my language in the review.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-06-22 12:57:26">
            
                <img src="https://avatars.slack-edge.com/2022-01-24/2986533557719_58ca8e83aa6247d0cc67_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Elijah Cole
                     <span class="print-only user-email">(ecole@caltech.edu)</span>
                </div>
                <a href="#2021-06-22 12:57:26"><div class="time">2021-06-22 12:57:26</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* The appendix seems to have a lot of the details:</p>

<p><a href="https://arxiv.org/abs/1506.02157">https://arxiv.org/abs/1506.02157</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/1506.02157">Dropout as a Bayesian Approximation: Appendix</a></div>
                                <div class="link-text">
                                    We show that a neural network with arbitrary depth and non-linearities, with dropout applied before every weight layer, is mathematically equivalent to an approximation to a well known Bayesian...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/1506.02157">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/1506.02157</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-06-22 13:09:05">
            
                <img src="https://secure.gravatar.com/avatar/0823b6f3321c0a7d2517b9874d259b0f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Jake Graving
                     <span class="print-only user-email">(jgraving@gmail.com)</span>
                </div>
                <a href="#2021-06-22 13:09:05"><div class="time">2021-06-22 13:09:05</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* MC dropout is definitely closer to parametric bootstrapping than proper Bayes. I think the idea is that the weight initialization scheme functions as some kind of improper prior by biasing the optimizer toward different modes in the posterior (see <a href="https://arxiv.org/abs/1912.02757">https://arxiv.org/abs/1912.02757</a>)  However, the end result is definitely prone to miscalibration and strongly depends on the size of the network and dropout rate, which I think have been the subjects of quite a few follow up papers (e.g. <a href="https://arxiv.org/abs/2006.11584">https://arxiv.org/abs/2006.11584</a>)</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/1912.02757">Deep Ensembles: A Loss Landscape Perspective</a></div>
                                <div class="link-text">
                                    Deep ensembles have been empirically shown to be a promising approach for improving accuracy, uncertainty and out-of-distribution robustness of deep learning models. While deep ensembles were...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/1912.02757">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/1912.02757</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2006.11584">Calibration of Model Uncertainty for Dropout Variational Inference</a></div>
                                <div class="link-text">
                                    The model uncertainty obtained by variational Bayesian inference with Monte Carlo dropout is prone to miscalibration. In this paper, different logit scaling methods are extended to dropout...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2006.11584">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2006.11584</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-06-22 13:09:34">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-06-22 13:09:34"><div class="time">2021-06-22 13:09:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks for the papers, this fits my expectation.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-07-06 13:39:02">
            
                <img src="https://avatars.slack-edge.com/2020-08-29/1354144022224_b8b2d9812a1ffe243e39_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Mike C
                     <span class="print-only user-email">(mike@mikecee.solutions)</span>
                </div>
                <a href="#2021-07-06 13:39:02"><div class="time">2021-07-06 13:39:02</div></a>
                <div class="msg">
                    <p>Can our datasets be of value to you? A few project updates</p>

<p>The University of Hong Kong has just developed an app called ‚ÄòSaving Face‚Äô for i-id of napoleon wrasse:</p>

<p><a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/aqc.3199">https://onlinelibrary.wiley.com/doi/abs/10.1002/aqc.3199</a>
<a href="https://www.scmp.com/magazines/post-magazine/short-reads/article/3134123/facial-recognition-app-used-protect-endangered">https://www.scmp.com/magazines/post-magazine/short-reads/article/3134123/facial-recognition-app-used-protect-endangered</a></p>

<p>The team has developed other ML applications in conservation such as:
<a href="https://www.clearbot.org/">https://www.clearbot.org/</a>
<a href="https://openoceancam.com/">https://openoceancam.com/</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">South China Morning Post</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.scmp.com/magazines/post-magazine/short-reads/article/3134123/facial-recognition-app-used-protect-endangered">Facial recognition app helps protect endangered fish species</a></div>
                                <div class="link-text">
                                    A facial recognition app created in Hong Kong is being used to protect an endangered species of coral reef fish called the humphead wrasse.
                                </div>
                                
                                
    
        <a href="https://www.scmp.com/magazines/post-magazine/short-reads/article/3134123/facial-recognition-app-used-protect-endangered">
            <img class="preview" src="https://cdn.i-scmp.com/sites/default/files/styles/og_twitter_scmp_generic/public/d8/images/canvas/2021/05/20/3913454f-0354-4cde-ad92-1b087eaa776c_b40e1eef.jpg?itok=tchSupJD&amp;v=1621475006"
                width="476"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.scmp.com/magazines/post-magazine/short-reads/article/3134123/facial-recognition-app-used-protect-endangered</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Clearbot</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.clearbot.org/">Clearbot | Hong Kong</a></div>
                                <div class="link-text">
                                    Building fleets of robots that clean our oceans.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://www.clearbot.org/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêü Oisin Mac Aodha, Sara Beery, Olivier Gimenez
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-07-28 14:11:43">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-07-28 14:11:43"><div class="time">2021-07-28 14:11:43</div></a>
                <div class="msg">
                    <p>Awesome new comprehensive review of sensors used for wildlife monitoring: <a href="https://academic.oup.com/bioscience/advance-article/doi/10.1093/biosci/biab073/6322306">https://academic.oup.com/bioscience/advance-article/doi/10.1093/biosci/biab073/6322306</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Olivier Gimenez, Omiros Pantazis
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-07-28 15:17:48">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2021-07-28 15:17:48"><div class="time">2021-07-28 15:17:48</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Such an awesome paper!! I‚Äôve been waiting for something like this to be published for years!</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-02 03:42:53">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-08-02 03:42:53"><div class="time">2021-08-02 03:42:53</div></a>
                <div class="msg">
                    <p>New paper "Becoming Good at AI for Good" by the Microsoft AI for Good team, including @Caleb Robinson, @Bistra Dilkina and @Siyu Yang!</p>

<p><a href="https://arxiv.org/abs/2104.11757">https://arxiv.org/abs/2104.11757</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2104.11757">Becoming Good at AI for Good</a></div>
                                <div class="link-text">
                                    AI for good (AI4G) projects involve developing and applying artificial intelligence (AI) based solutions to further goals in areas such as sustainability, health, humanitarian aid, and social...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2104.11757">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2104.11757</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Oisin Mac Aodha, Omiros Pantazis, Justin Kay, Carly Batist, Mitch Fennell, Mikey Tabak
                        </div>
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Lily Xu
                        </div>
                    
                        <div class="message-reaction">
                        üëÄ Carl Boettiger
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2021-08-02 03:43:01">
            
                <img src="https://avatars.slack-edge.com/2022-08-26/4012029248913_f5ad71b1fb3bf7118c8b_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Caleb Robinson
                     <span class="print-only user-email">(calebrob6@gmail.com)</span>
                </div>
                <a href="#2021-08-02 03:43:01"><div class="time">2021-08-02 03:43:01</div></a>
                <div class="msg">
                    <p>@Caleb Robinson has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-18 21:46:49">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-18 21:46:49"><div class="time">2021-08-18 21:46:49</div></a>
                <div class="msg">
                    <p>hey channel! I'm going to the tropics for a bit and will have plenty of afternoons for reading. Please drop literally all possibly interesting papers in here! I'm sure i'm not alone in having some summer reading to do, so if everyone drops one paper, we can get a decent reading list going. Your own work counts too! Bird detector preprint is up. <a href="https://www.biorxiv.org/content/10.1101/2021.08.05.455311v1">https://www.biorxiv.org/content/10.1101/2021.08.05.455311v1</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">bioRxiv</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.biorxiv.org/content/10.1101/2021.08.05.455311v1">A general deep learning model for bird detection in high resolution airborne imagery</a></div>
                                <div class="link-text">
                                    Advances in artificial intelligence for image processing hold great promise for increasing the scales at which ecological systems can be studied. The distribution and behavior of individuals is central to ecology, and computer vision using deep neural networks can learn to detect individual objects in imagery. However, developing computer vision for ecological monitoring is challenging because it needs large amounts of human-labeled training data, requires advanced technical expertise and computational infrastructure, and is prone to overfitting. This limits application across space and time. One solution is developing generalized models that can be applied across species and ecosystems. Using over 250,000 annotations from 13 projects from around the world, we develop a general bird detection model that achieves over 65% recall and 50% precision on novel aerial data without any local training despite differences in species, habitat, and imaging methodology. Fine-tuning this model with only 1000 local annotations increases these values to an average of 84% recall and 69% precision by building on the general features learned from other data sources. Retraining from the general model improves local predictions even when moderately large annotation sets are available and makes model training faster and more stable. Our results demonstrate that general models for detecting broad classes of organisms using airborne imagery are achievable. These models can reduce the effort, expertise, and computational resources necessary for automating the detection of individual organisms across large scales, helping to transform the scale of data collection in ecology and the questions that can be addressed. ### Competing Interest Statement The authors have declared no competing interest.
                                </div>
                                
                                
    
        <a href="https://www.biorxiv.org/content/10.1101/2021.08.05.455311v1">
            <img class="preview" src="https://www.biorxiv.org/sites/default/files/images/biorxiv_logo_homepage7-5-small.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.biorxiv.org/content/10.1101/2021.08.05.455311v1</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üòç Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëç Siyu Yang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:32:37">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-25 12:32:37"><div class="time">2021-08-25 12:32:37</div></a>
                <div class="msg">
                    <p>Does anyone know of a paper studying temporal identification of individual objects in remote sensing. Given a set of images, performing object detection and then specifying that this object is the same among images given small changes in acquisition and appearance?  The tracking literature (Like <a href="https://ieeexplore-ieee-org.lp.hscl.ufl.edu/abstract/document/9492311">https://ieeexplore-ieee-org.lp.hscl.ufl.edu/abstract/document/9492311</a>) all makes assumptions about that the object is actually moving and use things like optical flow. The image registration literature is concerned with shifting the entire image (like <a href="https://ieeexplore-ieee-org.lp.hscl.ufl.edu/abstract/document/8404075">https://ieeexplore-ieee-org.lp.hscl.ufl.edu/abstract/document/8404075</a>).</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:34:36">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-08-25 12:34:36"><div class="time">2021-08-25 12:34:36</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I don't but we've been thinking about this in the context of SSL for urban trees. Would be excited if someone knew of/could point to the right literature :)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:35:07">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-25 12:35:07"><div class="time">2021-08-25 12:35:07</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* if i feels like either i'm not using the right words, or its surprisingly understudied compared to change detection</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ûï Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:36:13">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-25 12:36:13"><div class="time">2021-08-25 12:36:13</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* sort of <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-cvi.2017.0261">https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-cvi.2017.0261</a>, but not really.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:37:27">
            
                <img src="https://avatars.slack-edge.com/2019-08-09/710927732467_361cf9702d4e00793c20_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Stefan Schneider
                     <span class="print-only user-email">(sschne01@uoguelph.ca)</span>
                </div>
                <a href="#2021-08-25 12:37:27"><div class="time">2021-08-25 12:37:27</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* In terms of the comparison portion, similarity comparison networks might help.</p>

<p><a href="https://arxiv.org/abs/1902.09324">https://arxiv.org/abs/1902.09324</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/1902.09324">Similarity Learning Networks for Animal Individual...</a></div>
                                <div class="link-text">
                                    Deep learning has become the standard methodology to approach computer vision tasks when large amounts of labeled data are available. One area where traditional deep learning approaches fail to...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/1902.09324">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/1902.09324</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:38:04">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-08-25 12:38:04"><div class="time">2021-08-25 12:38:04</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* So for clarification Ben, are you trying to determine whether objects in the same known position are the same object at different time points or two different objects?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:38:32">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-08-25 12:38:32"><div class="time">2021-08-25 12:38:32</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* which is distinguished from registration because the alignment is already known?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:42:09">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-25 12:42:09"><div class="time">2021-08-25 12:42:09</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* here is a picture. Here are two years of tree predictions shown at the same time. Its easy to do heuristically if you have just two years, but imagine we have 10 years. An ideal method using information from multiple years (like your camera trap paper), but also allows for new objects to appear. So the network would take in a series of images, and return object detections AND a 2nd head that had a unique code that represents an individual, similar to what @Stefan Schneider just shared.</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:43:05">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-25 12:43:05"><div class="time">2021-08-25 12:43:05</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* it feels like this should have been done in the building detection world. Buildings change over time. This building in these 5 images is the same building.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:44:04">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-08-25 12:44:04"><div class="time">2021-08-25 12:44:04</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Trees might change more over time than buildings?</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôÇ Ben Weinstein
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:44:34">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-08-25 12:44:34"><div class="time">2021-08-25 12:44:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* You would also want to catch deaths, yeah? So IDs would also be able to dissapear</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:44:50">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-25 12:44:50"><div class="time">2021-08-25 12:44:50</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* we think that 99% of the change among images is actually changes in angle/illumination</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:45:02">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-08-25 12:45:02"><div class="time">2021-08-25 12:45:02</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Basically sounds like an adaptation of multi-object tracking</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:45:35">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-25 12:45:35"><div class="time">2021-08-25 12:45:35</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* certainly all that happens and is important, but if you look at naive predictions, the variance among years is almost entirely driven by superficial appearance.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:45:37">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-08-25 12:45:37"><div class="time">2021-08-25 12:45:37</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* where the motion signal is growth</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:46:35">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-08-25 12:46:35"><div class="time">2021-08-25 12:46:35</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* right, with strong changes in superficial appearance, the signal is mostly in...trunk position? and positive instead of negative growth?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:47:04">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-25 12:47:04"><div class="time">2021-08-25 12:47:04</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* 2019 v 2018</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:48:06">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-08-25 12:48:06"><div class="time">2021-08-25 12:48:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* When does a simple IoU-based matching approach fail? Assuming the images are well-aligned?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:49:40">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-25 12:49:40"><div class="time">2021-08-25 12:49:40</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* ah, see that works for a small number of years, but the number of permutations is insane. Imagine 5 years, there are 5 choose 2 = 10 combinations of potential matches. Very quickly it becomes weird when tree A matches in year 4, 3, 1, but Tree B matches in year 5, 2.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:50:05">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-25 12:50:05"><div class="time">2021-08-25 12:50:05</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* it just starts to chain together trees to make super trees</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:51:08">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-08-25 12:51:08"><div class="time">2021-08-25 12:51:08</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* i'm going to go read the animal identification paper.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 12:52:30">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-08-25 12:52:30"><div class="time">2021-08-25 12:52:30</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* hmmmm interesting.  I think one thing that's different in this case from the animal re-ID is that here the stronger signal is the position of the object as opposed to the specific appearance. But possibly position, size, and time could be encoded into the similarity score in a cool way.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-25 14:52:49">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2361920803907_ad849dc380fc3d3470dc_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Daniel Davila
                     <span class="print-only user-email">(daniel.davila@kitware.com)</span>
                </div>
                <a href="#2021-08-25 14:52:49"><div class="time">2021-08-25 14:52:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* How good of a registration can you compute, year over year, with a proper orthorectification and features derived from the surrounding scenery? It seems like you should be able to get the reg good enough that the trees should almost completely overlay in their connection to the ground plane, so the trunks</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-08-30 17:50:12">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2021-08-30 17:50:12"><div class="time">2021-08-30 17:50:12</div></a>
                <div class="msg">
                    <p>For Python users &amp; bioacoustics folks --</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Sean Carter, Ben Weinstein
                        </div>
                    
                        <div class="message-reaction">
                        üß† Noah Giebink
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-09-14 15:30:17">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2021-09-14 15:30:17"><div class="time">2021-09-14 15:30:17</div></a>
                <div class="msg">
                    <p>AP-10K: A Benchmark for Animal Pose Estimation in the Wild</p>

<p>Accurate animal pose estimation is an essential step towards understanding animal behavior, and can potentially benefit many downstream applications, such as wildlife conservation. Previous works only focus on specific animals while ignoring the diversity of animal species, limiting the generalization ability. In this paper, we propose AP-10K, the first large-scale benchmark for general animal pose estimation, to facilitate the research in animal pose estimation. AP-10K consists of 10,015 images collected and filtered from 23 animal families and 60 species following the taxonomic rank and high-quality keypoint annotations labeled and checked manually. Based on AP-10K, we benchmark representative pose estimation models on the following three tracks: (1) supervised learning for animal pose estimation, (2) cross-domain transfer learning from human pose estimation to animal pose estimation, and (3) intra- and inter-family domain generalization for unseen animals. The experimental results provide sound empirical evidence on the superiority of learning from diverse animals species in terms of both accuracy and generalization ability. It opens new directions for facilitating future research in animal pose estimation.</p>

<p><a href="https://github.com/AlexTheBad/AP-10K">https://github.com/AlexTheBad/AP-10K</a></p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">AlexTheBad/AP-10K</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        23
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Last updated</div>
                                        a day ago
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Jake Graving, Subhransu Maji
                        </div>
                    
                        <div class="message-reaction">
                        üôå Suzanne Stathatos
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-09-17 12:09:32">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-09-17 12:09:32"><div class="time">2021-09-17 12:09:32</div></a>
                <div class="msg">
                    <p>@Sara Beery <a href="https://www.corp.at/archive/CORP2021_143.pdf">https://www.corp.at/archive/CORP2021_143.pdf</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-10-18 18:19:10">
            
                <img src="https://avatars.slack-edge.com/2021-07-06/2270250594576_b26208ffe098b963d801_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Zhongqi Miao
                     <span class="print-only user-email">(zhongqi.miao@berkeley.edu)</span>
                </div>
                <a href="#2021-10-18 18:19:10"><div class="time">2021-10-18 18:19:10</div></a>
                <div class="msg">
                    <p>Hello everyone! I am a sixth-year PhD student from UC Berkeley. We have just published a paper on Nature Machine Intelligence about deployable wildlife AI recognition systems with efficient humans in the loop and imperfect models! Please check it out if you are interested! This project is moving towards practical deployment in Africa. We hope this work can become an important step to the AI solutions for real-world conservation problems with imperfect AI models. I am very happy to answer any questions you have! Here is the link to the journal webpage (with a preprint link incorporated in case you don't have subscriptions):¬†<a href="https://www.nature.com/articles/s42256-021-00393-0">https://www.nature.com/articles/s42256-021-00393-0</a>¬† Thank you very much!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Nature Machine Intelligence</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nature.com/articles/s42256-021-00393-0">Iterative human and automated identification of...</a></div>
                                <div class="link-text">
                                    Nature Machine Intelligence - Camera trapping is a widely adopted method for monitoring terrestrial mammals. However, a drawback is the amount of human annotation needed to keep pace with...
                                </div>
                                
                                
    
        <a href="https://www.nature.com/articles/s42256-021-00393-0">
            <img class="preview" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs42256-021-00393-0/MediaObjects/42256_2021_393_Fig1_HTML.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nature.com/articles/s42256-021-00393-0</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Lily Xu, Ben Weinstein, Arthur Wandzel
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Carl Boettiger
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-10-20 16:17:15">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-10-20 16:17:15"><div class="time">2021-10-20 16:17:15</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* in the open long tailed framework (cited in your paper), how does one decide what is too far away in the clustered feature space? Looking at this figure, which relates to your work. How to decide when to call in a human? How sensitive is the performance to this threshold, seems like a really tough call about when a sample is novel enough.</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-10-21 15:29:27">
            
                <img src="https://avatars.slack-edge.com/2021-07-06/2270250594576_b26208ffe098b963d801_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Zhongqi Miao
                     <span class="print-only user-email">(zhongqi.miao@berkeley.edu)</span>
                </div>
                <a href="#2021-10-21 15:29:27"><div class="time">2021-10-21 15:29:27</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hello @Ben Weinstein. Thanks for asking! For OLTR, it is set up with a threshold as a hyperparameter to determine known v.s. novel. In terms of sensitivity, it was measured by a modified F1 score (originally proposed in ODIN) reported in the results section with the same threshold across all compared baselines. It is the same process in the iterative wildlife recognition framework. The only difference is we now don't focus to much on novel samples, but difficult samples as well because the purpose is not solely out of distribution detection, but efficient human intervention. The sensitivity is measured as percentage of high confidence and low confidence prediction in both known and unknown classes on validation or second period training data, which we think is more intuitive. Does that make sense?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-10-22 12:11:40">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-10-22 12:11:40"><div class="time">2021-10-22 12:11:40</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* ya. it does make sense, i'm just trying to think about how to come up with a first estimate for what the value of that hyperparameter should be. There are no units in that dimensional space. I get how to evaluate it. In practice did you just search for an optimal value by hand?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-10-25 01:03:05">
            
                <img src="https://avatars.slack-edge.com/2021-07-06/2270250594576_b26208ffe098b963d801_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Zhongqi Miao
                     <span class="print-only user-email">(zhongqi.miao@berkeley.edu)</span>
                </div>
                <a href="#2021-10-25 01:03:05"><div class="time">2021-10-25 01:03:05</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Oh, I see. Yes, we did some search with validation data for the iterative model. But for OLTR, it was just based on past experience where 0.2 gave a relatively good performance. And it is definitely not the optimal value. We only use it to compare with other methods.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-10-25 12:10:25">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-10-25 12:10:25"><div class="time">2021-10-25 12:10:25</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* thanks, this is something I will be investigating, we have a similar use case with trees. 192 species with atleast 1 sample, but only maybe 80 species with more than 10 samples. Are there other foundational papers on the meta-learning/metric learning/joint learning + clustering that you find helpful?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-10-25 12:23:57">
            
                <img src="https://avatars.slack-edge.com/2021-07-06/2270250594576_b26208ffe098b963d801_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Zhongqi Miao
                     <span class="print-only user-email">(zhongqi.miao@berkeley.edu)</span>
                </div>
                <a href="#2021-10-25 12:23:57"><div class="time">2021-10-25 12:23:57</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yes, if you are looking for long-tail related papers. LDAM (<a href="https://arxiv.org/pdf/1906.07413.pdf">https://arxiv.org/pdf/1906.07413.pdf</a>), DecouplingNetwork (<a href="https://arxiv.org/abs/1910.09217">https://arxiv.org/abs/1910.09217</a>), BBN (<a href="https://arxiv.org/abs/1912.02413">https://arxiv.org/abs/1912.02413</a>), and RIDE (<a href="https://arxiv.org/abs/2010.01809">https://arxiv.org/abs/2010.01809</a>) are the four highly discussed follow ups after our OLTR. RIDE is currently the state of the art method but relatively more complicated.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/1910.09217">Decoupling Representation and Classifier for Long-Tailed Recognition</a></div>
                                <div class="link-text">
                                    The long-tail distribution of the visual world poses great challenges for deep learning based classification models on how to handle the class imbalance problem. Existing solutions usually involve...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/1910.09217">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/1910.09217</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/1912.02413">BBN: Bilateral-Branch Network with Cumulative Learning for...</a></div>
                                <div class="link-text">
                                    Our work focuses on tackling the challenging but natural visual recognition task of long-tailed data distribution (i.e., a few classes occupy most of the data, while most classes have rarely few...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/1912.02413">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/1912.02413</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2010.01809">Long-tailed Recognition by Routing Diverse Distribution-Aware Experts</a></div>
                                <div class="link-text">
                                    Natural data are often long-tail distributed over semantic classes. Existing recognition methods tackle this imbalanced classification by placing more emphasis on the tail data, through class...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2010.01809">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2010.01809</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-10-25 12:25:02">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2021-10-25 12:25:02"><div class="time">2021-10-25 12:25:02</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Great thanks. I'll let you know, we have plenty of data if this the kind of thing you/others want to get involved with. Collaborative group here at UF.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2021-10-25 12:52:06">
            
                <img src="https://avatars.slack-edge.com/2021-07-06/2270250594576_b26208ffe098b963d801_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Zhongqi Miao
                     <span class="print-only user-email">(zhongqi.miao@berkeley.edu)</span>
                </div>
                <a href="#2021-10-25 12:52:06"><div class="time">2021-10-25 12:52:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Great! I can also answer any question you have!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-11 03:11:26">
            
                <img src="https://secure.gravatar.com/avatar/7e0d2f5ecd4f1c85405166545b4f2e66.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Akronix
                     <span class="print-only user-email">(akronix5@gmail.com)</span>
                </div>
                <a href="#2022-02-11 03:11:26"><div class="time">2022-02-11 03:11:26</div></a>
                <div class="msg">
                    <p>"A Comprehensive Overview of Technologies for Species and Habitat Monitoring and Conservation"
<a href="https://academic.oup.com/bioscience/article/71/10/1038/6322306">https://academic.oup.com/bioscience/article/71/10/1038/6322306</a> October 2021</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery, Lucia Gordon, Subhransu Maji
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-11 09:38:11">
            
                <img src="https://avatars.slack-edge.com/2022-02-10/3079007120838_2256d6dbf14428a3afc4_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Devis Tuia
                     <span class="print-only user-email">(devis.tuia@epfl.ch)</span>
                </div>
                <a href="#2022-02-11 09:38:11"><div class="time">2022-02-11 09:38:11</div></a>
                <div class="msg">
                    <p>‚ÄúPerspectives in Machine learning for Wildlife Conservation‚Äù, fresh from the press in Nature Communication. In our co-authors‚Äô words ‚Äúour call to action‚Äù üôÇ  <a href="https://www.nature.com/articles/s41467-022-27980-y">https://www.nature.com/articles/s41467-022-27980-y</a> Many of the people in the group have contributed to this paper, for instance @Sara Beery @Benjamin Kellenberger @Silvia Zuffi @Holger Klinck @gvanhorn @Tanya Berger-Wolf and many others !</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Nature</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nature.com/articles/s41467-022-27980-y">Perspectives in machine learning for wildlife conservation</a></div>
                                <div class="link-text">
                                    Nature Communications - Animal ecologists are increasingly limited by constraints in data processing. Here, Tuia and colleagues discuss how collaboration between ecologists and data scientists can...
                                </div>
                                
                                
    
        <a href="https://www.nature.com/articles/s41467-022-27980-y">
            <img class="preview" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41467-022-27980-y/MediaObjects/41467_2022_27980_Fig1_HTML.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nature.com/articles/s41467-022-27980-y</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Lily Xu, Sara Beery, Suzanne Stathatos, Lucia Gordon, Carly Batist
                        </div>
                    
                        <div class="message-reaction">
                        üôå Nico Lang, gvanhorn, Mitch Fennell, Omiros Pantazis, Casey Youngflesh, Subhransu Maji, Aude Vuilli
                        </div>
                    
                        <div class="message-reaction">
                        üíö Burak Ekim, Olivier Gimenez
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-15 14:50:05">
            
                <img src="https://avatars.slack-edge.com/2021-10-20/2615548747079_59b98294fae6beb7bd0b_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carl Boettiger
                     <span class="print-only user-email">(cboettig@berkeley.edu)</span>
                </div>
                <a href="#2022-02-15 14:50:05"><div class="time">2022-02-15 14:50:05</div></a>
                <div class="msg">
                    <p>"Coding for Life: Designing a Platform for Projecting and Protecting Global Biodiversity" <a href="https://doi.org/10.1093/biosci/biab099">https://doi.org/10.1093/biosci/biab099</a> (including (brief) mention of deep RL methods). I wasn't involved in this, but I thought this was a compelling pitch, notably coming from a mostly or entirely ecology-based team, led by a field ecologist.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Sara Beery, Akronix, Benjamin Akera, Lily Xu
                        </div>
                    
                        <div class="message-reaction">
                        :thumbsup_all: Frederic Fol Leymarie
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-15 16:21:52">
            
                <img src="https://secure.gravatar.com/avatar/7e0d2f5ecd4f1c85405166545b4f2e66.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Akronix
                     <span class="print-only user-email">(akronix5@gmail.com)</span>
                </div>
                <a href="#2022-02-15 16:21:52"><div class="time">2022-02-15 16:21:52</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* What's the name of that platform they're coding? do they have a github repo?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-16 07:51:24">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2385364021056_8aed180749aafbe43e0d_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Frederic Fol Leymarie
                     <span class="print-only user-email">(ffl@dynaikon.com)</span>
                </div>
                <a href="#2022-02-16 07:51:24"><div class="time">2022-02-16 07:51:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks for pointing this; looks useful; but it is behind a paywall .. surprisingly not in OA.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-16 15:44:42">
            
                <img src="https://secure.gravatar.com/avatar/7e0d2f5ecd4f1c85405166545b4f2e66.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Akronix
                     <span class="print-only user-email">(akronix5@gmail.com)</span>
                </div>
                <a href="#2022-02-16 15:44:42"><div class="time">2022-02-16 15:44:42</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I was surprised too!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-02-16 16:05:09">
            
                <img src="https://avatars.slack-edge.com/2021-10-20/2615548747079_59b98294fae6beb7bd0b_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Carl Boettiger
                     <span class="print-only user-email">(cboettig@berkeley.edu)</span>
                </div>
                <a href="#2022-02-16 16:05:09"><div class="time">2022-02-16 16:05:09</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* </p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üôå Akronix, Lily Xu
                        </div>
                    
                        <div class="message-reaction">
                        :thumbsup_all: Frederic Fol Leymarie
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-03-07 06:24:24">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2385364021056_8aed180749aafbe43e0d_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Frederic Fol Leymarie
                     <span class="print-only user-email">(ffl@dynaikon.com)</span>
                </div>
                <a href="#2022-03-07 06:24:24"><div class="time">2022-03-07 06:24:24</div></a>
                <div class="msg">
                    <p>Interesting use of 3D depth from stereo pair camera traps, combined with optic flow: generates 3D bounding boxes/detection of animals in the wild (May 2022 issue): <a href="https://doi.org/10.1016/j.ecoinf.2021.101535">https://doi.org/10.1016/j.ecoinf.2021.101535</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://doi.org/10.1016/j.ecoinf.2021.101535">Improving wildlife tracking using 3D information</a></div>
                                <div class="link-text">
                                    The monitoring of wildlife populations is of growing importance due to the worldwide endangerment of many species, global climate change, and land cov‚Ä¶
                                </div>
                                
                                
    
        <a href="https://doi.org/10.1016/j.ecoinf.2021.101535">
            <img class="preview" src="https://ars.els-cdn.com/content/image/1-s2.0-S1574954121X00088-cov150h.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://doi.org/10.1016/j.ecoinf.2021.101535</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Oisin Mac Aodha, Sara Beery, Mitch Fennell, Timm Haucke
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-03-30 16:03:31">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-03-30 16:03:31"><div class="time">2022-03-30 16:03:31</div></a>
                <div class="msg">
                    <p><a href="https://www.nature.com/articles/s41893-022-00851-6">https://www.nature.com/articles/s41893-022-00851-6</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Nature</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nature.com/articles/s41893-022-00851-6">Improving biodiversity protection through artificial intelligence</a></div>
                                <div class="link-text">
                                    Nature Sustainability - Artificial intelligence methods can help biodiversity conservation planning in a rapidly evolving world. A framework based on reinforcement learning quantifies the trade-off...
                                </div>
                                
                                
    
        <a href="https://www.nature.com/articles/s41893-022-00851-6">
            <img class="preview" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41893-022-00851-6/MediaObjects/41893_2022_851_Fig1_HTML.png"
                width="306"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nature.com/articles/s41893-022-00851-6</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ Declan, Stefan Schneider, Carly Batist
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-03-31 03:55:44">
            
                <img src="https://avatars.slack-edge.com/2021-07-21/2282138326615_ba71cb2bb0552a879374_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Nico Lang
                     <span class="print-only user-email">(nila@di.ku.dk)</span>
                </div>
                <a href="#2022-03-31 03:55:44"><div class="time">2022-03-31 03:55:44</div></a>
                <div class="msg">
                    <p><a href="https://www.nature.com/articles/s41559-022-01702-5">https://www.nature.com/articles/s41559-022-01702-5</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Nature</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nature.com/articles/s41559-022-01702-5">Integrating remote sensing with ecology and evolution to advance biodiversity conservation</a></div>
                                <div class="link-text">
                                    Nature Ecology &amp;amp; Evolution - This Perspective discusses how the latest advances in remote sensing can be used to answer basic ecological and evolutionary questions, as well as contribute to...
                                </div>
                                
                                
    
        <a href="https://www.nature.com/articles/s41559-022-01702-5">
            <img class="preview" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41559-022-01702-5/MediaObjects/41559_2022_1702_Fig1_HTML.png"
                width="257"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nature.com/articles/s41559-022-01702-5</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üòç Sara Beery, Aude Vuilli
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-04-08 03:07:54">
            
                <img src="https://secure.gravatar.com/avatar/7e0d2f5ecd4f1c85405166545b4f2e66.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Akronix
                     <span class="print-only user-email">(akronix5@gmail.com)</span>
                </div>
                <a href="#2022-04-08 03:07:54"><div class="time">2022-04-08 03:07:54</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* is there open access for this article?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-04-07 15:54:44">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-04-07 15:54:44"><div class="time">2022-04-07 15:54:44</div></a>
                <div class="msg">
                    <p><strong>Which mammals can be identified from camera traps and crowdsourced photographs? (Roland Kays et al)</strong></p>

<p>While museum voucher specimens continue to be the standard for species identifications, biodiversity data are increasingly represented by photographic records from camera traps and amateur naturalists. Some species are easily recognized in these pictures, others are impossible to distinguish. Here we quantify the extent to which 335 terrestrial nonvolant North American mammals can be identified in typical photographs, with and without considering species range maps. We evaluated all pairwise comparisons of species and judged, based on professional opinion, whether they are visually distinguishable in typical pictures from camera traps or the iNaturalist crowdsourced platform on a 4-point scale: (1) always, (2) usually, (3) rarely, or (4) never. Most (96.5%) of the 55,944 pairwise comparisons were ranked as always or usually distinguishable in a photograph, leaving exactly 2,000 pairs of species that can rarely or never be distinguished from typical pictures, primarily within clades such as shrews and small-bodied rodents. Accounting for a species geographic range eliminates many problematic comparisons, such that the average number of difficult or impossible-to-distinguish species pairs from any location was 7.3 when considering all species, or 0.37 when considering only those typically surveyed with camera traps. The greatest diversity of difficult-to-distinguish species was in Arizona and New Mexico, with 57 difficult pairs of species, suggesting the problem scales with overall species diversity. Our results show which species are most readily differentiated by photographic data and which taxa should be identified only to higher taxonomic levels (e.g., genus). Our results are relevant to ecologists, as well as those using artificial intelligence to identify species in photographs, but also serve as a reminder that continued study of mammals through museum vouchers is critical since it is the only way to accurately identify many smaller species, provides a wealth of data unattainable from photographs, and constrains photographic records via accurate range maps. Ongoing specimen voucher collection, in addition to photographs, will become even more important as species ranges change, and photographic evidence alone will not be sufficient to document these dynamics for many species.</p>

<p><a href="https://academic.oup.com/jmammal/advance-article-abstract/doi/10.1093/jmammal/gyac021/6564439?redirectedFrom=fulltext">https://academic.oup.com/jmammal/advance-article-abstract/doi/10.1093/jmammal/gyac021/6564439?redirectedFrom=fulltext</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ Stefan Schneider
                        </div>
                    
                        <div class="message-reaction">
                        üì∑ Mitch Fennell
                        </div>
                    
                        <div class="message-reaction">
                        üëç Andr√©s C Rodr√≠guez, Carly Batist
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-04-10 22:02:02">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5746234343873_b69d1fc6df3c896e4909_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ed Miller
                     <span class="print-only user-email">(ed@hypraptive.com)</span>
                </div>
                <a href="#2022-04-10 22:02:02"><div class="time">2022-04-10 22:02:02</div></a>
                <div class="msg">
                    <p>New paper from the BearID Project: <a href="https://doi.org/10.1007/s42991-021-00168-5">https://doi.org/10.1007/s42991-021-00168-5</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">SpringerLink</div>
                            
                            
                                
                                <div class="link-title"><a href="https://doi.org/10.1007/s42991-021-00168-5">Multispecies facial detection for individual identification of wildlife: a case study across ursids</a></div>
                                <div class="link-text">
                                    Mammalian Biology - To address biodiversity decline in the era of big data, replicable methods of data processing are needed. Automated methods of individual identification (ID) via computer vision...
                                </div>
                                
                                
    
        <a href="https://doi.org/10.1007/s42991-021-00168-5">
            <img class="preview" src="https://media.springernature.com/w200/springer-static/cover/journal/42991.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://doi.org/10.1007/s42991-021-00168-5</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêª Stefan Schneider, Sara Beery, Carly Batist, Mitch Fennell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-04-12 03:17:47">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-04-12 03:17:47"><div class="time">2022-04-12 03:17:47</div></a>
                <div class="msg">
                    <p><a href="https://medium.com/wcs-conservation-solutions/conservation-technology-navigating-the-hype-ccb908db6958">https://medium.com/wcs-conservation-solutions/conservation-technology-navigating-the-hype-ccb908db6958</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Medium</div>
                            
                            
                                
                                <div class="link-title"><a href="https://medium.com/wcs-conservation-solutions/conservation-technology-navigating-the-hype-ccb908db6958">Conservation Technology: Navigating the Hype</a></div>
                                <div class="link-text">
                                    By Jonathan Palmer | April 8, 2022
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Reading time</div>
                                        5 min read
                                    </div>
                                
                                
    
        <a href="https://medium.com/wcs-conservation-solutions/conservation-technology-navigating-the-hype-ccb908db6958">
            <img class="preview" src="https://miro.medium.com/max/1200/1*Hjb7VrziFG4hiikjXh2Lig.jpeg"
                width="333"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://medium.com/wcs-conservation-solutions/conservation-technology-navigating-the-hype-ccb908db6958</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ü§î Akronix
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-04-13 04:49:02">
            
                <img src="https://avatars.slack-edge.com/2020-11-16/1504707042882_c3f9b6d588ff02468277_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Olivier Gimenez
                     <span class="print-only user-email">(oag.gimenez@gmail.com)</span>
                </div>
                <a href="#2022-04-13 04:49:02"><div class="time">2022-04-13 04:49:02</div></a>
                <div class="msg">
                    <p>Awesome collective effort led by @Noa Rigoudy @Simon Chamaill√© &amp; @Vincent Miele CNRS The DeepFaune initiative: a collaborative effort towards the automatic identification of the French fauna in camera-trap images <a href="https://www.biorxiv.org/content/10.1101/2022.03.15.484324v1">https://www.biorxiv.org/content/10.1101/2022.03.15.484324v1</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üéâ Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-04-15 10:30:15">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-04-15 10:30:15"><div class="time">2022-04-15 10:30:15</div></a>
                <div class="msg">
                    <p>Thanks for the pointer @Nico Lang ! <a href="https://doi.org/10.1016/j.ecoinf.2022.101641">https://doi.org/10.1016/j.ecoinf.2022.101641</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://doi.org/10.1016/j.ecoinf.2022.101641">Applications of computer vision and machine learning techniques for digitized herbarium specimens: A systematic literature review</a></div>
                                <div class="link-text">
                                    Herbaria contain the treasure of millions of specimens that have been preserved for several years for scientific studies. To increase the rate of scie‚Ä¶
                                </div>
                                
                                
    
        <a href="https://doi.org/10.1016/j.ecoinf.2022.101641">
            <img class="preview" src="https://ars.els-cdn.com/content/image/1-s2.0-S1574954121X00088-cov150h.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://doi.org/10.1016/j.ecoinf.2022.101641</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-04-22 10:30:07">
            
                <img src="https://avatars.slack-edge.com/2020-11-16/1504707042882_c3f9b6d588ff02468277_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Olivier Gimenez
                     <span class="print-only user-email">(oag.gimenez@gmail.com)</span>
                </div>
                <a href="#2022-04-22 10:30:07"><div class="time">2022-04-22 10:30:07</div></a>
                <div class="msg">
                    <p>Shameless self-promotion üòá</p>

<p>"Trade-off between deep learning for species identification and inference about predator-prey co-occurrence: Reproducible R workflow integrating models in computer vision and ecological statistics"</p>

<p>published in Computo a new diamond open access journal in statistics and machine learning ü§©</p>

<p><a href="https://computo.sfds.asso.fr/published-202204-deeplearning-occupancy-lynx/">https://computo.sfds.asso.fr/published-202204-deeplearning-occupancy-lynx/</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Oisin Mac Aodha, Leonardo Viotti, Suzanne Stathatos, Casey Youngflesh, Daniel Davila, Lloyd Hughes, Sara Beery, Marcus Lapeyrolerie
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-04-28 17:36:35">
            
                <img src="https://avatars.slack-edge.com/2022-04-13/3389743771268_d32d5dc0322c72494836_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Guillaume Chapron
                     <span class="print-only user-email">(carnivoreconservation@gmail.com)</span>
                </div>
                <a href="#2022-04-28 17:36:35"><div class="time">2022-04-28 17:36:35</div></a>
                <div class="msg">
                    <p>Just spotted in PNAS, <strong>Machine learning in evolutionary studies comes of age</strong>, attached.</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-05-17 21:15:52">
            
                <img src="https://avatars.slack-edge.com/2022-05-17/3540118273218_1219d360077461a4a3e4_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Reece  Rhinehart
                     <span class="print-only user-email">(rhin0098@pacificu.edu)</span>
                </div>
                <a href="#2022-05-17 21:15:52"><div class="time">2022-05-17 21:15:52</div></a>
                <div class="msg">
                    <p>Hi all! I‚Äôm currently an undergraduate student working on landscape connectivity research using Rad seq data from the Northern Red Legged Frog. I don‚Äôt have a computer science background but I came across some interesting papers and talks that lead me here. Specifically this paper and one of the papers that it sites about <em>Hyla squirella</em>. The work I‚Äôm doing currently does not use machine learning but I am extremely interested in how it could be applied. Not only to this current project but more broadly in ecological research. I‚Äôm hoping someone here with more experience and insight might be able to shed some light on these papers or at least give an opinion about the methods used, and their soundness or lack thereof.</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-01 12:43:10">
            
                <img src="https://secure.gravatar.com/avatar/887e6a153d6b5eb1fb4e062f35dd26b0.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ritwik
                     <span class="print-only user-email">(rittyun@yahoo.com)</span>
                </div>
                <a href="#2022-06-01 12:43:10"><div class="time">2022-06-01 12:43:10</div></a>
                <div class="msg">
                    <p><a href="https://arxiv.org/abs/2205.11324">https://arxiv.org/abs/2205.11324</a>
"Towards automatic detection of wildlife trade using machine vision models"
excited to share our new paper coming out soon.. we compare popular machine vision models on a new dataset to identify if a mammal is in a wild surrounding or is a captive individual. the aim is to develop image analysis techniques to monitor wildlife trade (sale of exotic species). we found interesting results by training specifically for negative features and testing on out of distribution test data.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2205.11324">Towards automatic detection of wildlife trade using machine vision models</a></div>
                                <div class="link-text">
                                    Unsustainable trade in wildlife is one of the major threats affecting the global biodiversity crisis. An important part of the trade now occurs on the internet, especially on digital marketplaces...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2205.11324">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2205.11324</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Stephanie O&#39;Donnell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-01 12:47:35">
            
                <img src="https://secure.gravatar.com/avatar/887e6a153d6b5eb1fb4e062f35dd26b0.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ritwik
                     <span class="print-only user-email">(rittyun@yahoo.com)</span>
                </div>
                <a href="#2022-06-01 12:47:35"><div class="time">2022-06-01 12:47:35</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Sara Beery a very late follow up on an old thread where i asked if watermarks affect results.. which i cant find on slack now..  (does the model use watermarks as features).. the short answer is yes, as expected.. i put an example in figure S3 of the supplementary doc.. so i guess important to mitigate watermark effects in classification..
(also, congratulations on your Ph.D. ! )</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-01 14:43:09">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-06-01 14:43:09"><div class="time">2022-06-01 14:43:09</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Ah cool!! "Yes, as expected"... yeah it really does cheat however it can huh</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-07 02:39:21">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-06-07 02:39:21"><div class="time">2022-06-07 02:39:21</div></a>
                <div class="msg">
                    <p>‚ÄúSmart Oceans: Artificial intelligence and marine protected area governance‚Äù
<a href="http://sciencedirect.com/science/article/pii/S2589811622000106">sciencedirect.com/science/article/pii/S2589811622000106</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ Declan, Carl Boettiger
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-23 11:30:58">
            
                <img src="https://avatars.slack-edge.com/2019-08-26/727564533250_4bda977d3f85f4f6fc06_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Amrita Gupta
                     <span class="print-only user-email">(agupta375@gatech.edu)</span>
                </div>
                <a href="#2022-06-23 11:30:58"><div class="time">2022-06-23 11:30:58</div></a>
                <div class="msg">
                    <p>‚ÄúTowards Continuous Streamflow Monitoring with Time-Lapse Cameras and Deep Learning‚Äù, some recent work with my inimitable co-authors @Tony Chang, @Jeff Walker, and @Ben Letcher! Thanks also to @Caleb Robinson and @Bistra Dilkina for feedback on early drafts and to @Dan Morris for championing this effort!
I will be presenting this paper at COMPASS in Seattle next week--if any of you will be at the conference, please come say hello!! üôÇ</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üòç Sara Beery, Lily Xu, Tony Chang, Carly Batist, Caleb Robinson
                        </div>
                    
                        <div class="message-reaction">
                        üëç Justin Kay, Dan Morris, Mitch Fennell, Aaron Ferber, Emilio Luz-Ricca, Jeff Walker, Caleb Robinson
                        </div>
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Bistra Dilkina, Suzanne Stathatos, Caleb Robinson
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-23 15:12:55">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-06-23 15:12:55"><div class="time">2022-06-23 15:12:55</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* do you have a link/DOI? thanks üôÇ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-24 13:26:21">
            
                <img src="https://avatars.slack-edge.com/2019-08-26/727564533250_4bda977d3f85f4f6fc06_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Amrita Gupta
                     <span class="print-only user-email">(agupta375@gatech.edu)</span>
                </div>
                <a href="#2022-06-24 13:26:21"><div class="time">2022-06-24 13:26:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Carly, there is a tentative DOI in the PDF, but the online version of the paper will become available a few weeks (months?) after the conference. We might also put this on arXiv, in which case I'll DM you back with a link.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Carly Batist
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-27 12:48:11">
            
                <img src="https://avatars.slack-edge.com/2019-08-26/727564533250_4bda977d3f85f4f6fc06_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Amrita Gupta
                     <span class="print-only user-email">(agupta375@gatech.edu)</span>
                </div>
                <a href="#2022-06-27 12:48:11"><div class="time">2022-06-27 12:48:11</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* The online version came out before I expected! Here's a working link, for any who are interested: <a href="https://doi.org/10.1145/3530190.3534805">https://doi.org/10.1145/3530190.3534805</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-06-24 09:14:26">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2385364021056_8aed180749aafbe43e0d_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Frederic Fol Leymarie
                     <span class="print-only user-email">(ffl@dynaikon.com)</span>
                </div>
                <a href="#2022-06-24 09:14:26"><div class="time">2022-06-24 09:14:26</div></a>
                <div class="msg">
                    <p>Recently published in OA: a solution for camera traps not relying on PIR, developed for an RPi base, using available motion vectors from the video standard format. Code base is available. <a href="https://www.sciencedirect.com/science/article/pii/S1574954122001066">https://www.sciencedirect.com/science/article/pii/S1574954122001066</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.sciencedirect.com/science/article/pii/S1574954122001066">Motion vectors and deep neural networks for video camera traps</a></div>
                                <div class="link-text">
                                    Commercial camera traps are usually triggered by a Passive Infra-Red (PIR) motion sensor necessitating a delay between triggering and the image being ‚Ä¶
                                </div>
                                
                                
    
        <a href="https://www.sciencedirect.com/science/article/pii/S1574954122001066">
            <img class="preview" src="https://ars.els-cdn.com/content/image/1-s2.0-S1574954122X00022-cov150h.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.sciencedirect.com/science/article/pii/S1574954122001066</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Kai Waddington
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-07-19 07:02:09">
            
                <img src="https://avatars.slack-edge.com/2023-07-25/5629330214405_c9ffd65d99b302ec8496_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Malte Pedersen
                     <span class="print-only user-email">(mape@create.aau.dk)</span>
                </div>
                <a href="#2022-07-19 07:02:09"><div class="time">2022-07-19 07:02:09</div></a>
                <div class="msg">
                    <p>Hello, we've proposed a very simple pipeline for re-identification of Giant Sunfish. It's based on keypoint matching using SuperPoint and SuperGlue and it works quite well without the need of any training or finetuning. We have not tried this on other animals, but we expect it to work on animals with distinct and unique patterns.
Example of usecase: we have helped marine researchers to annotate a large database of Sunfish images by providing them the top-X ranked matches simply based on the number of matched keypoints.</p>

<p>Pedersen, M., Haurum, J.B., Moeslund, T.B. and Nyegaard, M., 2022, March. Re-Identification of Giant Sunfish using Keypoint Matching. In <em>Proceedings of the Northern Lights Deep Learning Workshop</em> (Vol. 3).
<a href="https://www.eludamos.org/index.php/nldl/article/view/6234">https://www.eludamos.org/index.php/nldl/article/view/6234</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ Cameron Trotter, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-07-19 07:21:34">
            
                <img src="https://avatars.slack-edge.com/2021-10-07/2577859750882_26b259c7e2145a81f7eb_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Luk√°≈° Adam
                     <span class="print-only user-email">(lukas.adam.cr@gmail.com)</span>
                </div>
                <a href="#2022-07-19 07:21:34"><div class="time">2022-07-19 07:21:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Very nice. I would like to ask whether the dataset is public.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-07-19 07:27:36">
            
                <img src="https://avatars.slack-edge.com/2023-07-25/5629330214405_c9ffd65d99b302ec8496_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Malte Pedersen
                     <span class="print-only user-email">(mape@create.aau.dk)</span>
                </div>
                <a href="#2022-07-19 07:27:36"><div class="time">2022-07-19 07:27:36</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Lukas, unfortunately not. We have only used a small portion (~90 images and ~30 IDs) of the Match My Mola dataset in the paper (simply because it was the only images that had been manually re-identified by the marine researchers at the time).
We are working on making the entire dataset (several thousand images) publicly available, but we are not done manually verifying the annotations yet and we also need to gather licenses to the images, which are most often provided by tourist divers.</p>

<p>I will drop a post if we get the dataset online (I cross my fingers), but it will probably not be until the end of this year or beginning of the next.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-07-19 07:29:08">
            
                <img src="https://avatars.slack-edge.com/2021-10-07/2577859750882_26b259c7e2145a81f7eb_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Luk√°≈° Adam
                     <span class="print-only user-email">(lukas.adam.cr@gmail.com)</span>
                </div>
                <a href="#2022-07-19 07:29:08"><div class="time">2022-07-19 07:29:08</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Perfect. Please write me a message if you manage to make it public. Thanks üôÇ</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Malte Pedersen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-07-21 11:56:25">
            
                <img src="https://avatars.slack-edge.com/2023-07-07/5539950667174_dcdf280a4cdeb98dc8d2_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Justin Kay
                     <span class="print-only user-email">(justinkay92@gmail.com)</span>
                </div>
                <a href="#2022-07-21 11:56:25"><div class="time">2022-07-21 11:56:25</div></a>
                <div class="msg">
                    <p>Hi everyone, we're excited to introduce The Caltech Fish Counting Dataset (CFC): A Benchmark for Multiple-Object Tracking and Counting, to appear at ECCV 2022!</p>

<p>CFC is a large-scale dataset for detecting, tracking, and counting fish in sonar videos, an important conservation application and a rich data source for advancing low signal-to-noise computer vision applications and tackling domain generalization in tracking and counting.</p>

<p>Sonar video is used to monitor salmon during their seasonal migration, informing sustainable fisheries management. Manually counting fish in these videos requires significant effort. Automation using computer vision could reduce this burden and help scale up monitoring efforts.</p>

<p>To enable this, we collected over half a million annotations in over 1,500 videos sourced from seven different sonar cameras, allowing researchers to train multiple-object tracking and counting algorithms and evaluate generalization performance at unseen test locations.</p>

<p>We encourage others to check out the dataset (linked below) and join us in tackling these challenges! Work done with an amazing team: @Peter Kulits @Suzanne Stathatos @Tiffany Deng @Erik Young @Sara Beery @gvanhorn @Pietro Perona</p>

<p>Data and code: <a href="https://github.com/visipedia/caltech-fish-counting">https://github.com/visipedia/caltech-fish-counting</a>
Paper: <a href="https://arxiv.org/abs/2207.09295">https://arxiv.org/abs/2207.09295</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2207.09295">The Caltech Fish Counting Dataset: A Benchmark for Multiple-Object...</a></div>
                                <div class="link-text">
                                    We present the Caltech Fish Counting Dataset (CFC), a large-scale dataset for detecting, tracking, and counting fish in sonar videos. We identify sonar videos as a rich source of data for...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2207.09295">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2207.09295</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">visipedia/caltech-fish-counting</a></div>
                                <div class="link-text">
                                    The Caltech Fish Counting Dataset
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        3
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        Python
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêü Sara Beery, gvanhorn, Stefan Schneider, Elijah Cole, Oisin Mac Aodha, Mitch Fennell, Daniel Davila, Ben Weinstein, Oliver Broadrick, Amrita Gupta, Suzanne Stathatos, Eddie Zhang, Marcus Lapeyrolerie, Lukas Picek, Casey Youngflesh, Riccardo de Lutio, Carl Boettiger, Bj√∂rn L√ºtjens, Malte Pedersen
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Carly Batist, Lukas Picek, Dan Morris
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-08-27 10:42:50">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-08-27 10:42:50"><div class="time">2022-08-27 10:42:50</div></a>
                <div class="msg">
                    <p>@Dan Morris @Sara Beery <a href="https://arxiv.org/pdf/2208.10607.pdf">https://arxiv.org/pdf/2208.10607.pdf</a> with data <a href="https://github.com/jonathanventura/urban-tree-detection-data">https://github.com/jonathanventura/urban-tree-detection-data</a> to be added to lila.science</p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">jonathanventura/urban-tree-detection-data</a></div>
                                <div class="link-text">
                                    Dataset for training and evaluating tree detectors in urban environments with aerial imagery
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Last updated</div>
                                        8 days ago
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üå≥ Dan Morris, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-08-28 05:25:56">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-08-28 05:25:56"><div class="time">2022-08-28 05:25:56</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Added to the list here:</p>

<p><a href="https://lila.science/otherdatasets#images-plants">https://lila.science/otherdatasets#images-plants</a></p>

<p>LMK if you know of other datasets that belong on that list.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="https://lila.science/otherdatasets#images-plants">List of other conservation data sets - LILA BC</a></div>
                                <div class="link-text">
                                    LILA BC - List of other conservation-related data sets
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Written by</div>
                                        lilawp
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Est. reading time</div>
                                        16 minutes
                                    </div>
                                
                                
    
        <a href="https://lila.science/otherdatasets#images-plants">
            <img class="preview" src="http://lila.science/wp-content/uploads/2019/03/inat150.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://lila.science/otherdatasets#images-plants</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-08-31 22:52:09">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-08-31 22:52:09"><div class="time">2022-08-31 22:52:09</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* also @Dan Morris, old dataset, but actually a really interesting paper <a href="http://bird.nae-lab.org/cattle/">http://bird.nae-lab.org/cattle/</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">bird.nae-lab.org</div>
                            
                            
                                
                                <div class="link-title"><a href="http://bird.nae-lab.org/cattle/">Cattle datasets</a></div>
                                <div class="link-text">
                                    ËãóÊùëÁ†îÁ©∂ÂÆ§, Êù±Â§ß, ÊÉÖÂ†±ÁêÜÂ∑•, ÈõªÂ≠êÊÉÖÂ†±, Â≠¶ÈöõÊÉÖÂ†±, ÊÉÖÂ†±Â≠¶Áí∞, ÂÖàÁ´ØË°®Áèæ, „Ç§„É≥„Çø„Éï„Çß„Éº„Çπ, „Éê„Éº„ÉÅ„É£„É´„É™„Ç¢„É™„ÉÜ„Ç£, „É°„Éá„Ç£„Ç¢„Ç¢„Éº„Éà, Êò†ÂÉè„É°„Éá„Ç£„Ç¢
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: http://bird.nae-lab.org/cattle/</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-01 18:07:38">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-01 18:07:38"><div class="time">2022-09-01 18:07:38</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks!  Added to:</p>

<p><a href="https://lila.science/otherdatasets#images-domestic-animals">https://lila.science/otherdatasets#images-domestic-animals</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">LILA BC</div>
                            
                            
                                
                                <div class="link-title"><a href="https://lila.science/otherdatasets#images-domestic-animals">List of other conservation data sets - LILA BC</a></div>
                                <div class="link-text">
                                    LILA BC - List of other conservation-related data sets
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Written by</div>
                                        lilawp
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Est. reading time</div>
                                        16 minutes
                                    </div>
                                
                                
    
        <a href="https://lila.science/otherdatasets#images-domestic-animals">
            <img class="preview" src="http://lila.science/wp-content/uploads/2019/03/inat150.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://lila.science/otherdatasets#images-domestic-animals</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-04 10:47:08">
            
                <img src="https://avatars.slack-edge.com/2022-07-02/3776325920368_58b86521162ba76c0e0e_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Eddie Zhang
                     <span class="print-only user-email">(ete@ucsb.edu)</span>
                </div>
                <a href="#2022-09-04 10:47:08"><div class="time">2022-09-04 10:47:08</div></a>
                <div class="msg">
                    <p><a href="https://www.deepmind.com/blog/advancing-conservation-with-ai-based-facial-recognition-of-turtles">https://www.deepmind.com/blog/advancing-conservation-with-ai-based-facial-recognition-of-turtles</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">deepmind.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.deepmind.com/blog/advancing-conservation-with-ai-based-facial-recognition-of-turtles">Advancing conservation with AI-based facial recognition of turtles</a></div>
                                <div class="link-text">
                                    We came across Zindi ‚Äì a dedicated partner with complementary goals ‚Äì who are the largest community of African data scientists and host competitions that focus on solving Africa‚Äôs most pressing problems. Our Science team‚Äôs Diversity, Equity, and Inclusion (DE&amp;amp;I) team worked with Zindi to identify a scientific challenge that could help advance conservation efforts and grow involvement in AI. Inspired by Zindi‚Äôs bounding box turtle challenge, we landed on a project with the potential for real impact: turtle facial recognition.
                                </div>
                                
                                
    
        <a href="https://www.deepmind.com/blog/advancing-conservation-with-ai-based-facial-recognition-of-turtles">
            <img class="preview" src="https://assets-global.website-files.com/621e749a546b7592125f38ed/6306106e19cc74840f40121a_Turtle%20Recall.webp"
                width="444"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.deepmind.com/blog/advancing-conservation-with-ai-based-facial-recognition-of-turtles</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Carly Batist, Dan Morris, Lily Xu, Cameron Trotter
                        </div>
                    
                        <div class="message-reaction">
                        üê¢ Lily Xu, Georgia Atkinson
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-06 15:18:16">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-09-06 15:18:16"><div class="time">2022-09-06 15:18:16</div></a>
                <div class="msg">
                    <p>Just because they are too polite to post it themselves, really interesting paper from @Devis Tuia group out this week. Trying to build explicit biological knowledge into black box models. Out of curiosity, are there tree stems (x,y point locations) associated with the NFI plot data, or just land-cover classifications?</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Devis Tuia, Eddie Zhang, Elijah Cole, Emilio Luz-Ricca, Rowan Converse, Thi√™n-Anh Nguyen, Suzanne Stathatos, Burak Ekim
                        </div>
                    
                        <div class="message-reaction">
                        üëè Blair Costelloe, Riccardo de Lutio, Oisin Mac Aodha, Dan Morris, Andr√©s C Rodr√≠guez, Jeff Reed
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-07 03:54:33">
            
                <img src="https://avatars.slack-edge.com/2022-09-13/4069718985029_0fa5ae02870d12068e52_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Thi√™n-Anh Nguyen
                     <span class="print-only user-email">(thien-anh.nguyen@epfl.ch)</span>
                </div>
                <a href="#2022-09-07 03:54:33"><div class="time">2022-09-07 03:54:33</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hi Ben, thanks for sharing the paper, and glad that you like it! Regarding the NFI plot data, the Swiss NFI team provided me with land-cover classification data only. I've heard that internally, they have a dataset of geo-located trees, but to my knowledge it is not openly available. More info on the Swiss NFI here: <a href="https://www.lfi.ch/publikationen/publ/ergebnisberichte/lfi4.php">https://www.lfi.ch/publikationen/publ/ergebnisberichte/lfi4.php</a> (some documents are only in French or German unfortunately).</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-08 22:57:43">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-09-08 22:57:43"><div class="time">2022-09-08 22:57:43</div></a>
                <div class="msg">
                    <p>Fish dataset for object detection <a href="http://metadata.nmdc.no/metadata-api/landingpage/01d102345aef4639f063a13ea20cd3f3">http://metadata.nmdc.no/metadata-api/landingpage/01d102345aef4639f063a13ea20cd3f3</a> <a href="https://rmets.onlinelibrary.wiley.com/doi/10.1002/gdj3.114">https://rmets.onlinelibrary.wiley.com/doi/10.1002/gdj3.114</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üêü Malte Pedersen, Cameron Trotter
                        </div>
                    
                        <div class="message-reaction">
                        üòç Rita Pucci
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-08 22:57:49">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-09-08 22:57:49"><div class="time">2022-09-08 22:57:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-09 11:32:02">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-09 11:32:02"><div class="time">2022-09-09 11:32:02</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks!  Added to:</p>

<p><a href="https://lila.science/otherdatasets#images-marine">https://lila.science/otherdatasets#images-marine</a></p>

<p>The community is getting really close to a critical mass of public data for training a general-purpose fish detector, and I'm seeing a decent amount of demand for that.</p>

<p>Now, I know someone would still have to actually train that detector, and validate that it's useful for anyone's real scenario, yadda yadda, deep learning, yadda yadda.</p>

<p>But can we get to the important stuff in advance?  Specifically, can we get the great minds at DrivenData - legendary pun-creators of the AI for Conservation community - to start naming the hypothetical fish detector that no one has built yet?</p>

<p>@Greg Lipstein @Peter Bull</p>
                    
                    
                    
                        <div class="message-reaction">
                        üòÇ Daniel Davila, Peter Bull
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-09 11:43:50">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2361920803907_ad849dc380fc3d3470dc_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Daniel Davila
                     <span class="print-only user-email">(daniel.davila@kitware.com)</span>
                </div>
                <a href="#2022-09-09 11:43:50"><div class="time">2022-09-09 11:43:50</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I feel like I've read 10 papers titled FishNet</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-09 11:43:57">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2361920803907_ad849dc380fc3d3470dc_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Daniel Davila
                     <span class="print-only user-email">(daniel.davila@kitware.com)</span>
                </div>
                <a href="#2022-09-09 11:43:57"><div class="time">2022-09-09 11:43:57</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Please not FishNet</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-09 11:48:35">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2361920803907_ad849dc380fc3d3470dc_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Daniel Davila
                     <span class="print-only user-email">(daniel.davila@kitware.com)</span>
                </div>
                <a href="#2022-09-09 11:48:35"><div class="time">2022-09-09 11:48:35</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Including my personal favorite, this one that has nothing to do with wildlife it just kinda looks like a fish</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-09 11:48:41">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2361920803907_ad849dc380fc3d3470dc_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Daniel Davila
                     <span class="print-only user-email">(daniel.davila@kitware.com)</span>
                </div>
                <a href="#2022-09-09 11:48:41"><div class="time">2022-09-09 11:48:41</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* </p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üêü Dan Morris
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-09 11:54:47">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-09 11:54:47"><div class="time">2022-09-09 11:54:47</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Image generators that design image generators that look like images is the next frontier in deep learning.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-09 13:21:31">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-09-09 13:21:31"><div class="time">2022-09-09 13:21:31</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* This seems like a good place to bring up that a long term goal for our lab in Florida is a unified animal detector across remote imagery, fish/bird/mammal. I'm very interested in opinions whether we think there are inherent tradeoffs in trying to bring a diverse group of imagery together. Whether camera trap and airborne imagery can live in the same model. Whether training on birds means we are likely to get poorer features for fish, etc. Its one of the reasons I keep sending datasets to LILA is that along with @Benjamin Kellenberger I see the future as running though a system like AIDE for general screening and then using these features as a starting point for species classification models. We took a baby step <a href="https://www.sciencedirect.com/science/article/pii/S157495412030011X">https://www.sciencedirect.com/science/article/pii/S157495412030011X</a>, looking at training models across different forests and did not find any tradeoffs, i.e learning trees in california did not make a new york tree model worse.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.sciencedirect.com/science/article/pii/S157495412030011X">Cross-site learning in deep learning RGB tree crown detection</a></div>
                                <div class="link-text">
                                    Tree crown detection is a fundamental task in remote sensing for forestry and ecosystem ecology. While many individual tree segmentation algorithms ha‚Ä¶
                                </div>
                                
                                
    
        <a href="https://www.sciencedirect.com/science/article/pii/S157495412030011X">
            <img class="preview" src="https://ars.els-cdn.com/content/image/1-s2.0-S1574954119X00072-cov150h.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.sciencedirect.com/science/article/pii/S157495412030011X</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-09 13:32:58">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-09-09 13:32:58"><div class="time">2022-09-09 13:32:58</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I would bet $20 that [camera trap data] and [fish data from camera-trap-like-angles] will get the best overall results from living in separate models, and I would bet $50 that either of those will get the best overall results from living in separate models from airborne imagery, but I wouldn't bet $100 on any of those hypotheses.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Malte Pedersen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-09 13:44:39">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-09-09 13:44:39"><div class="time">2022-09-09 13:44:39</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* interesting. I think the question becomes what kind of tradeoffs are involved. I think it would be a huge benefit to the community to have such a starting point, and might be worth a few percentage accuracy. If its 20% accuracy then no, that's not worth it.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-09 13:45:38">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-09-09 13:45:38"><div class="time">2022-09-09 13:45:38</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* or whether an airborne only perspective is useful just as a separate model</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-09 13:49:34">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-09-09 13:49:34"><div class="time">2022-09-09 13:49:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* the other piece to this, that i've wanted to talk to @gvanhorn is whether highly curated images, such as the millions at the Macaulay Library have role in training these broad models, atleast within birds. Either through synthetically creating airborne data from these images, or in teaching the model what a side on/high quality view looks like. I've been looking at airborne images from @Brad Pickens and others from fish and wildlife and thinking about those side-on data from Cornell.</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-14 18:02:15">
            
                <img src="https://secure.gravatar.com/avatar/4247dd9e36bf1ad0ccccb95a7ea75b4b.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Peter Bull
                     <span class="print-only user-email">(peter@drivendata.org)</span>
                </div>
                <a href="#2022-09-14 18:02:15"><div class="time">2022-09-14 18:02:15</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* &gt; Specifically, can we get the great minds at DrivenData - legendary pun-creators of the AI for Conservation community - to start naming the hypothetical fish detector that no one has built yet?
@Dan Morris Was pretty proud of <a href="https://www.drivendata.org/competitions/48/identify-fish-challenge/">this one</a>!  That said, I started thinking something like ‚Äúicth-ference‚Äù but that is maybe a little unwieldy. We‚Äôll need to workshop it‚Ä¶.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">DrivenData</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.drivendata.org/competitions/48/identify-fish-challenge/">N+1 fish, N+2 fish</a></div>
                                <div class="link-text">
                                    Sustainable fishing means tracking every fish caught. New tools using automated video processing and artificial intelligence can help responsible fisheries comply with regulations, save time, and lower the safety risk and cost from an auditor on board.
                                </div>
                                
                                
    
        <a href="https://www.drivendata.org/competitions/48/identify-fish-challenge/">
            <img class="preview" src="https://drivendata-prod-public.s3.amazonaws.com/comp_images/fish-tile.png"
                width="387"
                 height="222" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.drivendata.org/competitions/48/identify-fish-challenge/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üê° Dan Morris
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-20 03:19:46">
            
                <img src="https://avatars.slack-edge.com/2023-07-25/5629330214405_c9ffd65d99b302ec8496_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Malte Pedersen
                     <span class="print-only user-email">(mape@create.aau.dk)</span>
                </div>
                <a href="#2022-09-20 03:19:46"><div class="time">2022-09-20 03:19:46</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Ben Weinstein Due to the huge differences between the aquatic and terrestrial domains <strong>I think</strong> a single model to "solve" it all is not feasible (or not the best option, at least). The attenuation of light, backscatter, refraction, and turbidity (when you are under water) combined with different camera sensors, image compression, a ton of different species etc. etc. is just a huge mouthful. Another solution could be to have a single model that analyses the environment of the image/video and classifies whether it is, e.g., 1) clear underwater 2) air-borne terrestrial 3) turbid underwater 4) bla bla... and then you can use that to automatically choose which model is best suited to use. Like a cascade of small models, which can be individually fine-tuned and adjusted. IMO this could lead to easier maintenance and debugging and probably much better results. Just my thoughts üëç</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-21 11:22:06">
            
                <img src="https://avatars.slack-edge.com/2024-08-02/7510233340197_2e10694603b688fab440_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Josh Veitch-Michaelis
                     <span class="print-only user-email">(j.veitchmichaelis@gmail.com)</span>
                </div>
                <a href="#2022-09-21 11:22:06"><div class="time">2022-09-21 11:22:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Malte Pedersen I think this is where foundational models should be useful. Train an unsupervised backbone model on a huge corpus of remotely sensed imagery (e.g. camera trap, aerial, etc) - views/images that are not generally in common large image datasets that CV researchers use. And then use those models as strong feature extractors for few-shot learning on target tasks.</p>

<p>This is especially a problem for satellite data because of domain shift between instruments. Models often don't transfer well even between similar satellites e.g. Sentinel 2 -&gt; Landsat. Terrestrial based models seem to do better, but maybe we're taking advantage of millions of individual cameras in training corpora like OpenImages/ImageNet.</p>

<p>Problem is usually these models are expensive to train and curate - you need huge amounts of data and compute, but at least once someone's done it once it should be reusable. And you'd probably need a suite of models for generic applications like 'horizontal' camera trap, airborne, satellite, etc. That ought to be a better approach than everyone fine-tuning networks that are at some point derived from ImageNet and experimentally it seems to work well.</p>

<p><a href="https://arxiv.org/abs/2108.07258">https://arxiv.org/abs/2108.07258</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2108.07258">On the Opportunities and Risks of Foundation Models</a></div>
                                <div class="link-text">
                                    AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2108.07258">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2108.07258</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Malte Pedersen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-21 11:36:57">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2361920803907_ad849dc380fc3d3470dc_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Daniel Davila
                     <span class="print-only user-email">(daniel.davila@kitware.com)</span>
                </div>
                <a href="#2022-09-21 11:36:57"><div class="time">2022-09-21 11:36:57</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* There is some critical mass of data and modalities where throwing everything into a pot does produce some incredible results. The extreme example of this are the large foundational models like CLIP, etc... which actually work incredibly well on a huge number of domains. We've played with CLIP for ground imagery, aerial, satellite, multiple modalities (EO, IR, SAR), etc... and it just works. This is trained on something like a billion text-image pairs though. Im not sure anyone has a great heuristic (definitely not a formula) for saying where that magic line is, above which you can throw everything into a pot and outperform models trained on very specific tasks, e.g. a small set of animals in a single domain. Practically all the successful applications Ive seen try to limit the ontology of what the network has to learn to be as narrow as it can be and still add value</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-22 03:51:20">
            
                <img src="https://avatars.slack-edge.com/2023-07-25/5629330214405_c9ffd65d99b302ec8496_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Malte Pedersen
                     <span class="print-only user-email">(mape@create.aau.dk)</span>
                </div>
                <a href="#2022-09-22 03:51:20"><div class="time">2022-09-22 03:51:20</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Josh Veitch-Michaelis as you also mention there are many pitfalls and uncertainties regarding the behavior and nature of foundation models. You loose a lot of control and it is extremely difficult to explain the decisions made by such large and diverse models (even more difficult than regular DL models, which are already unexplainable for most (all?) experts). In my opinion, explainability is extremely important when it comes to decisions that actively affect humans and/or animals. That said, I completely agree that foundation models could potentially be extremely useful for this application. Very interesting!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2022-09-09 13:21:35">
            
                <img src="https://avatars.slack-edge.com/2020-04-11/1056293086643_e199e9ee13e18ee1ce23_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Benjamin Kellenberger
                     <span class="print-only user-email">(benjamin.kellenberger@wur.nl)</span>
                </div>
                <a href="#2022-09-09 13:21:35"><div class="time">2022-09-09 13:21:35</div></a>
                <div class="msg">
                    <p>@Benjamin Kellenberger has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2022-09-09 13:49:37">
            
                <img src="https://avatars.slack-edge.com/2022-10-20/4236948455079_1074b1375f1a05290bed_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Brad Pickens
                     <span class="print-only user-email">(bradley_pickens@fws.gov)</span>
                </div>
                <a href="#2022-09-09 13:49:37"><div class="time">2022-09-09 13:49:37</div></a>
                <div class="msg">
                    <p>@Brad Pickens has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-20 08:02:32">
            
                <img src="https://secure.gravatar.com/avatar/8506d912aad282c3247f4196b17cef3e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0007-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Emily Lines
                     <span class="print-only user-email">(erl27@cam.ac.uk)</span>
                </div>
                <a href="#2022-09-20 08:02:32"><div class="time">2022-09-20 08:02:32</div></a>
                <div class="msg">
                    <p>New paper from @Matt Allen - "Tree species classification from complex laser scanning data in Mediterranean forests using deep learning" <a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13981">https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13981</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üå≥ Sara Beery, Carly Batist, Lucia Gordon
                        </div>
                    
                        <div class="message-reaction">
                        üëç:skin_tone_5: Ando Shah
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-21 23:57:52">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-09-21 23:57:52"><div class="time">2022-09-21 23:57:52</div></a>
                <div class="msg">
                    <p><a href="https://www.sciencedirect.com/science/article/pii/S2352938522001446">https://www.sciencedirect.com/science/article/pii/S2352938522001446</a> not an AI paper, but about 7% difference between elephant seals in satellite and drone in the Antarctic, @Heather Lynch @Casey Youngflesh @Devis Tuia and anyone else working on seals/pinnipeds</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.sciencedirect.com/science/article/pii/S2352938522001446">Seals from outer space - Population census of southern elephant seals using VHR satellite imagery</a></div>
                                <div class="link-text">
                                    This work aims to assess the utility of World-View 3 satellite imagery of 31¬†cm resolution for conducting population censuses of southern elephant sea‚Ä¶
                                </div>
                                
                                
    
        <a href="https://www.sciencedirect.com/science/article/pii/S2352938522001446">
            <img class="preview" src="https://ars.els-cdn.com/content/image/1-s2.0-S2352938522X00037-cov150h.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.sciencedirect.com/science/article/pii/S2352938522001446</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Valentin Gabeff, Riccardo de Lutio, Casey Youngflesh, Lily Xu, Carly Batist, Rowan Converse, Dan Morris
                        </div>
                    
                        <div class="message-reaction">
                        ü¶≠ Alex Borowicz
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-09-26 18:40:43">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-09-26 18:40:43"><div class="time">2022-09-26 18:40:43</div></a>
                <div class="msg">
                    <p>not necessarily AI-specific, but cool none the less with lots of potential applications for AI - <a href="https://www.nature.com/articles/s41467-022-33223-x">https://www.nature.com/articles/s41467-022-33223-x</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Nature</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nature.com/articles/s41467-022-33223-x">Battery-free wireless imaging of underwater environments</a></div>
                                <div class="link-text">
                                    Nature Communications - The authors present an approach to underwater imaging, which does not require tethering or batteries. The low-power camera uses power from harvested acoustic energy and...
                                </div>
                                
                                
    
        <a href="https://www.nature.com/articles/s41467-022-33223-x">
            <img class="preview" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41467-022-33223-x/MediaObjects/41467_2022_33223_Fig1_HTML.png"
                width="485"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nature.com/articles/s41467-022-33223-x</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ Yseult Hb
                        </div>
                    
                        <div class="message-reaction">
                        üëç Bourhan
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-03 09:32:21">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-10-03 09:32:21"><div class="time">2022-10-03 09:32:21</div></a>
                <div class="msg">
                    <p><a href="https://www.biorxiv.org/content/10.1101/2022.02.19.481011v3.full">https://www.biorxiv.org/content/10.1101/2022.02.19.481011v3.full</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Emilio Luz-Ricca, Yseult Hb
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-04 08:00:11">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-10-04 08:00:11"><div class="time">2022-10-04 08:00:11</div></a>
                <div class="msg">
                    <p><a href="https://medium.com/@unassuming_yonder_snake_966/distribution-and-individual-chital-recapture-using-neural-networks-17e838fe6639">https://medium.com/@unassuming_yonder_snake_966/distribution-and-individual-chital-recapture-using-neural-networks-17e838fe6639</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Medium</div>
                            
                            
                                
                                <div class="link-title"><a href="https://medium.com/@unassuming_yonder_snake_966/distribution-and-individual-chital-recapture-using-neural-networks-17e838fe6639">Distribution and individual chital recapture using Neural Networks</a></div>
                                <div class="link-text">
                                    Prey decline is a major threat to vitality of wild tigers and safety in national park Bardia located in South-Western Nepal. Chitals (Axis‚Ä¶
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Reading time</div>
                                        3 min read
                                    </div>
                                
                                
    
        <a href="https://medium.com/@unassuming_yonder_snake_966/distribution-and-individual-chital-recapture-using-neural-networks-17e838fe6639">
            <img class="preview" src="https://miro.medium.com/max/945/1*yDerJAWpyvv467_v37ODoQ.png"
                width="375"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://medium.com/@unassuming_yonder_snake_966/distribution-and-individual-chital-recapture-using-neural-networks-17e838fe6639</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-04 14:00:11">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-10-04 14:00:11"><div class="time">2022-10-04 14:00:11</div></a>
                <div class="msg">
                    <p>This is an interesting application of super resolution <a href="https://openaccess.thecvf.com/content/WACV2022W/RWS/papers/Xue_Small_or_Far_Away_Exploiting_Deep_Super-Resolution_and_Altitude_Data_WACVW_2022_paper.pdf">https://openaccess.thecvf.com/content/WACV2022W/RWS/papers/Xue<em>Small</em>or<em>Far</em>Away<em>Exploi[‚Ä¶]ep</em>Super-Resolution<em>and</em>Altitude<em>Data</em>WACVW<em>2022</em>paper.pdf</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üôè Majid Mirmehdi, Sara Beery, Ian Ocholla
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-04 16:50:08">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-10-04 16:50:08"><div class="time">2022-10-04 16:50:08</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Anna Boser</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-10 11:00:58">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-10-10 11:00:58"><div class="time">2022-10-10 11:00:58</div></a>
                <div class="msg">
                    <p><a href="https://arxiv.org/abs/2210.00889">https://arxiv.org/abs/2210.00889</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2210.00889">Learnable Acoustic Frontends in Bird Activity Detection</a></div>
                                <div class="link-text">
                                    Autonomous recording units and passive acoustic monitoring present minimally intrusive methods of collecting bioacoustics data. Combining this data with species agnostic bird activity detection...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2210.00889">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2210.00889</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Justin Kay, Sara Beery, Georgia Atkinson
                        </div>
                    
                        <div class="message-reaction">
                        üëÄ John Martinsson
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-12 15:54:01">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-10-12 15:54:01"><div class="time">2022-10-12 15:54:01</div></a>
                <div class="msg">
                    <p>@Vienna Saccomanno has a cool paper on drones and kelp. <a href="https://zslpublications.onlinelibrary.wiley.com/doi/10.1002/rse2.295">https://zslpublications.onlinelibrary.wiley.com/doi/10.1002/rse2.295</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2022-10-12 15:54:04">
            
                <img src="https://avatars.slack-edge.com/2021-03-09/1863703098064_fc52292dd462e457037f_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Vienna Saccomanno
                     <span class="print-only user-email">(v.r.saccomanno@tnc.org)</span>
                </div>
                <a href="#2022-10-12 15:54:04"><div class="time">2022-10-12 15:54:04</div></a>
                <div class="msg">
                    <p>@Vienna Saccomanno has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-16 08:12:20">
            
                <img src="https://avatars.slack-edge.com/2022-10-11/4203870994483_c201360f475a1bd6a180_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Titus
                     <span class="print-only user-email">(titus@colossal.com)</span>
                </div>
                <a href="#2022-10-16 08:12:20"><div class="time">2022-10-16 08:12:20</div></a>
                <div class="msg">
                    <p>Good morning! Peter Bermant, @Leah Brickson, and I just released a new paper on bioRxiv that we'd like to share  <a href="https://doi.org/10.1101/2022.10.12.511740">https://doi.org/10.1101/2022.10.12.511740</a>. We'd love your feedback!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">bioRxiv</div>
                            
                            
                                
                                <div class="link-title"><a href="https://doi.org/10.1101/2022.10.12.511740">Bioacoustic Event Detection with Self-Supervised Contrastive Learning</a></div>
                                <div class="link-text">
                                    While deep learning has revolutionized ecological data analysis, existing strategies often rely on supervised learning, which is subject to limitations on real-world applicability. In this paper, we apply self supervised deep learning methods to bioacoustic data to enable unsupervised detection of bioacoustic event boundaries. We propose a convolutional deep neural network that operates on the raw waveform directly and is trained in accordance with the Noise Contrastive Estimation principle, which enables the system to detect spectral changes in the input acoustic stream. The model learns a representation of the input audio sampled at low frequency that encodes information regarding dissimilarity between sequential acoustic windows. During inference, we use a peak finding algorithm to search for regions of high dissimilarity in order to identify temporal boundaries of bioacoustic events. We report results using these techniques to detect sperm whale (Physeter macrocephalus) coda clicks in real-world recordings, and we demonstrate the viability of analyzing the vocalizations of other species (e.g. Bengalese finch syllable segmentation) in addition to other data modalities (e.g. animal behavioral dynamics, embryo development and tracking). We find that the self-supervised deep representation learning-based technique outperforms established threshold-based baseline methods without requiring manual annotation of acoustic datasets. Quantitatively, our approach yields a maximal R-value and F1-score of 0.887 and 0.876, respectively, and an area under the Precision-Recall curve (PR-AUC) of 0.917, while a threshold detector based on signal energy amplitude returns a maximal R-value and F1-score of 0.620 and 0.576, respectively, and a PR-AUC of 0.571. The findings of this paper establish the validity of unsupervised bioacoustic event detection using deep neural networks and self-supervised contrastive learning as an effective alternative to conventional techniques that leverage supervised methods for signal presence indication. Providing a means for highly accurate unsupervised detection, this paper serves as an important step towards developing a fully automated system for real-time acoustic monitoring of bioacoustic signals in real-world acoustic data. All code and data used in this study are available online. ### Competing Interest Statement The authors have declared no competing interest.
                                </div>
                                
                                
    
        <a href="https://doi.org/10.1101/2022.10.12.511740">
            <img class="preview" src="https://www.biorxiv.org/sites/default/files/images/biorxiv_logo_homepage7-5-small.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://doi.org/10.1101/2022.10.12.511740</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Carly Batist, Dan Morris, Sara Beery, Aleksis Pirinen, Valentin Gabeff
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Alexandre Lacoste
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-17 12:46:48">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-10-17 12:46:48"><div class="time">2022-10-17 12:46:48</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Looking at this now, can you make the abstract clearer about the performance gain versus supervised learning
<code>respectively, and an area under the Precision-Recall curve (PR-AUC) of 0.917, while a threshold detector based on signal energy amplitude returns a maximal R-value and F1-score of 0.620 and 0.576, respectively, and a PR-AUC of 0.571</code>
I think the 'threshold detector' is supervised? or is that unsupervised? Only read the abstract.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-17 12:51:23">
            
                <img src="https://avatars.slack-edge.com/2022-10-11/4203870994483_c201360f475a1bd6a180_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Titus
                     <span class="print-only user-email">(titus@colossal.com)</span>
                </div>
                <a href="#2022-10-17 12:51:23"><div class="time">2022-10-17 12:51:23</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Good feedback. Thanks @Ben Weinstein</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-17 12:55:27">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-10-17 12:55:27"><div class="time">2022-10-17 12:55:27</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I just skimmed the paper, I think this kind of work is really important and provides massive potential benefits over the very old and outdated stuff I published a few years ago <a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13011">https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13011</a>. Couple thoughts on very first glance. Can you provide a concrete comparison to supervised data? Basically how many sperm whale calls would you need to annotate to get a similar performance? It's great that unsupervised works at all, which is welcome news, just wondering about its efficiency versus supervised. Second thought, is how universal do you think those feature backbones are? Imagine we collected petabytes of biodiversity video data and wanted to make a general animal detector. Could a single backbone be used, or do you think the contrastive approach is not generalizable? We have similar goals in mining background features for airborne object detection and hundreds of TB of imagery from National Ecological Observatory Network. @Alexandre Lacoste</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Alexandre Lacoste
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-17 13:00:06">
            
                <img src="https://avatars.slack-edge.com/2022-10-11/4203870994483_c201360f475a1bd6a180_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Titus
                     <span class="print-only user-email">(titus@colossal.com)</span>
                </div>
                <a href="#2022-10-17 13:00:06"><div class="time">2022-10-17 13:00:06</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Ben Weinstein to your second question, we think they will be quite generalizable, which is why we show preliminary data in different modalities. A full characterization of generalizability was outside the scope of this one paper, but we found that any discontinuity is possible to generalize to. Of course we'd need to do the experiments, but would love to know if you are applying it in your modality, or are interested in chatting about how it would apply.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-17 13:00:24">
            
                <img src="https://avatars.slack-edge.com/2022-10-11/4203870994483_c201360f475a1bd6a180_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Titus
                     <span class="print-only user-email">(titus@colossal.com)</span>
                </div>
                <a href="#2022-10-17 13:00:24"><div class="time">2022-10-17 13:00:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* To your first point, again great feedback and I'll take it back to my team.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2022-10-16 08:12:27">
            
                <img src="https://avatars.slack-edge.com/2022-10-07/4188522499061_9015173e49078525c163_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Leah Brickson
                     <span class="print-only user-email">(leah36@gmail.com)</span>
                </div>
                <a href="#2022-10-16 08:12:27"><div class="time">2022-10-16 08:12:27</div></a>
                <div class="msg">
                    <p>@Leah Brickson has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2022-10-17 12:55:30">
            
                <img src="https://avatars.slack-edge.com/2022-04-11/3387579467969_15507dbc04c86e3c5f03_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Alexandre Lacoste
                     <span class="print-only user-email">(alex.lacoste.shmu@gmail.com)</span>
                </div>
                <a href="#2022-10-17 12:55:30"><div class="time">2022-10-17 12:55:30</div></a>
                <div class="msg">
                    <p>@Alexandre Lacoste has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-18 09:37:26">
            
                <img src="https://avatars.slack-edge.com/2022-11-07/4325264017430_1d69dc73e8586441b2af_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Omiros Pantazis
                     <span class="print-only user-email">(omiros.pantazis.16@ucl.ac.uk)</span>
                </div>
                <a href="#2022-10-18 09:37:26"><div class="time">2022-10-18 09:37:26</div></a>
                <div class="msg">
                    <p>Hey everyone, here is a pointer to our recent work on self-supervised learning for adaptation of large vision-language models (CLIP) to challenging real-world tasks (to be presented in BMVC 2022) <a href="https://arxiv.org/abs/2210.03794">https://arxiv.org/abs/2210.03794</a>.
It's not strictly a biodiversity/conservation piece of work but we show the effectiveness of the suggested approach across 4 diverse <b>#camera_traps</b> datasets so can be relevant to some.
Twitter thread: <a href="https://twitter.com/panom1/status/1582320238640496640?s=20&amp;t=rQq89XKk8HJUFx6NulF5jw">https://twitter.com/panom1/status/1582320238640496640?s=20&amp;t=rQq89XKk8HJUFx6NulF5jw</a></p>

<p>Looking forward to any kind of feedback üôÇ</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2210.03794">SVL-Adapter: Self-Supervised Adapter for Vision-Language Pretrained Models</a></div>
                                <div class="link-text">
                                    Vision-language models such as CLIP are pretrained on large volumes of internet sourced image and text pairs, and have been shown to sometimes exhibit impressive zero- and low-shot image...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2210.03794">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2210.03794</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëè Titus, Oisin Mac Aodha, Justin Kay, Sara Beery, Dan Morris, Andrew Schulz
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-18 10:48:08">
            
                <img src="https://avatars.slack-edge.com/2023-07-17/5589806448180_29de367a7904a3aeef8c_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Andrew Schulz
                     <span class="print-only user-email">(akschulz@gatech.edu)</span>
                </div>
                <a href="#2022-10-18 10:48:08"><div class="time">2022-10-18 10:48:08</div></a>
                <div class="msg">
                    <p>so regarding the <b>#new_papers</b> channel history - I have a Zotero Group Library for AI4Conservation Items - would people want me to work on ways to share it with the community?</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç:skin_tone_5: Ando Shah
                        </div>
                    
                        <div class="message-reaction">
                        üëç Eddie Zhang, Pascal Hirsch, Carl Boettiger
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-18 10:50:45">
            
                <img src="https://avatars.slack-edge.com/2022-10-11/4203870994483_c201360f475a1bd6a180_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Titus
                     <span class="print-only user-email">(titus@colossal.com)</span>
                </div>
                <a href="#2022-10-18 10:50:45"><div class="time">2022-10-18 10:50:45</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I would.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-18 13:07:58">
            
                <img src="https://avatars.slack-edge.com/2022-06-16/3678647045572_c26c1e2893f13bc3ad2f_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ando Shah
                     <span class="print-only user-email">(ando@berkeley.edu)</span>
                </div>
                <a href="#2022-10-18 13:07:58"><div class="time">2022-10-18 13:07:58</div></a>
                <div class="msg">
                    <p>Big shoutout to @Sara Beery for this wonderful paper - <a href="https://arxiv.org/abs/2107.10400">Species Distribution Modeling for Machine Learning Practitioners: A Review</a>. As a computer scientist newly working on species distribution modeling (SDM), this was such a helpful review of topics and it elegantly framed some the challenges in this field like ‚Äúwhat the heck is ground truth here?‚Äú, etc. Not a new paper, but highly recommended reading for those new to SDMs ü•≥</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2107.10400">Species Distribution Modeling for Machine Learning Practitioners: A Review</a></div>
                                <div class="link-text">
                                    Conservation science depends on an accurate understanding of what&#39;s happening in a given ecosystem. How many species live there? What is the makeup of the population? How is that changing over...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2107.10400">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2107.10400</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery, Michael Procko, Nina van Tiel, Frederic, Toryn Schafer, Suzanne Stathatos, Viktor Domazetoski, Carly Batist, Lauren Gillespie, Mitch Fennell, Eddie Zhang, Robin Zbinden, Pen-Yuan Hsing, Yseult Hb, Elijah Cole, Sachith Seneviratne, Carl Boettiger
                        </div>
                    
                        <div class="message-reaction">
                        üëë Suzanne Stathatos
                        </div>
                    
                        <div class="message-reaction">
                        üêõ Kalindi Fonda
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-18 13:08:55">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2022-10-18 13:08:55"><div class="time">2022-10-18 13:08:55</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Shout out to @Elijah Cole as well!! This was very much a joint effort</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëè:skin_tone_5: Ando Shah
                        </div>
                    
                        <div class="message-reaction">
                        üëè:skin_tone_3: Pen-Yuan Hsing
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-20 09:56:14">
            
                <img src="https://avatars.slack-edge.com/2022-10-20/4236948455079_1074b1375f1a05290bed_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Brad Pickens
                     <span class="print-only user-email">(bradley_pickens@fws.gov)</span>
                </div>
                <a href="#2022-10-20 09:56:14"><div class="time">2022-10-20 09:56:14</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Nice paper, Sara! SDM's also have a history of tackling issues directly relevant to deep learning, such as problems with the random split <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/geb.12684">https://onlinelibrary.wiley.com/doi/abs/10.1111/geb.12684</a>  ; I'm going in the opposite direction...moving from SDM to deep learning, but always happy to discuss SDMs.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëÄ Carl Boettiger
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-20 10:01:47">
            
                <img src="https://avatars.slack-edge.com/2022-10-20/4236948455079_1074b1375f1a05290bed_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Brad Pickens
                     <span class="print-only user-email">(bradley_pickens@fws.gov)</span>
                </div>
                <a href="#2022-10-20 10:01:47"><div class="time">2022-10-20 10:01:47</div></a>
                <div class="msg">
                    <p>On the counting of migratory Sandhill Cranes with thermal imagery and deep learning: huge thanks to William and Mary and @Emilio Luz-Ricca for this research regarding a globally important stopover area for this species  <a href="https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1002/rse2.301">https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1002/rse2.301</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Titus, Dan Morris, Mitch Fennell
                        </div>
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Emilio Luz-Ricca, Rowan Converse
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-20 11:38:25">
            
                <img src="https://avatars.slack-edge.com/2022-01-24/2986533557719_58ca8e83aa6247d0cc67_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Elijah Cole
                     <span class="print-only user-email">(ecole@caltech.edu)</span>
                </div>
                <a href="#2022-10-20 11:38:25"><div class="time">2022-10-20 11:38:25</div></a>
                <div class="msg">
                    <p>This is a somewhat random tidbit, but might be useful to people here!</p>

<p><a href="https://twitter.com/eli_cole_/status/1583119979804704768">https://twitter.com/eli_cole_/status/1583119979804704768</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">twitter</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="https://pbs.twimg.com/profile_images/1485787518536617986/1o83C_Yw_normal.jpg" class="icon">
                                    }
                                    <a href="https://twitter.com/eli_cole_/status/1583119979804704768">
                                    Elijah Cole
                                    </a><span class="print-only">(https://twitter.com/eli_cole_/status/1583119979804704768)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href=""></a></div>
                                <div class="link-text">
                                    A little bonus from our &lt;b&gt;#ECCV2022&lt;/b&gt; paper: a mapping between the CUB classes and the &lt;a href=&#34;https://twitter.com/inaturalist&#34;&gt;@inaturalist&lt;/a&gt; taxonomy! 

CUB &amp;lt;-&amp;gt; iNat mapping: &lt;https://github.com/visipedia/inat_loc/tree/main/class_mappings&gt;

Paper: &lt;https://arxiv.org/abs/2207.10225&gt;
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://twitter.com/eli_cole_/status/1583119979804704768</div>
                                
                                
                                    <div class="attachment-footer">
                                        <img src="https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png" class="icon" />
                                        Twitter
                                    </div>
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Suzanne Stathatos, Cameron Trotter, Oisin Mac Aodha, Omiros Pantazis, Emilio Luz-Ricca
                        </div>
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-20 12:31:44">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-10-20 12:31:44"><div class="time">2022-10-20 12:31:44</div></a>
                <div class="msg">
                    <p><a href="https://ieeexplore.ieee.org/abstract/document/9918242">https://ieeexplore.ieee.org/abstract/document/9918242</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">ieeexplore.ieee.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://ieeexplore.ieee.org/abstract/document/9918242">Deep Learning for Marine Bioacoustics and Fish Classification Using Underwater Sounds</a></div>
                                <div class="link-text">
                                    The migration of species is an important factor in the analysis of ecological systems. Changes in migratory patterns of a species or a specific group in an ecosystem often follow changes in the environment - many animals are sensitive to small changes that may not initially be thought of as significant for the health of an ecosystem. The presence of many species can be detected by the sounds they produce, and as such, environmental conservation efforts have much to gain from the automation of the analysis of Bioacoustics. Deep Learning shows promise for this type of task. This work evaluates the performance of different deep learning methods when performing the task of detecting the presence of brown meagre sounds in spectrograms with different window lengths and achieves an F1-score of 0.94 for brown meagre vocalization detection.
                                </div>
                                
                                
    
        <a href="https://ieeexplore.ieee.org/abstract/document/9918242">
            <img class="preview" src="https://ieeexplore.ieee.org/assets/img/ieee_logo_smedia_200X200.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://ieeexplore.ieee.org/abstract/document/9918242</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Justin Kay, Suzanne Stathatos, Yseult Hb, Emilio Luz-Ricca
                        </div>
                    
                        <div class="message-reaction">
                        üëç:skin_tone_5: Ando Shah
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-24 13:06:29">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-10-24 13:06:29"><div class="time">2022-10-24 13:06:29</div></a>
                <div class="msg">
                    <p><a href="https://onlinelibrary.wiley.com/doi/10.1111/ele.14123">https://onlinelibrary.wiley.com/doi/10.1111/ele.14123</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëç Rowan Converse, Mitch Fennell
                        </div>
                    
                        <div class="message-reaction">
                        üôå John Martinsson, Emilio Luz-Ricca
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-25 06:07:15">
            
                <img src="https://avatars.slack-edge.com/2022-01-24/2986533557719_58ca8e83aa6247d0cc67_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Elijah Cole
                     <span class="print-only user-email">(ecole@caltech.edu)</span>
                </div>
                <a href="#2022-10-25 06:07:15"><div class="time">2022-10-25 06:07:15</div></a>
                <div class="msg">
                    <p>Today at ECCV we‚Äôre presenting our paper on using label hierarchies to improve object localization. We also released a new iNat dataset with manually verified bounding boxes. Drop by if you‚Äôre at the conference! üôÇ</p>

<p><a href="https://twitter.com/eli_cole_/status/1584846750787174400">https://twitter.com/eli_cole_/status/1584846750787174400</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">twitter</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="https://pbs.twimg.com/profile_images/1485787518536617986/1o83C_Yw_normal.jpg" class="icon">
                                    }
                                    <a href="https://twitter.com/eli_cole_/status/1584846750787174400">
                                    Elijah Cole
                                    </a><span class="print-only">(https://twitter.com/eli_cole_/status/1584846750787174400)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href=""></a></div>
                                <div class="link-text">
                                    Today (10/25) we&#39;re presenting &#34;On Label Granularity and Object Localization&#34; at &lt;b&gt;#ECCV2022&lt;/b&gt; poster #32 from 3:30pm_5:30pm! Drop by and say hi!

We use label hierarchies to get better object localization with fewer labels - full details here: &lt;https://sites.google.com/view/label-granularity-localization/home&gt;
                                </div>
                                
                                
    
        <a href="https://twitter.com/eli_cole_/status/1584846750787174400">
            <img class="preview" src="https://pbs.twimg.com/media/Ff6AMNMWAAAh4ny.jpg"
                width="1200"
                 height="548" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://twitter.com/eli_cole_/status/1584846750787174400</div>
                                
                                
                                    <div class="attachment-footer">
                                        <img src="https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png" class="icon" />
                                        Twitter
                                    </div>
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        :squirrel: Andrew Schulz, Justin Kay
                        </div>
                    
                        <div class="message-reaction">
                        ü§© Yves Bas, Lukas Picek, Lily Xu
                        </div>
                    
                        <div class="message-reaction">
                        üôå Omiros Pantazis, Subhransu Maji, Emily Lines, Robin Zbinden, Caleb Robinson, Casey Youngflesh, Ben Weinstein, Ethan Shafron, Dan Morris, Rowan Converse, Aleksis Pirinen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-25 16:14:31">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-10-25 16:14:31"><div class="time">2022-10-25 16:14:31</div></a>
                <div class="msg">
                    <p><a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14003">https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14003</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üê¶ Oisin Mac Aodha, Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëç Yves Bas, Leonardo Viotti
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-26 09:02:44">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-10-26 09:02:44"><div class="time">2022-10-26 09:02:44</div></a>
                <div class="msg">
                    <p><a href="https://arxiv.org/abs/2210.12300">https://arxiv.org/abs/2210.12300</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2210.12300">BEANS: The Benchmark of Animal Sounds</a></div>
                                <div class="link-text">
                                    The use of machine learning (ML) based techniques has become increasingly popular in the field of bioacoustics over the last years. Fundamental requirements for the successful application of ML...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2210.12300">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2210.12300</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ Carl Boettiger, Masato Hagiwara, Aleksis Pirinen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-26 11:15:10">
            
                <img src="https://avatars.slack-edge.com/2022-10-11/4203870994483_c201360f475a1bd6a180_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Titus
                     <span class="print-only user-email">(titus@colossal.com)</span>
                </div>
                <a href="#2022-10-26 11:15:10"><div class="time">2022-10-26 11:15:10</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* This is great! We will start using it</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-27 01:02:30">
            
                <img src="https://secure.gravatar.com/avatar/1f4c833e8cd844b19615f8e6f5a51303.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Masato Hagiwara
                     <span class="print-only user-email">(hagisan@gmail.com)</span>
                </div>
                <a href="#2022-10-27 01:02:30"><div class="time">2022-10-27 01:02:30</div></a>
                <div class="msg">
                    <p>I‚Äôm excited to introduce AVES, aka ‚ÄúBERT for animals‚Äù, a self-supervised audio encoder model which beats strong baselines including VGGish etc. across the board in bioacoustics tasks. <a href="https://twitter.com/mhagiwara/status/1585496748298219520">https://twitter.com/mhagiwara/status/1585496748298219520</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">twitter</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="https://pbs.twimg.com/profile_images/1140801068797968391/Y99Kl_BU_normal.png" class="icon">
                                    }
                                    <a href="https://twitter.com/mhagiwara/status/1585496748298219520">
                                    Masato Hagiwara
                                    </a><span class="print-only">(https://twitter.com/mhagiwara/status/1585496748298219520)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href=""></a></div>
                                <div class="link-text">
                                    Excited to announce AVES ‚Äî aka &#34;BERT for animals&#34; ‚Äî a self-supervised audio encoder model which beats strong baselines including VGGish etc. across the board in bioacoustics tasks. 

We also open sourced the model weights. Check out the paper and the repo below üëá &lt;https://twitter.com/earthspecies/status/1585480058596007936&gt;
                                </div>
                                
                                
    
        <a href="https://twitter.com/mhagiwara/status/1585496748298219520">
            <img class="preview" src="https://pbs.twimg.com/media/FgDQV8SaAAIZfBe.jpg"
                width="1200"
                 height="297" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://twitter.com/mhagiwara/status/1585496748298219520</div>
                                
                                
                                    <div class="attachment-footer">
                                        <img src="https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png" class="icon" />
                                        Twitter
                                    </div>
                                
                            
                        </div>
                    <div class="message-attachment"
                            style="border-color: #32BBF3">
                            <div class="service-name">twitter</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="https://pbs.twimg.com/profile_images/1235357843710070784/bvqgUJ_U_normal.jpg" class="icon">
                                    }
                                    <a href="https://twitter.com/earthspecies/status/1585480058596007936">
                                    Earth Species Project
                                    </a><span class="print-only">(https://twitter.com/earthspecies/status/1585480058596007936)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href=""></a></div>
                                <div class="link-text">
                                    Announcing AVES, a self-supervised audio representation model for encoding animal vocalizations, aka &#34;BERT for animals,&#34; led by ESP Senior AI Research Scientist &lt;a href=&#34;https://twitter.com/mhagiwara&#34;&gt;@mhagiwara&lt;/a&gt;. AVES outperforms all the baselines. 

* Paper: &lt;https://arxiv.org/abs/2210.14493&gt; 
* Repo: &lt;https://github.com/earthspecies/aves&gt;
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                                    <div class="attachment-footer">
                                        <img src="https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png" class="icon" />
                                        Twitter
                                    </div>
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëè Lucia Gordon, Sara Beery, Yves Bas, Devis Tuia, Carly Batist, Francisco Carrillo P√©rez, Ben Weinstein, Sachith Seneviratne
                        </div>
                    
                        <div class="message-reaction">
                        ü§© Sara Beery, Francisco Carrillo P√©rez, Yseult Hb, Toryn Schafer
                        </div>
                    
                        <div class="message-reaction">
                        üëè:skin_tone_5: Ando Shah
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-31 12:40:09">
            
                <img src="https://avatars.slack-edge.com/2022-07-05/3753846318550_088497c75b874351ff25_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Valentin Lucet
                     <span class="print-only user-email">(valentin.lucet@gmail.com)</span>
                </div>
                <a href="#2022-10-31 12:40:09"><div class="time">2022-10-31 12:40:09</div></a>
                <div class="msg">
                    <p><a href="https://www.sciencedirect.com/science/article/pii/S1574954122003260">https://www.sciencedirect.com/science/article/pii/S1574954122003260</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.sciencedirect.com/science/article/pii/S1574954122003260">Human vs. machine: Detecting wildlife in camera trap images</a></div>
                                <div class="link-text">
                                    As the capacity to collect and store large amounts of data expands, identifying and evaluating strategies to efficiently convert raw data into meaning‚Ä¶
                                </div>
                                
                                
    
        <a href="https://www.sciencedirect.com/science/article/pii/S1574954122003260">
            <img class="preview" src="https://ars.els-cdn.com/content/image/1-s2.0-S1574954122X00046-cov150h.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.sciencedirect.com/science/article/pii/S1574954122003260</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Hannah Murray, Oisin Mac Aodha, Sara Beery, Carly Batist, Dan Morris, Emilio Luz-Ricca
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-10-31 13:26:04">
            
                <img src="https://avatars.slack-edge.com/2022-09-17/4096548327171_f782c98b7749ccd16df6_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Adam Noach
                     <span class="print-only user-email">(amn55@cam.ac.uk)</span>
                </div>
                <a href="#2022-10-31 13:26:04"><div class="time">2022-10-31 13:26:04</div></a>
                <div class="msg">
                    <p><a href="https://www.sciencedirect.com/science/article/pii/S1569843222002473">https://www.sciencedirect.com/science/article/pii/S1569843222002473</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.sciencedirect.com/science/article/pii/S1569843222002473">Fine-resolution landscape-scale biomass mapping using a spatiotemporal patchwork of LiDAR coverages</a></div>
                                <div class="link-text">
                                    Estimating forest aboveground biomass (AGB) at large scales and fine spatial resolutions has become increasingly important for greenhouse gas accounti‚Ä¶
                                </div>
                                
                                
    
        <a href="https://www.sciencedirect.com/science/article/pii/S1569843222002473">
            <img class="preview" src="https://ars.els-cdn.com/content/image/1-s2.0-S1569843222X0006X-cov150h.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.sciencedirect.com/science/article/pii/S1569843222002473</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Emilio Luz-Ricca, Ariane Roberge
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-11-01 11:43:54">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-11-01 11:43:54"><div class="time">2022-11-01 11:43:54</div></a>
                <div class="msg">
                    <p><a href="https://www.mdpi.com/2313-433X/8/4/96">https://www.mdpi.com/2313-433X/8/4/96</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">MDPI</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.mdpi.com/2313-433X/8/4/96">Convolutional Neural Networks for the Identification of African Lions from Individual Vocalizations</a></div>
                                <div class="link-text">
                                    The classification of vocal individuality for passive acoustic monitoring (PAM) and census of animals is becoming an increasingly popular area of research. Nearly all studies in this field of inquiry have relied on classic audio representations and classifiers, such as Support Vector Machines (SVMs) trained on spectrograms or Mel-Frequency Cepstral Coefficients (MFCCs). In contrast, most current bioacoustic species classification exploits the power of deep learners and more cutting-edge audio representations. A significant reason for avoiding deep learning in vocal identity classification is the tiny sample size in the collections of labeled individual vocalizations. As is well known, deep learners require large datasets to avoid overfitting. One way to handle small datasets with deep learning methods is to use transfer learning. In this work, we evaluate the performance of three pretrained CNNs (VGG16, ResNet50, and AlexNet) on a small, publicly available lion roar dataset containing approximately 150 samples taken from five male lions. Each of these networks is retrained on eight representations of the samples: MFCCs, spectrogram, and Mel spectrogram, along with several new ones, such as VGGish and stockwell, and those based on the recently proposed LM spectrogram. The performance of these networks, both individually and in ensembles, is analyzed and corroborated using the Equal Error Rate and shown to surpass previous classification attempts on this dataset; the best single network achieved over 95% accuracy and the best ensembles over 98% accuracy. The contributions this study makes to the field of individual vocal classification include demonstrating that it is valuable and possible, with caution, to use transfer learning with single pretrained CNNs on the small datasets available for this problem domain. We also make a contribution to bioacoustics generally by offering a comparison of the performance of many state-of-the-art audio representations, including for the first time the LM spectrogram and stockwell representations. All source code for this study is available on GitHub.
                                </div>
                                
                                
    
        <a href="https://www.mdpi.com/2313-433X/8/4/96">
            <img class="preview" src="https://www.mdpi.com/img/journals/jimaging-logo-social.png?8600e93ff98dbf14"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.mdpi.com/2313-433X/8/4/96</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-11-01 13:31:17">
            
                <img src="https://secure.gravatar.com/avatar/fad8243912668a0add63704d16e4c44f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Subhransu Maji
                     <span class="print-only user-email">(smaji@cs.umass.edu)</span>
                </div>
                <a href="#2022-11-01 13:31:17"><div class="time">2022-11-01 13:31:17</div></a>
                <div class="msg">
                    <p><a href="https://www.biorxiv.org/content/10.1101/2022.10.28.513761v1">https://www.biorxiv.org/content/10.1101/2022.10.28.513761v1</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">bioRxiv</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.biorxiv.org/content/10.1101/2022.10.28.513761v1">Using spatio-temporal information in weather radar data to detect and track communal bird roosts</a></div>
                                <div class="link-text">
                                    The exodus of swallows from communal nighttime roosts is often visible as an expanding ring-shaped pattern in weather radar data. The WSR-88D network operated by the NationalWeather Service archives more than 25 years of data across 143 stations in the contiguous US. However, access to information about the roosting behavior of swallows is limited by the cost of manual annotation of these scans. We develop an AI system to detect and track swallow roosts in weather radar data. Our model is based on the Faster R-CNN architecture and is customized to incorporate multiple spatial and temporal channels in volumetric radar scans using novel adaptor layers. We systematically study the impact of network architecture and input representation for this task. We incorporate our detection outputs into an AI-assisted system with an interface for human screening to collect research-grade data about roosting behavior. We deploy the system to collect information from 12 radar stations in the Great Lakes region of the US spanning 21 years. The addition of temporal information improves roost detection performance from 47.0% mean average precision to 54.7%. Temporal information helps the model recognize the expanding pattern of roosts and filter false positives due to rain and static structures. Our system allowed the annotation of 15,628 roost signatures with 64,620 single-frame detections in 612,786 radar scans with 183.6 total hours of human screening, or 1.08 seconds per radar scan. Our AI-assisted system provides research-quality roost data with far less human effort than manual annotation of radar scans. The data contains critical information about the phenology and population trends of swallows and martins, a declining group of aerial insectivores. Our successful deployment to collect historical data for 8% of the radar stations in the contiguous US lays the groundwork for continent-scale analysis of swallow roosts, and provides a starting point for analysis of other family-specific phenomena in weather radar, such as bat roosts and mayfly hatches. ### Competing Interest Statement The authors have declared no competing interest.
                                </div>
                                
                                
    
        <a href="https://www.biorxiv.org/content/10.1101/2022.10.28.513761v1">
            <img class="preview" src="https://www.biorxiv.org/sites/default/files/images/biorxiv_logo_homepage7-5-small.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.biorxiv.org/content/10.1101/2022.10.28.513761v1</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Carly Batist
                        </div>
                    
                        <div class="message-reaction">
                        üê¶ Oisin Mac Aodha, Elijah Cole
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-11-03 17:55:16">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-11-03 17:55:16"><div class="time">2022-11-03 17:55:16</div></a>
                <div class="msg">
                    <p>Virtual scene learning for tree detection. <a href="https://arxiv.org/pdf/2210.17424.pdf">https://arxiv.org/pdf/2210.17424.pdf</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-11-03 17:55:32">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-11-03 17:55:32"><div class="time">2022-11-03 17:55:32</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris some data here for LILA</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-11-03 18:57:15">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2022-11-03 18:57:15"><div class="time">2022-11-03 18:57:15</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Very cool!  Looks like the dataset is here:</p>

<p><a href="https://github.com/norlab-ulaval/PercepTreeV1">https://github.com/norlab-ulaval/PercepTreeV1</a></p>

<p>I'll add a link on the LILA "other data sets" page.</p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">norlab-ulaval/PercepTreeV1</a></div>
                                <div class="link-text">
                                    Tree detection in forests based on deep learning.
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        8
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        Python
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-11-07 14:36:13">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2022-11-07 14:36:13"><div class="time">2022-11-07 14:36:13</div></a>
                <div class="msg">
                    <p>@Zhongqi Miao <a href="https://www.sciencedirect.com/science/article/pii/S1574954122003260">https://www.sciencedirect.com/science/article/pii/S1574954122003260</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.sciencedirect.com/science/article/pii/S1574954122003260">Human vs. machine: Detecting wildlife in camera trap images</a></div>
                                <div class="link-text">
                                    As the capacity to collect and store large amounts of data expands, identifying and evaluating strategies to efficiently convert raw data into meaning‚Ä¶
                                </div>
                                
                                
    
        <a href="https://www.sciencedirect.com/science/article/pii/S1574954122003260">
            <img class="preview" src="https://ars.els-cdn.com/content/image/1-s2.0-S1574954122X00046-cov150h.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.sciencedirect.com/science/article/pii/S1574954122003260</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Zhongqi Miao, Rowan Converse, Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üôå Mitch Fennell, Dan Morris, Yseult Hb, Sicily Fiennes, Yves Bas
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-11-09 10:02:25">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2022-11-09 10:02:25"><div class="time">2022-11-09 10:02:25</div></a>
                <div class="msg">
                    <p><a href="https://www.sciencedirect.com/science/article/pii/S1470160X22010949">https://www.sciencedirect.com/science/article/pii/S1470160X22010949</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.sciencedirect.com/science/article/pii/S1470160X22010949">Classification of animal sounds in a hyperdiverse rainforest using convolutional neural networks with data augmentation</a></div>
                                <div class="link-text">
                                    To protect tropical forest biodiversity, we need to be able to detect it reliably, cheaply, and at scale. Automated detection of sound producing anima‚Ä¶
                                </div>
                                
                                
    
        <a href="https://www.sciencedirect.com/science/article/pii/S1470160X22010949">
            <img class="preview" src="https://ars.els-cdn.com/content/image/1-s2.0-S1470160X22X00083-cov150h.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.sciencedirect.com/science/article/pii/S1470160X22010949</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëè Titus, Tiziana Gelmi Candusso, Yseult Hb
                        </div>
                    
                        <div class="message-reaction">
                        üëç Rowan Converse, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-12-08 08:05:07">
            
                <img src="https://avatars.slack-edge.com/2021-08-11/2375300351412_c166518db961a417096e_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Cameron Trotter
                     <span class="print-only user-email">(cater@bas.ac.uk)</span>
                </div>
                <a href="#2022-12-08 08:05:07"><div class="time">2022-12-08 08:05:07</div></a>
                <div class="msg">
                    <p>üåäüê¨ üö§ üì∑‚û°Ô∏è üñ•Ô∏è üîç</p>

<p>Excited to present our recent work, <a href="https://arxiv.org/abs/2212.03646">Towards Automatic Cetacean Photo-Identification: A Framework for Fine-Grain, Few-Shot Learning in Marine Ecology</a>, which highlights a system for automated individual cetacean photo-id through the use of a pipeline of computer vision models and post-processing methodologies. The work will be presented later this month at the IEEE Big Data 2022 Conference in Osaka, Japan though the pre-print is now available on arXiv</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2212.03646">Towards Automatic Cetacean Photo-Identification: A Framework for...</a></div>
                                <div class="link-text">
                                    Photo-identification (photo-id) is one of the main non-invasive
capture-recapture methods utilised by marine researchers for monitoring
cetacean (dolphin, whale, and porpoise) populations. This...
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2212.03646">
            <img class="preview" src="https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2212.03646</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëè Georgia Atkinson, Kirsten Crane, Tiziana Gelmi Candusso, Emily Lines, Sara Beery, Oisin Mac Aodha, Rita Pucci
                        </div>
                    
                        <div class="message-reaction">
                        üê¨ Georgia Atkinson, Kirsten Crane, Dan Morris, Rowan Converse, Toryn Schafer, Emilio Luz-Ricca
                        </div>
                    
                        <div class="message-reaction">
                        üëè:skin_tone_2: Manish Rai
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2022-12-20 12:42:43">
            
                <img src="https://secure.gravatar.com/avatar/4391c54952e1c48b6e9f3077946818bc.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0006-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Oisin Mac Aodha
                     <span class="print-only user-email">(macaodha@caltech.edu)</span>
                </div>
                <a href="#2022-12-20 12:42:43"><div class="time">2022-12-20 12:42:43</div></a>
                <div class="msg">
                    <p>Hi all. We have just uploaded a pre-print discussing our new deep-learning based method for bat echolocation call detection and species classification. Feel free to drop me a message if you have any thoughts/questions.
ü¶áüîäüíª</p>

<p><a href="https://www.biorxiv.org/content/10.1101/2022.12.14.520490v1">https://www.biorxiv.org/content/10.1101/2022.12.14.520490v1</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëè Georgia Atkinson, Justin Kay, Subhransu Maji, Elijah Cole, Mikey Tabak, Lukas Picek, Dan Morris, Timm Haucke, Cameron Trotter, Omiros Pantazis, Tiziana Gelmi Candusso, Anton Alvarez, Ben Williams, Ritwik
                        </div>
                    
                        <div class="message-reaction">
                        üôå Mark Fisher
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-01-09 18:31:13">
            
                <img src="https://secure.gravatar.com/avatar/29bb5bfa2f4fc413cf2e1adfb3a5ebb9.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0015-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Majid Mirmehdi
                     <span class="print-only user-email">(m.mirmehdi@bristol.ac.uk)</span>
                </div>
                <a href="#2023-01-09 18:31:13"><div class="time">2023-01-09 18:31:13</div></a>
                <div class="msg">
                    <p>Hi All,
Preprint on learning Great Ape behavioural actions using camera-trap footage with @Otto Brookes, @Tilo Burghardt and Hjalmar Kuhl:
<a href="https://deepai.org/publication/triple-stream-deep-metric-learning-of-great-ape-behavioural-actions">https://deepai.org/publication/triple-stream-deep-metric-learning-of-great-ape-behavioural-actions</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">DeepAI</div>
                            
                            
                                
                                <div class="link-title"><a href="https://deepai.org/publication/triple-stream-deep-metric-learning-of-great-ape-behavioural-actions">Triple-stream Deep Metric Learning of Great Ape Behavioural Actions</a></div>
                                <div class="link-text">
                                    01/06/23 - We propose the first metric learning system for the recognition of great ape
behavioural actions. Our proposed triple stream embed...
                                </div>
                                
                                
    
        <a href="https://deepai.org/publication/triple-stream-deep-metric-learning-of-great-ape-behavioural-actions">
            <img class="preview" src="https://images.deepai.org/publication-preview/triple-stream-deep-metric-learning-of-great-ape-behavioural-actions-page-2-medium.jpg"
                width="177"
                 height="250" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://deepai.org/publication/triple-stream-deep-metric-learning-of-great-ape-behavioural-actions</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëè Timm Haucke, Ed Miller, Yseult Hb, Cameron Trotter, Oisin Mac Aodha, Mikey Tabak, Emilio Luz-Ricca
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-01-26 18:44:49">
            
                <img src="https://secure.gravatar.com/avatar/29bb5bfa2f4fc413cf2e1adfb3a5ebb9.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0015-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Majid Mirmehdi
                     <span class="print-only user-email">(m.mirmehdi@bristol.ac.uk)</span>
                </div>
                <a href="#2023-01-26 18:44:49"><div class="time">2023-01-26 18:44:49</div></a>
                <div class="msg">
                    <p>Open Access to:</p>

<p>Dynamic Curriculum Learning for Great Ape Detection in the Wild,
Yang, X., Burghardt, T. &amp; Mirmehdi, M.
<em>International Journal of Computer Vision</em> (2023).
<a href="https://link.springer.com/article/10.1007/s11263-023-01748-3">https://link.springer.com/article/10.1007/s11263-023-01748-3</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">SpringerLink</div>
                            
                            
                                
                                <div class="link-title"><a href="https://link.springer.com/article/10.1007/s11263-023-01748-3">Dynamic Curriculum Learning for Great Ape Detection in the Wild</a></div>
                                <div class="link-text">
                                    International Journal of Computer Vision - We propose a novel end-to-end curriculum learning approach for sparsely labelled animal datasets leveraging large volumes of unlabelled data to improve...
                                </div>
                                
                                
    
        <a href="https://link.springer.com/article/10.1007/s11263-023-01748-3">
            <img class="preview" src="https://media.springernature.com/w200/springer-static/cover/journal/11263.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://link.springer.com/article/10.1007/s11263-023-01748-3</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Leonardo Viotti, Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëè Emilio Luz-Ricca
                        </div>
                    
                        <div class="message-reaction">
                        üôå Felipe Montealegre-Mora
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-04 20:09:58">
            
                <img src="https://avatars.slack-edge.com/2023-04-04/5075175490321_889000869582b1ab11ce_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Felipe Montealegre-Mora
                     <span class="print-only user-email">(felimomo@berkeley.edu)</span>
                </div>
                <a href="#2023-04-04 20:09:58"><div class="time">2023-04-04 20:09:58</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Hey Majid! A bit late to the show, but I've been reading this paper preparing to talk about it in a small group meeting. It's very cool!! I was wondering if I could steal maybe half an hour at some point to discuss about it shortly?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-03 10:17:29">
            
                <img src="https://secure.gravatar.com/avatar/88722d903090be6058838a3a5f8ebaf6.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Sheldon
                     <span class="print-only user-email">(sheldon@cs.umass.edu)</span>
                </div>
                <a href="#2023-02-03 10:17:29"><div class="time">2023-02-03 10:17:29</div></a>
                <div class="msg">
                    <p>Fuentes, M., Van Doren, B. M., Fink, D., &amp; Sheldon, D. (2023). BirdFlow: Learning seasonal bird movements from eBird data. <em>Methods in Ecology and Evolution</em>, 00, 1‚Äì 16. <a href="https://doi.org/10.1111/2041-210X.14052">https://doi.org/10.1111/2041-210X.14052</a></p>

<p><a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14052">https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14052</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üê¶ Oisin Mac Aodha, Sara Beery, Declan, Ben Weinstein, Dan Morris, Sankaran (shun-ka-run), Emilio Luz-Ricca, Mikey Tabak, Wenxin Yang, Lindsey Dukles
                        </div>
                    
                        <div class="message-reaction">
                        üëç Holger Klinck, Tiziana Gelmi Candusso
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-10 10:49:03">
            
                <img src="https://secure.gravatar.com/avatar/887e6a153d6b5eb1fb4e062f35dd26b0.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ritwik
                     <span class="print-only user-email">(rittyun@yahoo.com)</span>
                </div>
                <a href="#2023-02-10 10:49:03"><div class="time">2023-02-10 10:49:03</div></a>
                <div class="msg">
                    <p>hi all, introducing our recently published paper, where we tested a bunch or popular architectures on newly created data to differentiate images of captive mammals from wild ones, aimed at monitoring illegal wildlife trade. Some insights on specifically including negative features while training, and the importance of testing on out of distribution data.
<a href="https://www.sciencedirect.com/science/article/pii/S0006320723000241">https://www.sciencedirect.com/science/article/pii/S0006320723000241</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">sciencedirect.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.sciencedirect.com/science/article/pii/S0006320723000241">Towards automatic detection of wildlife trade using machine vision models</a></div>
                                <div class="link-text">
                                    Unsustainable trade in wildlife is one of the major threats affecting the global biodiversity crisis. An important part of the trade now occurs on dig‚Ä¶
                                </div>
                                
                                
    
        <a href="https://www.sciencedirect.com/science/article/pii/S0006320723000241">
            <img class="preview" src="https://ars.els-cdn.com/content/image/1-s2.0-S0006320722X00165-cov150h.gif"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.sciencedirect.com/science/article/pii/S0006320723000241</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëè Cameron Trotter, Georgia Atkinson, Viktor Domazetoski, Dan Morris, Suzanne Stathatos, Sara Beery, Emilio Luz-Ricca, aruna, Ian Ocholla
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-10 14:00:57">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-02-10 14:00:57"><div class="time">2023-02-10 14:00:57</div></a>
                <div class="msg">
                    <p>Has anyone else tried drones + bird microphone (@gvanhorn @Tessa Rhinehart @Dan Stowell)<a href="https://cdnsciencepub.com/doi/pdf/10.1139/dsa-2022-0015">https://cdnsciencepub.com/doi/pdf/10.1139/dsa-2022-0015</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container channel_join ">
        <div id="2023-02-10 14:01:00">
            
                <img src="https://secure.gravatar.com/avatar/170f4f5f03087b25cc411f7758518241.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Stowell
                     <span class="print-only user-email">(dan.stowell@naturalis.nl)</span>
                </div>
                <a href="#2023-02-10 14:01:00"><div class="time">2023-02-10 14:01:00</div></a>
                <div class="msg">
                    <p>@Dan Stowell has joined the channel</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-15 14:17:29">
            
                <img src="https://secure.gravatar.com/avatar/e96336d4ab1e44113cdeeb9c597c99ae.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Mikey Tabak
                     <span class="print-only user-email">(tabakma@gmail.com)</span>
                </div>
                <a href="#2023-02-15 14:17:29"><div class="time">2023-02-15 14:17:29</div></a>
                <div class="msg">
                    <p>Hi folks,
I get asked to review dozens of papers using machine learning for camera traps, or other wildlife-related studies, every year and I cannot do them all. If you are in this field and you are interested in (and qualified for) reviewing this type of paper, please let me know. I‚Äôd appreciate your name and contact details. Peer review is a great service to the scientific community and it can look really good on your CV.
Thanks,
Mikey</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-15 14:21:09">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2023-02-15 14:21:09"><div class="time">2023-02-15 14:21:09</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I would love this list as well, for the same reasons.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-15 14:34:33">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-02-15 14:34:33"><div class="time">2023-02-15 14:34:33</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* me too! I'm 3 or 4 requests a week.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-15 14:34:44">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-02-15 14:34:44"><div class="time">2023-02-15 14:34:44</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* (i think the answer is that everyone is)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-15 14:35:50">
            
                <img src="https://secure.gravatar.com/avatar/e96336d4ab1e44113cdeeb9c597c99ae.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mikey Tabak
                     <span class="print-only user-email">(tabakma@gmail.com)</span>
                </div>
                <a href="#2023-02-15 14:35:50"><div class="time">2023-02-15 14:35:50</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Beware: If you post your information here, you will get all of us passing reviews to you!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üòÖ Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-16 08:57:07">
            
                <img src="https://avatars.slack-edge.com/2023-07-17/5589806448180_29de367a7904a3aeef8c_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Andrew Schulz
                     <span class="print-only user-email">(akschulz@gatech.edu)</span>
                </div>
                <a href="#2023-02-16 08:57:07"><div class="time">2023-02-16 08:57:07</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* question @Mikey Tabak about this (a challenge I've faced with reviews), do they allow senior PhD students/early postdocs to be reviewers, and if so does the review have to be signed by their PI?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-16 09:10:34">
            
                <img src="https://secure.gravatar.com/avatar/e96336d4ab1e44113cdeeb9c597c99ae.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mikey Tabak
                     <span class="print-only user-email">(tabakma@gmail.com)</span>
                </div>
                <a href="#2023-02-16 09:10:34"><div class="time">2023-02-16 09:10:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Andrew, grad students are able to review papers. If you are unexperienced, it might be good to get some guidance from someone with more experience. It does not need to be signed by the PI, though. If you are concerned and want to involve your PI, it could be something to bring up with the editor when the contact you about reviewing</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-16 09:11:32">
            
                <img src="https://avatars.slack-edge.com/2023-07-17/5589806448180_29de367a7904a3aeef8c_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Andrew Schulz
                     <span class="print-only user-email">(akschulz@gatech.edu)</span>
                </div>
                <a href="#2023-02-16 09:11:32"><div class="time">2023-02-16 09:11:32</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* so I'm more of speaking from experience with where I commonly review - exp: Journal of Experimental Biology there is a ~soft requirement to be at least a postdoc to review.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-16 09:12:45">
            
                <img src="https://avatars.slack-edge.com/2023-07-17/5589806448180_29de367a7904a3aeef8c_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Andrew Schulz
                     <span class="print-only user-email">(akschulz@gatech.edu)</span>
                </div>
                <a href="#2023-02-16 09:12:45"><div class="time">2023-02-16 09:12:45</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* there is a list in behavioral biology for this exact reason when folks need people that have some time to review, maybe could make like a google doc with those that have time in the coming weeks/months to be a reviewer and could fill in how many papers they have the availability for? Could allow more early career follks to sign up as well?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-02-16 09:14:34">
            
                <img src="https://secure.gravatar.com/avatar/e96336d4ab1e44113cdeeb9c597c99ae.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Mikey Tabak
                     <span class="print-only user-email">(tabakma@gmail.com)</span>
                </div>
                <a href="#2023-02-16 09:14:34"><div class="time">2023-02-16 09:14:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Good idea! Some journals can have specific requirements, but it is not essential in general. I think, at this point, editors are so desperate they would not be too restrictive in their searches for reviewers</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-10 09:59:15">
            
                <img src="https://avatars.slack-edge.com/2021-05-21/2092314637443_dec133d7da36a4e57adc_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Emily Charry Tissier
                     <span class="print-only user-email">(hello@whaleseeker.com)</span>
                </div>
                <a href="#2023-03-10 09:59:15"><div class="time">2023-03-10 09:59:15</div></a>
                <div class="msg">
                    <p><a href="https://www.frontiersin.org/articles/10.3389/fmars.2023.1099479/full?utm_source=dlvr.it&amp;utm_medium=twitter">https://www.frontiersin.org/articles/10.3389/fmars.2023.1099479/full?utm_source=dlvr.it&amp;utm_medium=twitter</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Frontiers</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.frontiersin.org/articles/10.3389/fmars.2023.1099479/full?utm_source=dlvr.it&amp;utm_medium=twitter">Scaling whale monitoring using deep learning: A human-in-the-loop solution for analyzing aerial datasets</a></div>
                                <div class="link-text">
                                    To ensure effective cetacean management and conservation policies, it is necessary to collect and rigorously analyze data about these populations. Remote sensing allows the acquisition of images over large observation areas, but due to the lack of reliable automatic analysis techniques, biologists usually analyze all images by hand. In this paper, we propose a human-in-the-loop approach to couple the power of deep learning-based automation with the expertise of biologists to develop a reliable artificial intelligence assisted annotation tool for cetacean monitoring. We tested this approach to analyze a dataset of 5334 aerial images acquired in 2017 by Fisheries and Oceans Canada to monitor belugas (Delphinapterus leucas) from the threatened Cumberland Sound population in Clearwater Fjord, Canada. First, we used a test subset of photographs to compare predictions obtained by the fine-tuned model to manual annotations made by three Observers, expert marine mammal biologists. With only 100 annotated images for training, the model obtained between 90% and 91.4% mutual agreement with the three Observers, exceeding the minimum inter-observer agreement of 88.6% obtained between the experts themselves. Second, this model was applied to the full dataset. The predictions were then verified by an Observer and compared to annotations made completely manually and independently by another Observer. The annotating Observer and the human-in-the-loop pipeline detected 4051 belugas in commo...
                                </div>
                                
                                
    
        <a href="https://www.frontiersin.org/articles/10.3389/fmars.2023.1099479/full?utm_source=dlvr.it&amp;utm_medium=twitter">
            <img class="preview" src="https://www.frontiersin.org/files/MyHome%20Article%20Library/1099479/1099479_Thumb_400.jpg"
                width="400"
                 height="135" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.frontiersin.org/articles/10.3389/fmars.2023.1099479/full?utm_source=dlvr.it&amp;amp;utm_medium=twitter</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Georgia Atkinson, Cameron Trotter, Dan Morris, Viktor Domazetoski, Sara Beery, Shir Bar, Tjomme Dooper, Caleb Robinson
                        </div>
                    
                        <div class="message-reaction">
                        üêã Suzanne Stathatos, Emilio Luz-Ricca, Caleb Robinson, Alexander Dungate
                        </div>
                    
                        <div class="message-reaction">
                        üëÄ Nico Lang
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-23 05:55:56">
            
                <img src="https://avatars.slack-edge.com/2022-05-30/3618994471616_25e0011a7151bbafe212_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Blair Costelloe
                     <span class="print-only user-email">(blaircostelloe@gmail.com)</span>
                </div>
                <a href="#2023-03-23 05:55:56"><div class="time">2023-03-23 05:55:56</div></a>
                <div class="msg">
                    <p>Excited to announce our new Research Methods Guide on using drones and deep learning to observe the movement and behavior of animal groups in the context of their natural environments! <a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.13904">https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.13904</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Emily Lines, Stephanie O&#39;Donnell, Sara Beery, Yseult Hb, Suzanne Stathatos, Andrew Schulz, Viktor Domazetoski, Andrzej Bia≈Ça≈õ, Emilio Luz-Ricca, Venkatesh Ramesh, Mitch Fennell
                        </div>
                    
                        <div class="message-reaction">
                        :thumbsup_all: Frederic Fol Leymarie, Aakash Gupta
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-23 10:30:24">
            
                <img src="https://avatars.slack-edge.com/2020-01-25/922209904805_4d3028137f486fd1f400_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Koger
                     <span class="print-only user-email">(benkoger@gmail.com)</span>
                </div>
                <a href="#2023-03-23 10:30:24"><div class="time">2023-03-23 10:30:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* See Twitter for more info! <a href="https://mobile.twitter.com/ben_koger/status/1638635520816476160">https://mobile.twitter.com/ben_koger/status/1638635520816476160</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">twitter</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="https://pbs.twimg.com/profile_images/1037696037442465793/muLD8tbw_normal.jpg" class="icon">
                                    }
                                    <a href="https://twitter.com/ben_koger/status/1638635520816476160">
                                    Ben Koger
                                    </a><span class="print-only">(https://twitter.com/ben_koger/status/1638635520816476160)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href=""></a></div>
                                <div class="link-text">
                                    Out now in &lt;a href=&#34;https://twitter.com/AnimalEcology&#34;&gt;@AnimalEcology&lt;/a&gt;! A general approach for using drones to study animal behavior in the wild. Record the location and posture of many animals simultaneously at sub-second sub-meter resolution, plus reconstruct their 3D landscape: &lt;https://doi.org/10.1111/1365-2656.13904&gt;
                                </div>
                                
                                
    
        <a href="https://mobile.twitter.com/ben_koger/status/1638635520816476160">
            <img class="preview" src="https://pbs.twimg.com/ext_tw_video_thumb/1638632364644642819/pu/img/kTHvO0bXeXcDRGIn.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://mobile.twitter.com/ben_koger/status/1638635520816476160</div>
                                
                                
                                    <div class="attachment-footer">
                                        <img src="https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png" class="icon" />
                                        Twitter
                                    </div>
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ Blair Costelloe, Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-23 13:03:17">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-03-23 13:03:17"><div class="time">2023-03-23 13:03:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Are the training data available there? @Dan Morris. It would nice for us to check how we are doing at doing object detection for novel classes like zebras and other large mammals.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-23 13:16:28">
            
                <img src="https://avatars.slack-edge.com/2020-01-25/922209904805_4d3028137f486fd1f400_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Koger
                     <span class="print-only user-email">(benkoger@gmail.com)</span>
                </div>
                <a href="#2023-03-23 13:16:28"><div class="time">2023-03-23 13:16:28</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Yes, it should be here: <a href="https://edmond.mpdl.mpg.de/dataset.xhtml?persistentId=doi:10.17617/3.EMRZGH">https://edmond.mpdl.mpg.de/dataset.xhtml?persistentId=doi:10.17617/3.EMRZGH</a> (Sorry for the giant download size. If you have recommendation for a better place to store just the annotated dataset let me know and I can put them there.)</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Edmond</div>
                            
                            
                                
                                <div class="link-title"><a href="https://edmond.mpdl.mpg.de/dataset.xhtml?persistentId=doi:10.17617/3.EMRZGH">Data for: Multi-animal behavioral tracking and environmental reconstruction using drones and computer vision in the wild</a></div>
                                <div class="link-text">
                                    This is data used for the worked examples in the paper &#34;Multi-animal behavioral tracking and environmental reconstruction using drones and computer...
                                </div>
                                
                                
    
        <a href="https://edmond.mpdl.mpg.de/dataset.xhtml?persistentId=doi:10.17617/3.EMRZGH">
            <img class="preview" src="https://edmond.mpdl.mpg.de/javax.faces.resource/images/dataverse-icon-1200.png.xhtml;jsessionid=f7775e49b075a81f4114ff645e04"
                width="1200"
                 height="1200" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://edmond.mpdl.mpg.de/dataset.xhtml?persistentId=doi:10.17617/3.EMRZGH</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-23 13:21:29">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-03-23 13:21:29"><div class="time">2023-03-23 13:21:29</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* yeah, that's why i pinged @Dan Morris before, its the first place is on the archive he maintains.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-23 13:24:00">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-03-23 13:24:00"><div class="time">2023-03-23 13:24:00</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* What would you say is a maintain pain points for the object detection + drone parts of the workflow, not the tracking. We are always trying to gauge what we should be working on. 1) active learning/integrated annotation frameworks, 2) managing large geospatial tiles, for example cutting them, storing them and retrieving them, 3) getting enough data, starting from relevant backbones, 4) prediction at scale, 5) visualizing results, 6) anything else.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-23 13:52:08">
            
                <img src="https://avatars.slack-edge.com/2020-01-25/922209904805_4d3028137f486fd1f400_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Koger
                     <span class="print-only user-email">(benkoger@gmail.com)</span>
                </div>
                <a href="#2023-03-23 13:52:08"><div class="time">2023-03-23 13:52:08</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I think especially for the ecologists who want to start using this stuff, the biggest hurdle is still mostly around point 1: helping people as painlessly as possible go  from "I have a bunch of drone videos where the animals are pretty easy to see" to a usable trained model. I think a lot of initial projects are still pretty small scale footage-wise so some of the other stuff is less of a bottleneck.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-23 14:12:40">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-03-23 14:12:40"><div class="time">2023-03-23 14:12:40</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* so that might look like, take in a video, process into images, use a baseline model to identify potential crops, show those crops to user for annotation, maybe look them up against any data we have, or potentially resources like inaturalist, use those annotations to train a model, and save it somewhere online for them to point from a url  (@Sara Beery for our meeting).</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Ben Koger, Blair Costelloe
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-24 15:54:30">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-03-24 15:54:30"><div class="time">2023-03-24 15:54:30</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* This looks like a really interesting dataset!  I downloaded it and explored a little, the videos are pretty mesmerizing.</p>

<p>I'd like to add it to LILA's list of other data sets: <a href="https://lila.science/otherdatasets">https://lila.science/otherdatasets</a>.  @Ben Koger, is there a summary of the dataset, i.e., how many annotated bounding boxes on how many species?  Basically: is there a README?</p>

<p>In terms of giving it a (new) permanent home, I don't usually re-host something on LILA when it already has a definitive place to live, and the <a href="http://mpg.de">mpg.de</a> page looks like it's a good place.  The download isn't too big a deal, although it would be a lot faster if it were hosted directly on a cloud bucket.  So I'm not opposed to re-hosting on LILA.  Ben K, if that's of interest to you, drop me an email at info@lila.science .  These are the most analogous datasets hosted on LILA right now:</p>

<p><a href="https://lila.science/datasets/aerial-seabirds-west-africa/">https://lila.science/datasets/aerial-seabirds-west-africa/</a>
<a href="https://lila.science/datasets/conservationdrones">https://lila.science/datasets/conservationdrones</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-28 12:15:35">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2023-03-28 12:15:35"><div class="time">2023-03-28 12:15:35</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Ben Koger @Blair Costelloe I'm also very interested in more of a breakdown of the data! What human detection and keypoint annotations were collected, across what number of flights, what locations/regions, what species, what timestamps...? I don't see information like this in the supplementary, though you do have a <strong>great</strong> discussion of how careful this selection process should be, let me know if I've missed it!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-28 13:26:24">
            
                <img src="https://avatars.slack-edge.com/2020-01-25/922209904805_4d3028137f486fd1f400_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Koger
                     <span class="print-only user-email">(benkoger@gmail.com)</span>
                </div>
                <a href="#2023-03-28 13:26:24"><div class="time">2023-03-28 13:26:24</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Right now the best info we have in the text is Table 1 in the supplement which breaks down the annotated data by species and has info about bounding box size and our trained model performance on the different species classes in our test set. @Sara Beery we currently don't list the additional information you mention which I agree would be very useful. I'm working now to write down some of that additional information. Ultimately I think it will make sense to include the stand alone annotated dataset with clearer and more comprehensive metadata on LILA (@Dan Morris, I'll email info@lila.science when I get things put together)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-28 13:28:02">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2023-03-28 13:28:02"><div class="time">2023-03-28 13:28:02</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* That sounds great :)</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-29 13:46:34">
            
                <img src="https://secure.gravatar.com/avatar/9695bf0c86a1187d70780f746aeb64df.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0026-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Levi Cai
                     <span class="print-only user-email">(lcai@whoi.edu)</span>
                </div>
                <a href="#2023-03-29 13:46:34"><div class="time">2023-03-29 13:46:34</div></a>
                <div class="msg">
                    <p>Hi all, didn't realize this channel existed. A little older, but for anyone interested in using AUVs and vision for animal tracking, especially in data-scarce scenarios, we recently published a paper on this using semi-supervised learning approaches in IJCV's animal tracking special issue: <a href="https://link.springer.com/article/10.1007/s11263-023-01762-5">https://link.springer.com/article/10.1007/s11263-023-01762-5</a>. <b>#marine</b> folks may be interested as well.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">SpringerLink</div>
                            
                            
                                
                                <div class="link-title"><a href="https://link.springer.com/article/10.1007/s11263-023-01762-5">Semi-supervised Visual Tracking of Marine Animals Using Autonomous Underwater Vehicles</a></div>
                                <div class="link-text">
                                    International Journal of Computer Vision - In-situ visual observations of marine organisms is crucial to developing behavioural understandings and their relations to their surrounding ecosystem....
                                </div>
                                
                                
    
        <a href="https://link.springer.com/article/10.1007/s11263-023-01762-5">
            <img class="preview" src="https://media.springernature.com/w200/springer-static/cover/journal/11263.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://link.springer.com/article/10.1007/s11263-023-01762-5</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Justin Kay, Steve Haddock, Mauricio Tec, Sara Beery, Malte Pedersen, Mikey Tabak
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-03-29 16:25:43">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-03-29 16:25:43"><div class="time">2023-03-29 16:25:43</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Very cool, and I'm especially interested in the dataset!  I downloaded it and tinkered a little, the annotations are straightforward and - most importantly - the videos are really fun to stare at.  I added to the list of marine image datasets here:</p>

<p><a href="https://lila.science/otherdatasets#images-marine">https://lila.science/otherdatasets#images-marine</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-05 15:55:09">
            
                <img src="https://avatars.slack-edge.com/2020-01-25/922209904805_4d3028137f486fd1f400_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Koger
                     <span class="print-only user-email">(benkoger@gmail.com)</span>
                </div>
                <a href="#2023-04-05 15:55:09"><div class="time">2023-04-05 15:55:09</div></a>
                <div class="msg">
                    <p>New segmentation dataset/model/paper from meta that looks very helpful at a minimum for annotation but probably for much more: <a href="https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/">https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">ai.facebook.com</div>
                            
                            
                                
                                <div class="link-title"><a href="https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/">Introducing Segment Anything</a></div>
                                <div class="link-text">
                                    We&#39;re releasing the Segment Anything Model (SAM) ‚Äî a step toward the first foundation model for image segmentation ‚Äî and the SA-1B dataset.
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚úÖ Aakash Gupta, Josh Veitch-Michaelis, Timm Haucke, Lucia Gordon, Mikey Tabak, Sepand Dyanatkar
                        </div>
                    
                        <div class="message-reaction">
                        üëÄ Carl Boettiger
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-06 07:10:39">
            
                <img src="https://avatars.slack-edge.com/2024-08-02/7510233340197_2e10694603b688fab440_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Josh Veitch-Michaelis
                     <span class="print-only user-email">(j.veitchmichaelis@gmail.com)</span>
                </div>
                <a href="#2023-04-06 07:10:39"><div class="time">2023-04-06 07:10:39</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* This is super cool. It seems like a nicely packaged assist tool for annotation (I've not tried text-guided segmentation yet). The big model does work on my M1 mac CPU (I didn't try mps) but it's pretty heavy so you definitely want a gpu to play with it. Seems to work "ok" on satellite images and at least as good as any commercial auto-segment too I've tried.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-05 16:29:48">
            
                <img src="https://avatars.slack-edge.com/2023-09-08/5869613577747_0ca93b5fea80e0bd83bd_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Tiziana Gelmi Candusso
                     <span class="print-only user-email">(tiziana.gelmicandusso@utoronto.ca)</span>
                </div>
                <a href="#2023-04-05 16:29:48"><div class="time">2023-04-05 16:29:48</div></a>
                <div class="msg">
                    <p><a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14044">https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14044</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Ed Miller, Dante Wasmuht, Agnethe Seim Olsen, Mikey Tabak, Emilio Luz-Ricca
                        </div>
                    
                        <div class="message-reaction">
                        üëç:skin_tone_3: Pen-Yuan Hsing
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-12 03:49:02">
            
                <img src="https://avatars.slack-edge.com/2022-05-30/3618994471616_25e0011a7151bbafe212_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Blair Costelloe
                     <span class="print-only user-email">(blaircostelloe@gmail.com)</span>
                </div>
                <a href="#2023-04-12 03:49:02"><div class="time">2023-04-12 03:49:02</div></a>
                <div class="msg">
                    <p><a href="https://www.biorxiv.org/content/10.1101/2023.04.07.535991v1">https://www.biorxiv.org/content/10.1101/2023.04.07.535991v1</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">bioRxiv</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.biorxiv.org/content/10.1101/2023.04.07.535991v1">PoseR - A deep learning toolbox for decoding animal behavior</a></div>
                                <div class="link-text">
                                    The actions of animals provide a window into how their minds work. Recent advances in deep learning are providing powerful approaches to recognize patterns of animal movement from video recordings, including markerless pose estimation models. However, tools to efficiently parse coordinates of animal position and pose into meaningful semantic behavioral labels are lacking. Here, we present PoseRecognition (PoseR), a behavioral decoder leveraging state- of-the-art action recognition models using spatio-temporal graph convolutional networks. We show that it can be used to decode animal behavior quickly and accurately from pose estimations, using zebrafish larvae and mice as model organisms. PoseR can be accessed using a Napari plugin, which facilitates efficient behavioral extraction, annotation, model training and deployment. We have simplified the workflow of behavioral analysis after pose estimation, transforming coordinates of animal position and pose into meaningful semantic behavioral labels, using methods designed for fast and accurate behavioral extraction, annotation, model training and deployment. Furthermore, we contribute a novel method for unsupervised clustering of behaviors and provide open-source access to our zebrafish datasets and models. The design of our tool ensures scalability and versatility for use across multiple species and contexts, improving the efficiency of behavioral analysis across fields.

### Competing Interest Statement

The authors have declared no competing interest.
                                </div>
                                
                                
    
        <a href="https://www.biorxiv.org/content/10.1101/2023.04.07.535991v1">
            <img class="preview" src="https://www.biorxiv.org/sites/default/files/images/biorxiv_logo_homepage7-5-small.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.biorxiv.org/content/10.1101/2023.04.07.535991v1</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Sara Beery, Yseult Hb, Tiziana Gelmi Candusso, Mikey Tabak
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-13 06:57:01">
            
                <img src="https://avatars.slack-edge.com/2021-10-20/2615548747079_59b98294fae6beb7bd0b_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carl Boettiger
                     <span class="print-only user-email">(cboettig@berkeley.edu)</span>
                </div>
                <a href="#2023-04-13 06:57:01"><div class="time">2023-04-13 06:57:01</div></a>
                <div class="msg">
                    <p>provocative but fun paper about some of the possible risks to AI-assisted governance, potentially relevant to AI conservation: <a href="https://journals.sagepub.com/doi/full/10.1177/20539517231164119">https://journals.sagepub.com/doi/full/10.1177/20539517231164119</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Felipe Parodi, Suzanne Stathatos, Mikey Tabak, Emilio Luz-Ricca
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-13 10:17:08">
            
                <img src="https://avatars.slack-edge.com/2022-05-15/3524665416485_92bd421c6859526492bf_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Felipe Parodi
                     <span class="print-only user-email">(parodifelipe07@gmail.com)</span>
                </div>
                <a href="#2023-04-13 10:17:08"><div class="time">2023-04-13 10:17:08</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* neat, thanks! Anyone know if there‚Äôs an ai for conservation reading club or something similar?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-26 03:18:42">
            
                <img src="https://avatars.slack-edge.com/2022-09-23/4122822797362_b2de7d2056cd71d19f4c_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Aleksis Pirinen
                     <span class="print-only user-email">(aleksis.pirinen@ri.se)</span>
                </div>
                <a href="#2023-04-26 03:18:42"><div class="time">2023-04-26 03:18:42</div></a>
                <div class="msg">
                    <p>This sounds interesting:</p>

<p><em><strong>Empowering Wildlife Guardians: An Equitable Digital Stewardship and Reward System for Biodiversity Conservation using Deep Learning and 3/4G Camera Traps</strong></em> (<a href="https://arxiv.org/abs/2304.12703">https://arxiv.org/abs/2304.12703</a>).</p>

<p>From the abstract:</p>

<p>"""
This paper proposes a radical new solution based on <strong>"Interspecies Money,"</strong> where <strong>animals own their own money</strong>. Creating a digital twin for each species allows animals to dispense funds to their guardians for the services they provide. <strong>For example, a rhinoceros may release a payment to its guardian each time it is detected in a camera trap as long as it remains alive and well</strong>. To test the efficacy of this approach 27 camera traps were deployed over a 400km2 area in Welgevonden Game Reserve in Limpopo Province in South Africa. The motion-triggered camera traps were operational for ten months and, using deep learning, we managed to capture images of 12 distinct animal species. For each species, a makeshift bank account was set up and credited with ¬£100. Each time an animal was captured in a camera and successfully classified, 1 penny (an arbitrary amount - mechanisms still need to be developed to determine the real value of species) was transferred from the animal account to its associated guardian.
"""</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2304.12703">Empowering Wildlife Guardians: An Equitable Digital Stewardship and Reward System for Biodiversity Conservation using Deep Learning and 3/4G Camera Traps</a></div>
                                <div class="link-text">
                                    The biodiversity of our planet is under threat, with approximately one
million species expected to become extinct within decades. The reason; negative
human actions, which include hunting, overfishing, pollution, and the
conversion of land for urbanisation and agricultural purposes. Despite
significant investment from charities and governments for activities that
benefit nature, global wildlife populations continue to decline. Local wildlife
guardians have historically played a critical role in global conservation
efforts and have shown their ability to achieve sustainability at various
levels. In 2021, COP26 recognised their contributions and pledged US$1.7
billion per year; however, this is a fraction of the global biodiversity budget
available (between US$124 billion and US$143 billion annually) given they
protect 80% of the planets biodiversity. This paper proposes a radical new
solution based on &#34;Interspecies Money,&#34; where animals own their own money.
Creating a digital twin for each species allows animals to dispense funds to
their guardians for the services they provide. For example, a rhinoceros may
release a payment to its guardian each time it is detected in a camera trap as
long as it remains alive and well. To test the efficacy of this approach 27
camera traps were deployed over a 400km2 area in Welgevonden Game Reserve in
Limpopo Province in South Africa. The motion-triggered camera traps were
operational for ten months and, using deep learning, we managed to capture
images of 12 distinct animal species. For each species, a makeshift bank
account was set up and credited with ¬£100. Each time an animal was
captured in a camera and successfully classified, 1 penny (an arbitrary amount
- mechanisms still need to be developed to determine the real value of species)
was transferred from the animal account to its associated guardian.
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2304.12703">
            <img class="preview" src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2304.12703</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Lucia Gordon
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-01 17:17:19">
            
                <img src="https://avatars.slack-edge.com/2023-10-04/5986725888693_d75fa003cae23e4beeff_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Kalindi Fonda
                     <span class="print-only user-email">(kalindi.fonda@gmail.com)</span>
                </div>
                <a href="#2023-05-01 17:17:19"><div class="time">2023-05-01 17:17:19</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thank you for sharing. It's interesting.</p>

<p>It reminds me of a conversation with Ale (the cofounder) from LAMAVE <a href="https://www.lamave.org/">https://www.lamave.org/</a> about how there was this one specific family that was selling turtle eggs on the market and they'd get 4 pesos for it. So then the turtle nurseries offered them 6 pesos, to make sure they'd drop the eggs at the nursery instead of the market. But if the market paid 8 pesos ...</p>

<p>He mentioned that it's important to create some kind of inherent value about the biodiveristy around us (often traditionally it comes in the form of myths and stories), because if there is a clear monetary value, then it's very "easy "to shift to whoever who will pay more.</p>

<p>I am curious about where biodiversity and money intersect.
And curious to hear about what you think about the paper too.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üíö Aleksis Pirinen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-26 06:32:00">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5729572396613_37c6726ad5d913013f67_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Aakash Gupta
                     <span class="print-only user-email">(aakash@thinkevolveconsulting.com)</span>
                </div>
                <a href="#2023-04-26 06:32:00"><div class="time">2023-04-26 06:32:00</div></a>
                <div class="msg">
                    <p>This seems like a useful tool for bio-mass estimation. The pipeline includes the DINOv2 and segment-anything model. RGB airborne images have been trained along with LiDAR images of the same geo-referenced location for identifying the canopy height with sub-meter resolution.</p>

<p><strong><a href="https://research.facebook.com/blog/2023/4/every-tree-counts-large-scale-mapping-of-canopy-height-at-the-resolution-of-individual-trees/">https://research.facebook.com/blog/2023/4/every-tree-counts-large-scale-mapping-of-canopy-height-at-the-resolution-of-individual-trees/</a></strong></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Meta Research</div>
                            
                            
                                
                                <div class="link-title"><a href="https://research.facebook.com/blog/2023/4/every-tree-counts-large-scale-mapping-of-canopy-height-at-the-resolution-of-individual-trees/">Every tree counts: Large-scale mapping of canopy height at the resolution of individual trees | Meta Research</a></div>
                                <div class="link-text">
                                    Meta set a goal to reach net zero emissions by 2030. We are developing technology to mitigate our carbon footprint and making these openly available.
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Written by</div>
                                        Jamie Tolan, Camille Couprie, and Tracy Johns
                                    </div>
                                
                                
    
        <a href="https://research.facebook.com/blog/2023/4/every-tree-counts-large-scale-mapping-of-canopy-height-at-the-resolution-of-individual-trees/">
            <img class="preview" src="https://research.facebook.com/file/229236876446547/every-tree-counts.jpg"
                width="1500"
                 height="840" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://research.facebook.com/blog/2023/4/every-tree-counts-large-scale-mapping-of-canopy-height-at-the-resolution-of-individual-trees/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üå≥ Nico Lang, Adam Noach, Sara Beery, Lucia Gordon, Felipe Parodi, Shir Bar, David Will
                        </div>
                    
                        <div class="message-reaction">
                        üëç Stephanie O&#39;Donnell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-30 15:04:20">
            
                <img src="https://avatars.slack-edge.com/2021-07-06/2270250594576_b26208ffe098b963d801_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Zhongqi Miao
                     <span class="print-only user-email">(zhongqi.miao@berkeley.edu)</span>
                </div>
                <a href="#2023-04-30 15:04:20"><div class="time">2023-04-30 15:04:20</div></a>
                <div class="msg">
                    <p>Check out our new paper on a system analysis and review of the challenges and flexibility of using deep learning techniques to real-world imagery datasets, featuring a case study on overhead bird recognition:</p>

<p><em><strong>Challenges and solutions for automated avian recognition in aerial imagery</strong></em></p>

<p><a href="https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1002/rse2.318">https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1002/rse2.318</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        ü¶Ü Dan Morris, Rowan Converse, Sara Beery, Mikey Tabak
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-04-30 17:47:40">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-04-30 17:47:40"><div class="time">2023-04-30 17:47:40</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* You know how into aerial bird survey data I am right now... üôÇ Is any of the training data from this paper available?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-01 04:26:50">
            
                <img src="https://avatars.slack-edge.com/2022-02-10/3079007120838_2256d6dbf14428a3afc4_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Devis Tuia
                     <span class="print-only user-email">(devis.tuia@epfl.ch)</span>
                </div>
                <a href="#2023-05-01 04:26:50"><div class="time">2023-05-01 04:26:50</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I think I have an idea üòâ Dan..</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-01 15:08:16">
            
                <img src="https://avatars.slack-edge.com/2021-07-06/2270250594576_b26208ffe098b963d801_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Zhongqi Miao
                     <span class="print-only user-email">(zhongqi.miao@berkeley.edu)</span>
                </div>
                <a href="#2023-05-01 15:08:16"><div class="time">2023-05-01 15:08:16</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris we did publish some data for this project, but only cropped and resized instances. The full overhead imagery are still not published and I think it is determined by USGS. If you are still interested in the cropped instances, there is a link to the data in the paper!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-01 17:06:39">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-05-01 17:06:39"><div class="time">2023-05-01 17:06:39</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Dan Morris, i'm working with these teams, if you need data, let me know too.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-01 21:05:14">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-05-01 21:05:14"><div class="time">2023-05-01 21:05:14</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I don't "need" data, I'm just sort of in the mode of hoarding data. üôÇ I'll let you know if I want to dig deeper, and @Zhongqi Miao, I will check out the crops.  Thanks!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-02 02:56:05">
            
                <img src="https://avatars.slack-edge.com/2022-02-10/3079007120838_2256d6dbf14428a3afc4_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Devis Tuia
                     <span class="print-only user-email">(devis.tuia@epfl.ch)</span>
                </div>
                <a href="#2023-05-02 02:56:05"><div class="time">2023-05-02 02:56:05</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Jokes apart, great work @Zhongqi Miao! if someone needs some more data, we had this paper out some time ago and the images we got were a good starting point for us in avian recognition: <a href="https://zslpublications.onlinelibrary.wiley.com/doi/pdf/10.1002/rse2.200">https://zslpublications.onlinelibrary.wiley.com/doi/pdf/10.1002/rse2.200</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-03 13:32:17">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2023-05-03 13:32:17"><div class="time">2023-05-03 13:32:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Zhongqi Miao Thanks, I downloaded the crops; the dataset is very clear and well-organized.  I added the dataset to this list:</p>

<p><a href="https://lila.science/otherdatasets#images-terrestrial-animals">https://lila.science/otherdatasets#images-terrestrial-animals</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-03 14:03:12">
            
                <img src="https://avatars.slack-edge.com/2021-07-06/2270250594576_b26208ffe098b963d801_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Zhongqi Miao
                     <span class="print-only user-email">(zhongqi.miao@berkeley.edu)</span>
                </div>
                <a href="#2023-05-03 14:03:12"><div class="time">2023-05-03 14:03:12</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thank you very much for adding it to lila!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-01 17:11:00">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-05-01 17:11:00"><div class="time">2023-05-01 17:11:00</div></a>
                <div class="msg">
                    <p>I enjoyed <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/43119db5d59f07cc08fca7ba6820179a-Paper-Datasets_and_Benchmarks.pdf">https://proceedings.neurips.cc/paper_files/paper/2022/file/43119db5d59f07cc08fca7ba6820179a-Paper-Datasets_and_Benchmarks.pdf</a>. Existing computer vision methods have a hard time capturing temporal shifts in classes and predictors. This is really important for wildlife surveys that may capture animal migration or phenology. Does anyone have experience on trying to influence predictors with image metadata. Somewhat connection to older paper, but time instead of space, as paper by @Oisin Mac Aodha <a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Aodha_Presence-Only_Geographical_Priors_for_Fine-Grained_Image_Classification_ICCV_2019_paper.html">https://openaccess.thecvf.com/content<em>ICCV</em>2019/html/Aodha<em>Presence-Only</em>Geographical<em>P[‚Ä¶]for</em>Fine-Grained<em>Image</em>Classification<em>ICCV</em>2019_paper.html</a>).</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Sara Beery, Justin Kay, Oisin Mac Aodha, Timm Haucke
                        </div>
                    
                        <div class="message-reaction">
                        üêù aruna, Aakash Gupta
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-01 17:12:52">
            
                <img src="https://avatars.slack-edge.com/2023-09-21/5921741643494_a59f0c723aa600a8676a_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Sara Beery
                     <span class="print-only user-email">(sbeery@caltech.edu)</span>
                </div>
                <a href="#2023-05-01 17:12:52"><div class="time">2023-05-01 17:12:52</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* We've been looking at some of these issues in fish detection and tracking in sonar with @Justin Kay @Suzanne Stathatos and @gvanhorn</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ aruna
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-01 17:42:17">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-05-01 17:42:17"><div class="time">2023-05-01 17:42:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* A followup paper is here <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Dynamic_MLP_for_Fine-Grained_Image_Classification_by_Leveraging_Geographical_and_CVPR_2022_paper.pdf">https://openaccess.thecvf.com/content/CVPR2022/papers/Yang<em>Dynamic</em>MLP<em>for</em>Fine-Grained[‚Ä¶]ication<em>by</em>Leveraging<em>Geographical</em>and<em>CVPR</em>2022_paper.pdf</a>. Reviewing different adaptive strategies for additional data temporal integration. Gets us closer to the seasonality question, since similar timestamps may be non-linear and non-consecutive, as with migrant birds returning in spring and fall. Bias from temporal imbalance in training data is lurking in all of this.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-10 01:10:01">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-05-10 01:10:01"><div class="time">2023-05-10 01:10:01</div></a>
                <div class="msg">
                    <p><a href="https://arxiv.org/pdf/2304.06306.pdf">https://arxiv.org/pdf/2304.06306.pdf</a> is a nice model on fusing large language model text and vision features. One thing i've been brewing on for a long time is how to do we merge the context that many ecologists/conservation managers have of a set of images with the computer vision classifier. For example, if you were piloting a UAV over a forest, you might give the prompt, "This survey took place in a dense hardwood forest in Northern Vermont. Many small  red maples are present". Could we fuse that knowledge with the typical computer vision classifier to help push the model to make better predictions of tree species. The alternative is what we do now, try to embed structured information like geography and environment into models and concat features (<a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13335">https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13335</a>) or the kind of rule-based knowledge distillation with student/teacher methods. I've never had much success with either kind of embeddings. They overfit quickly and are awkward. Thoughts?</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Emilio Luz-Ricca, Dan Stowell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-10 13:06:36">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-05-10 13:06:36"><div class="time">2023-05-10 13:06:36</div></a>
                <div class="msg">
                    <p>Our new paper on tree species prediction for one NEON site is out at Remote Sensing in Ecology and Conservation. Tree species predictions for 100 million NEON trees will be out soon for ~25 sites.</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üéâ Declan, Gracie Ermi, Sara Beery, Aakash Gupta, Malte Pedersen, Casey Youngflesh, Lindsey Dukles, Emilio Luz-Ricca, Mikey Tabak
                        </div>
                    
                        <div class="message-reaction">
                        üå≥ Rowan Converse
                        </div>
                    
                        <div class="message-reaction">
                        üôå Carl Boettiger
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-10 13:08:43">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-05-10 13:08:43"><div class="time">2023-05-10 13:08:43</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Data will look like this, released as 1km shapefiles.</p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-13 23:22:41">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-05-13 23:22:41"><div class="time">2023-05-13 23:22:41</div></a>
                <div class="msg">
                    <p>Helpful. 
<a href="https://arxiv.org/abs/2304.12210">https://arxiv.org/abs/2304.12210</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2304.12210">A Cookbook of Self-Supervised Learning</a></div>
                                <div class="link-text">
                                    Self-supervised learning, dubbed the dark matter of intelligence, is a
promising path to advance machine learning. Yet, much like cooking, training
SSL methods is a delicate art with a high barrier to entry. While many
components are familiar, successfully training a SSL method involves a dizzying
set of choices from the pretext tasks to training hyper-parameters. Our goal is
to lower the barrier to entry into SSL research by laying the foundations and
latest SSL recipes in the style of a cookbook. We hope to empower the curious
researcher to navigate the terrain of methods, understand the role of the
various knobs, and gain the know-how required to explore how delicious SSL can
be.
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2304.12210">
            <img class="preview" src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2304.12210</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Shir Bar, Lukas Picek, Matt Weldy, Enis Berk √áoban, Sara Beery, Carly Batist
                        </div>
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Ben Williams
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-22 12:42:08">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-05-22 12:42:08"><div class="time">2023-05-22 12:42:08</div></a>
                <div class="msg">
                    <p>regardless of what you think of the evidence (for the record i'm <em>not</em> convinced), I think its incredibly important to highlight how image and sensor based technologies are the being actively used and relied on during the fieldwork surrounding Ivory-billed Woodpeckers. Camera traps, UAVs and sound recorders. When you step back, these pieces of evidence are the only convincing way to document the species, should it exist. I think we as a community should be proud of that. <a href="https://onlinelibrary.wiley.com/doi/10.1002/ece3.10017">https://onlinelibrary.wiley.com/doi/10.1002/ece3.10017</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-23 03:57:59">
            
                <img src="https://secure.gravatar.com/avatar/170f4f5f03087b25cc411f7758518241.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Stowell
                     <span class="print-only user-email">(dan.stowell@naturalis.nl)</span>
                </div>
                <a href="#2023-05-23 03:57:59"><div class="time">2023-05-23 03:57:59</div></a>
                <div class="msg">
                    <p>New preprint from us! "Learning to detect an animal sound from five examples" <a href="https://arxiv.org/abs/2305.13210">https://arxiv.org/abs/2305.13210</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2305.13210">Learning to detect an animal sound from five examples</a></div>
                                <div class="link-text">
                                    Automatic detection and classification of animal sounds has many applications
in biodiversity monitoring and animal behaviour. In the past twenty years, the
volume of digitised wildlife sound available has massively increased, and
automatic classification through deep learning now shows strong results.
However, bioacoustics is not a single task but a vast range of small-scale
tasks (such as individual ID, call type, emotional indication) with wide
variety in data characteristics, and most bioacoustic tasks do not come with
strongly-labelled training data. The standard paradigm of supervised learning,
focussed on a single large-scale dataset and/or a generic pre-trained
algorithm, is insufficient. In this work we recast bioacoustic sound event
detection within the AI framework of few-shot learning. We adapt this framework
to sound event detection, such that a system can be given the annotated
start/end times of as few as 5 events, and can then detect events in
long-duration audio -- even when the sound category was not known at the time
of algorithm training. We introduce a collection of open datasets designed to
strongly test a system&#39;s ability to perform few-shot sound event detections,
and we present the results of a public contest to address the task. We show
that prototypical networks are a strong-performing method, when enhanced with
adaptations for general characteristics of animal sounds. We demonstrate that
widely-varying sound event durations are an important factor in performance, as
well as non-stationarity, i.e. gradual changes in conditions throughout the
duration of a recording. For fine-grained bioacoustic recognition tasks without
massive annotated training data, our results demonstrate that few-shot sound
event detection is a powerful new method, strongly outperforming traditional
signal-processing detection methods in the fully automated scenario.
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2305.13210">
            <img class="preview" src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2305.13210</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ü§Ø Oisin Mac Aodha, Fagner Cunha, Enis Berk √áoban, Andy Viet Huynh, Yseult Hb
                        </div>
                    
                        <div class="message-reaction">
                        üôå Omiros Pantazis, Santiago Martinez Balvanera, Shir Bar, Benjamin Hoffman, Sara Beery, Gracie Ermi, Andy Viet Huynh, Yseult Hb, Georgia Atkinson
                        </div>
                    
                        <div class="message-reaction">
                        üíÉ Rita Pucci, Andy Viet Huynh
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Carly Batist, Ben Weinstein, Dan Morris, Andy Viet Huynh, John Martinsson
                        </div>
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Leonardo Viotti, Emilio Luz-Ricca, Felipe Montealegre-Mora, Maddie Cusimano, Ben Williams, Juan Sebasti√°n Ca√±as Silva
                        </div>
                    
                        <div class="message-reaction">
                        üëç Aleksis Pirinen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-24 17:41:09">
            
                <img src="https://avatars.slack-edge.com/2021-08-09/2361920803907_ad849dc380fc3d3470dc_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Daniel Davila
                     <span class="print-only user-email">(daniel.davila@kitware.com)</span>
                </div>
                <a href="#2023-05-24 17:41:09"><div class="time">2023-05-24 17:41:09</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Very cool! Is there something like simclr in the field of acoustics? Would be near to see the equivalent of a large foundational model for all things bird sounds</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-25 18:47:51">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-05-25 18:47:51"><div class="time">2023-05-25 18:47:51</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I'm deeply interested in the 'foundation model' idea, when and where it is possible/useful/worth time as a community. Check out @gvanhorn paper <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Van_Horn_Benchmarking_Representation_Learning_for_Natural_World_Image_Collections_CVPR_2021_paper.html">https://openaccess.thecvf.com/content/CVPR2021/html/Van<em>Horn</em>Benchmarking<em>Representatio[‚Ä¶]g</em>for<em>Natural</em>World<em>Image</em>Collections<em>CVPR</em>2021_paper.html</a>, that didn't find a ton of downstream improvement and @Elijah Cole <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Cole_When_Does_Contrastive_Visual_Representation_Learning_Work_CVPR_2022_paper.pdf">https://openaccess.thecvf.com/content/CVPR2022/papers/Cole_When_Does_Contrastive_Visual_Representation_Learning_Work_CVPR_2022_paper.pdf</a>. which also didn't find a ton of promise. I defer to these two on additional insights, but I will say that at UF we are really working towards the question 'when do foundational models work in ecological monitoring' looking at airborne data for both trees and birds. If there are CS students out there looking for additional data or projects, let me know.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-26 06:52:34">
            
                <img src="https://secure.gravatar.com/avatar/170f4f5f03087b25cc411f7758518241.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Stowell
                     <span class="print-only user-email">(dan.stowell@naturalis.nl)</span>
                </div>
                <a href="#2023-05-26 06:52:34"><div class="time">2023-05-26 06:52:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Daniel Davila @Ben Weinstein Yes! The idea of a foundation model for wildlife sound is something I've been thinking about a lot, and IMHO the recent methods that seem to build towards it are (a) our few-shot work and (b) van Horn's work that you cite (specifically, its general "meta-learning for Wildlife QA" approach is neat).</p>

<p>I have some <em><strong>Opinions</strong></em> about self-supervised learning for animal sound, too long to type out here, but suffice to say that I'm doubtful it will be the solution in itself, some algorithm guidance is needed. Thus, keep the idea of foundation models distinct from the idea of SSL, and let's try and work out how we can build them...</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-26 10:17:04">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-05-26 10:17:04"><div class="time">2023-05-26 10:17:04</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* total agreement.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-29 08:22:38">
            
                <img src="https://avatars.slack-edge.com/2021-02-26/1801755617939_161ba9073fae1d586c9e_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Benjamin Hoffman
                     <span class="print-only user-email">(benjaminsshoffman@gmail.com)</span>
                </div>
                <a href="#2023-05-29 08:22:38"><div class="time">2023-05-29 08:22:38</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* @Masato Hagiwara has done some work in this direction, see <a href="https://arxiv.org/pdf/2210.14493.pdf">https://arxiv.org/pdf/2210.14493.pdf</a>.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-25 17:39:36">
            
                <img src="https://avatars.slack-edge.com/2021-02-26/1801755617939_161ba9073fae1d586c9e_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Benjamin Hoffman
                     <span class="print-only user-email">(benjaminsshoffman@gmail.com)</span>
                </div>
                <a href="#2023-05-25 17:39:36"><div class="time">2023-05-25 17:39:36</div></a>
                <div class="msg">
                    <p>New preprint, which is joint with @Maddie Cusimano. We worked with eight other research groups to create a multi-species benchmark for ML applications to fine-scale bio-logger data. We also tested a lot of methods (both previously proposed and new) for analyzing this type of data. All the code, data, and annotations are available for others to use ü¶ä. <a href="https://arxiv.org/abs/2305.10740">https://arxiv.org/abs/2305.10740</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2305.10740">A benchmark for computational analysis of animal behavior, using animal-borne tags</a></div>
                                <div class="link-text">
                                    Animal-borne sensors (&#39;bio-loggers&#39;) can record a suite of kinematic and
environmental data, which can elucidate animal ecophysiology and improve
conservation efforts. Machine learning techniques are useful for interpreting
the large amounts of data recorded by bio-loggers, but there exists no standard
for comparing the different machine learning techniques in this domain. To
address this, we present the Bio-logger Ethogram Benchmark (BEBE), a collection
of datasets with behavioral annotations, standardized modeling tasks, and
evaluation metrics. BEBE is to date the largest, most taxonomically diverse,
publicly available benchmark of this type, and includes 1654 hours of data
collected from 149 individuals across nine taxa. We evaluate the performance of
ten different machine learning methods on BEBE, and identify key challenges to
be addressed in future work. Datasets, models, and evaluation code are made
publicly available at &lt;https://github.com/earthspecies/BEBE&gt;, to enable community
use of BEBE as a point of comparison in methods development.
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2305.10740">
            <img class="preview" src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2305.10740</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üòç Sara Beery, Elie Alhajjar, Malte Pedersen, Yseult Hb, Juan Sebasti√°n Ca√±as Silva
                        </div>
                    
                        <div class="message-reaction">
                        üëç Maddie Cusimano, Dan Morris, Shir Bar, Dante Wasmuht, Cameron Trotter, Georgia Atkinson, Timm Haucke, Dan Stowell, Valentin Gabeff, Yseult Hb
                        </div>
                    
                        <div class="message-reaction">
                        üôå Santiago Martinez Balvanera, Oisin Mac Aodha, Jeremy Forest, Dan Stowell, Emilio Luz-Ricca
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-29 03:06:54">
            
                <img src="https://secure.gravatar.com/avatar/170f4f5f03087b25cc411f7758518241.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Stowell
                     <span class="print-only user-email">(dan.stowell@naturalis.nl)</span>
                </div>
                <a href="#2023-05-29 03:06:54"><div class="time">2023-05-29 03:06:54</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Ace. Thanks for putting this together! I will look into using this data in teaching. Would you say it's appropriate for that?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-05-29 08:21:31">
            
                <img src="https://avatars.slack-edge.com/2021-02-26/1801755617939_161ba9073fae1d586c9e_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Benjamin Hoffman
                     <span class="print-only user-email">(benjaminsshoffman@gmail.com)</span>
                </div>
                <a href="#2023-05-29 08:21:31"><div class="time">2023-05-29 08:21:31</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thank you! I think it would be. We formatted all the data in a consistent way, and most of the datasets are modestly sized by modern standards. So it would be easy for students to get started with the data and to run multiple experiments quickly.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Dan Stowell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-06-14 10:09:04">
            
                <img src="https://avatars.slack-edge.com/2019-11-12/817945634530_560bc5626fb464539496_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Hemal Naik
                     <span class="print-only user-email">(hnaik@ab.mpg.de)</span>
                </div>
                <a href="#2023-06-14 10:09:04"><div class="time">2023-06-14 10:09:04</div></a>
                <div class="msg">
                    <p>If some of you visit CVPR next week, do check out our new paper 3D-POP : An automated approach annotation approach to facilitate markerless 2D-3D tracking of freely moving birds with marker-based motion capture
Highlights:
A method to use mo-cap with birds for 3D posture
Dataset with 6Hrs of videos in different group sizes, 3D Posture with ground truth
Ground truth on Identity of each individual , other annotations: 2D locations, trajectory, 3D trajectory
Scene : Indoor with 4 views
Applications :</p>

<ol><li>Full 3D markerless tracking (position, trajectory, identitifaction) of pigeons in indoor environment</li><li>Hyrid tracking (Mocap + Markerless) </li><li>Geometry of birds wont change so potentially same model should work for birds in outdoor environment for lifting pose from 2D to 3D. 
Happy to chat more and collaborate.</li>
</ol>

<p>Video : <a href="https://www.youtube.com/watch?v=uGMsJ0qQZrA">https://www.youtube.com/watch?v=uGMsJ0qQZrA</a>
Link:
<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Naik_3D-POP_-_An_Automated_Annotation_Approach_to_Facilitate_Markerless_2D-3D_CVPR_2023_paper.pdf">https://openaccess.thecvf.com/content/CVPR2023/papers/Naik<em>3D-POP</em>-<em>An</em>Automated<em>Annota[‚Ä¶]pproach</em>to<em>Facilitate</em>Markerless<em>2D-3D</em>CVPR<em>2023</em>paper.pdf</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">YouTube</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="" class="icon">
                                    }
                                    <a href="https://www.youtube.com/@hmnaik">
                                    hemal naik
                                    </a><span class="print-only">(https://www.youtube.com/@hmnaik)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.youtube.com/watch?v=uGMsJ0qQZrA">3D-POP : Posture of Pigeon paper explained in 6 mins.</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                
    
        <a href="https://www.youtube.com/watch?v=uGMsJ0qQZrA">
            <img class="preview" src="https://i.ytimg.com/vi/uGMsJ0qQZrA/hqdefault.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.youtube.com/watch?v=uGMsJ0qQZrA</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üïäÔ∏è Oisin Mac Aodha, Malte Pedersen, Lukas Picek, Sara Beery, Blair Costelloe, Toryn Schafer, aruna, Yseult Hb
                        </div>
                    
                        <div class="message-reaction">
                        üëç Lukas Picek
                        </div>
                    
                        <div class="message-reaction">
                        üëè Silvia Zuffi
                        </div>
                    
                        <div class="message-reaction">
                        üòç Sara Beery
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-06-16 00:45:36">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-06-16 00:45:36"><div class="time">2023-06-16 00:45:36</div></a>
                <div class="msg">
                    <p>Not new, but topical with the discussion on few shot learning and how we move the community towards foundational models that adapt quickly. 
<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Phoo_Coarsely-Labeled_Data_for_Better_Few-Shot_Transfer_ICCV_2021_paper.pdf">https://openaccess.thecvf.com/content/ICCV2021/papers/Phoo_Coarsely-Labeled_Data_for_Better_Few-Shot_Transfer_ICCV_2021_paper.pdf</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery, Ankita Shukla, Felipe Montealegre-Mora, Enis Berk √áoban
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-06-23 14:35:17">
            
                <img src="https://avatars.slack-edge.com/2023-08-12/5729572396613_37c6726ad5d913013f67_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Aakash Gupta
                     <span class="print-only user-email">(aakash@thinkevolveconsulting.com)</span>
                </div>
                <a href="#2023-06-23 14:35:17"><div class="time">2023-06-23 14:35:17</div></a>
                <div class="msg">
                    <p>Shared areas in Africa and Asia where humans and big cats live together can sometimes lead to rare but notable cases of people being harmed or killed by lions, tigers, and leopards. Among these big cats, leopards are the most widespread and can be found even in areas with high human populations. This increases the chances of encounters between leopards and humans, resulting in attacks. India is a country where such attacks are common, with 50% of the states reporting injuries and deaths caused by leopards.</p>

<p>Himachal Pradesh (HP) state, for example, reported 30 fatal and 287 non-fatal attacks by leopards on humans each year between 2004 and 2015. By understanding the patterns of big cat attacks on people, we can develop targeted interventions to reduce these incidents. This study aims to determine if leopards are the main cause of injuries and deaths among humans by examining the following questions:
(a) do leopard attacks on humans happen in specific areas and at certain times?
(b) among these leopard attacks, do unprovoked attacks on humans cluster together in terms of location and time? and
(c) what environmental factors are associated with these clustered leopard attacks on humans?</p>

<p>The authors have used a statistical method commonly used in epidemiology called space-time permutation scan statistic to test for clustering of leopard attacks in specific areas and times. The attacks were scattered across 75% of HP, covering an area of approximately 42,000 square kilometers, in 11 out of 12 districts. We found that 23% of the attacks clustered into 12 significant spatio-temporal clusters. Around 14% of the leopard attacks were unprovoked, but these attacks did not form significant clusters.</p>

<p>The authors used statistical models to examine the relationship between eight environmental factors and the clustered attacks. They discovered that leopard attacks that occurred farther away from protected areas and closer to district boundaries had a higher likelihood of clustering. The approach developed by the authors helps identify outbreaks of unprovoked leopard attacks and confirms that there are no dedicated "man-eating" leopards in the study region. This approach can be useful in managing conflicts between humans and wildlife, and it demonstrates the usefulness of the scan statistic in ecological research.</p>

<p><a href="https://www.frontiersin.org/articles/10.3389/fcosc.2023.1157067/full">https://www.frontiersin.org/articles/10.3389/fcosc.2023.1157067/full</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Frontiers</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.frontiersin.org/articles/10.3389/fcosc.2023.1157067/full">Examining leopard attacks: spatio-temporal clustering of human injuries and deaths in Western Himalayas, India</a></div>
                                <div class="link-text">
                                    Shared spaces in Africa and Asia accommodate both humans and big cats. This engenders rare but distinctive cases of human fatalities by lions, tigers, and leopards. Among big cats, leopards have the widest range and occur even among high densities of humans. This increased potential for encounters with humans results in attacks, exemplified most by India where 50% of the states report human injuries and deaths due to leopards. Himachal Pradesh (HP) state reported 30 lethal and 287 non-lethal leopard attacks on humans per year between 2004 ‚Äì 2015 (N=317). Identifying patterns in big cat attacks on people facilitates targeted interventions for decreasing such fatalities. This study aims to detect if leopards are cluster-causing agents of human injuries and deaths. We identify the patterns of leopard attacks on humans in Himachal Pradesh by examining the following questions: (a) do leopard-attributed attacks on humans cluster in space and time? and among the leopard-attributed attacks (b) do unprovoked attacks on humans cluster spatio-temporally? and (c) what environmental factors are associated with the clustered leopard attacks on humans? We employed a space-time permutation scan statistic commonly used in epidemiology to test for spatio-temporal clustering of leopard attacks. Attacks were spread across 75% (~42,000 km sq.) of HP in 11 out of 12 districts. We found that 23% of attacks clustered into 12 significant spatio-temporal clusters. Nearly 14% of the leopard-attribut...
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://www.frontiersin.org/articles/10.3389/fcosc.2023.1157067/full</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-06-27 08:01:00">
            
                <img src="https://avatars.slack-edge.com/2022-10-11/4203870994483_c201360f475a1bd6a180_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Titus
                     <span class="print-only user-email">(titus@colossal.com)</span>
                </div>
                <a href="#2023-06-27 08:01:00"><div class="time">2023-06-27 08:01:00</div></a>
                <div class="msg">
                    <p>Hi everyone! I wanted to share the review we released today - ‚ÄúElephants and Algorithms: A Review of the Current and Future Role of AI in Elephant Monitoring‚Äù </p>

<p>We‚Äôd love your thoughts and feedback!
<a href="https://arxiv.org/abs/2306.13803">https://arxiv.org/abs/2306.13803</a></p>

<p>Abstract:
‚ÄúArtificial intelligence (AI) and machine learning (ML) present revolutionary opportunities to enhance our understanding of animal behavior and conservation strategies. Using elephants, a crucial species in Africa's protected areas, as our focal point, we delve into the role of AI and ML in their conservation. Given the increasing amounts of data gathered from a variety of sensors like cameras, microphones, geophones, drones, and satellites, the challenge lies in managing and interpreting this vast data. New AI and ML techniques offer solutions to streamline this process, helping us extract vital information that might otherwise be overlooked. This paper focuses on the different AI-driven monitoring methods and their potential for improving elephant conservation. Collaborative efforts between AI experts and ecological researchers are essential in leveraging these innovative technologies for enhanced wildlife conservation, setting a precedent for numerous other species.‚Äù</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2306.13803">Elephants and Algorithms: A Review of the Current and Future Role of AI in Elephant Monitoring</a></div>
                                <div class="link-text">
                                    Artificial intelligence (AI) and machine learning (ML) present revolutionary
opportunities to enhance our understanding of animal behavior and conservation
strategies. Using elephants, a crucial species in Africa&#39;s protected areas, as
our focal point, we delve into the role of AI and ML in their conservation.
Given the increasing amounts of data gathered from a variety of sensors like
cameras, microphones, geophones, drones, and satellites, the challenge lies in
managing and interpreting this vast data. New AI and ML techniques offer
solutions to streamline this process, helping us extract vital information that
might otherwise be overlooked. This paper focuses on the different AI-driven
monitoring methods and their potential for improving elephant conservation.
Collaborative efforts between AI experts and ecological researchers are
essential in leveraging these innovative technologies for enhanced wildlife
conservation, setting a precedent for numerous other species.
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2306.13803">
            <img class="preview" src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2306.13803</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêò Dan Morris, Shir Bar, Stefan Schneider, Andrew Schulz, Aakash Gupta, Rebecca Wilks, Emilio Luz-Ricca, Lucia Gordon
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-07-16 19:08:11">
            
                <img src="https://avatars.slack-edge.com/2023-07-17/5589806448180_29de367a7904a3aeef8c_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Andrew Schulz
                     <span class="print-only user-email">(akschulz@gatech.edu)</span>
                </div>
                <a href="#2023-07-16 19:08:11"><div class="time">2023-07-16 19:08:11</div></a>
                <div class="msg">
                    <p>Hi everyone! This may not fit (exactly) with this group. But I wanted to share a pre-print with everyone. This work aimed to show how important this field is and...it works. The big takeaway is that we surveyed and interviewed participants in an intradisciplinary setting and through a conservation technology course...Computer Scientists identify as stronger engineers, environmentalists, conservationists,....and even programmers &amp; biologists! It's awesome( not all were statistically significant...but still pretty impressive). <a href="https://www.biorxiv.org/content/10.1101/2023.07.03.546429v1">https://www.biorxiv.org/content/10.1101/2023.07.03.546429v1</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">bioRxiv</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.biorxiv.org/content/10.1101/2023.07.03.546429v1">Intradisciplinary Growth of Sustainability-Minded Engineers through Conservation Technology</a></div>
                                <div class="link-text">
                                    The need for sustainability-minded engineers prepared to address complex societal challenges has grown exponentially in recent years. Frameworks like the United Nations (UN) Sustainable Development Goals (SDGs) have begun to drive structural changes in engineering education, including new ABET accreditation focused on sustainability. The new field of conservation technology allows engineers to develop sustainability competencies and identities as conservationists and environmentalists.This manuscript describes an assessment of student identity development in conservation and environmentalism in the GaTech4Wildlife Vertically Integrated Project (VIP) course at Georgia Tech. The course uses the principles of Human-Centered Design along with the UN Sustainable Development Goals and project-based learning to solve conservation-oriented, real-world problems and develop sustainability-minded engineers. Undergraduate students participated in the course and utilizing both in-person interviews and post-course assessment, students were assessed for course themes and identities. The sample consisted of students from the College of Engineering and the College of Computing. Since 2019, over 50 students have participated in this Tech4Wildlife course. Based on surveys and interviews of nearly 20 of the most recent students, students transitioned from identifying as engineers and coders with no sustainability knowledge to nearly doubling their identity measures as conservationists and environmentalists after only one &lt;a href=&#34;http://semester.To&#34;&gt;semester.To&lt;/a&gt; teach the next generation of sustainability-minded engineers, interdisciplinary, project-based courses grounded in Sustainable Development Goals may offer a meaningful pathway for students to develop both technical skills and conservationist identities.

### Competing Interest Statement

The authors have declared no competing interest.
                                </div>
                                
                                
    
        <a href="https://www.biorxiv.org/content/10.1101/2023.07.03.546429v1">
            <img class="preview" src="https://www.biorxiv.org/sites/default/files/images/biorxiv_logo_homepage7-5-small.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.biorxiv.org/content/10.1101/2023.07.03.546429v1</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Stephanie O&#39;Donnell, Sara Beery, Shir Bar, Timm Haucke, Mikey Tabak, Emilio Luz-Ricca
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-07-27 11:54:55">
            
                <img src="https://secure.gravatar.com/avatar/170f4f5f03087b25cc411f7758518241.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Stowell
                     <span class="print-only user-email">(dan.stowell@naturalis.nl)</span>
                </div>
                <a href="#2023-07-27 11:54:55"><div class="time">2023-07-27 11:54:55</div></a>
                <div class="msg">
                    <p>4 pieces of recent research from my amazing students and postdocs <a href="http://mcld.co.uk/blog/2023/recent-research-from-my-amazing-students-and-postdocs.html">http://mcld.co.uk/blog/2023/recent-research-from-my-amazing-students-and-postdocs.html</a> A new crop of preprints üôÇ</p>
                    
                    
                    
                        <div class="message-reaction">
                        üîà Oisin Mac Aodha, Justin Kay, Enis Berk √áoban, Aleksis Pirinen
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Suzanne Stathatos, Carly Batist, Matt Weldy, Cameron Trotter, Maddie Cusimano, Enis Berk √áoban, Rita Pucci, Emilio Luz-Ricca, Aleksis Pirinen, Sara Beery, Yseult Hb, Dan Morris, Andrew Schulz
                        </div>
                    
                        <div class="message-reaction">
                        üëç Maddie Cusimano, Shivam Shrotriya
                        </div>
                    
                        <div class="message-reaction">
                        üëè Silvia Zuffi
                        </div>
                    
                        <div class="message-reaction">
                        üôå John Martinsson
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-09-04 07:32:32">
            
                <img src="https://avatars.slack-edge.com/2019-11-12/817945634530_560bc5626fb464539496_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Hemal Naik
                     <span class="print-only user-email">(hnaik@ab.mpg.de)</span>
                </div>
                <a href="#2023-09-04 07:32:32"><div class="time">2023-09-04 07:32:32</div></a>
                <div class="msg">
                    <p>Hi everyone, sharing our latest work on 3D tracking animals in a large environment. Tracking insects, birds and mammals with high precision 3D (marker based, markerless and acoustic tracking) for open and closed loop experiments that can be designed for multiple questions with wide range of species.</p>

<p>A short youtube introduction can be found here : <a href="https://www.youtube.com/watch?v=X9RjxY2AZWs">https://www.youtube.com/watch?v=X9RjxY2AZWs</a>, and the paper is in Science Advances can be downloaded from here :  <a href="https://www.science.org/doi/10.1126/sciadv.adf8068">https://www.science.org/doi/10.1126/sciadv.adf8068</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">YouTube</div>
                            
                                <div class="attachment-author">
                                    
                                        <img src="" class="icon">
                                    }
                                    <a href="https://www.youtube.com/@hmnaik">
                                    hemal naik
                                    </a><span class="print-only">(https://www.youtube.com/@hmnaik)</span>
                                </div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.youtube.com/watch?v=X9RjxY2AZWs">SMART-BARN: Scalable Multimodal Arena for Real-time Tracking    Behavior of Animals in laRge Numbers</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                
    
        <a href="https://www.youtube.com/watch?v=X9RjxY2AZWs">
            <img class="preview" src="https://i.ytimg.com/vi/X9RjxY2AZWs/hqdefault.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.youtube.com/watch?v=X9RjxY2AZWs</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëè Silvia Zuffi, Yseult Hb, Sara Beery, Fagner Cunha, Andrew Schulz, Malte Pedersen, Steve Haddock
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-09-07 17:21:17">
            
                <img src="https://avatars.slack-edge.com/2023-04-04/5075175490321_889000869582b1ab11ce_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Felipe Montealegre-Mora
                     <span class="print-only user-email">(felimomo@berkeley.edu)</span>
                </div>
                <a href="#2023-09-07 17:21:17"><div class="time">2023-09-07 17:21:17</div></a>
                <div class="msg">
                    <p>Hi all!</p>

<p>Our new paper on reinforcement learning (RL) and complex ecological control problems is published! Check it out here:</p>

<p><em>Pretty darn good control: When are are Approximate Solutions Better than Approximate Models.</em>
<em>F. Montealegre-Mora, M. Lapeyrolerie, M. Chapman, A. G. Keller, C. Boettiger</em>
Link to <a href="https://link.springer.com/article/10.1007/s11538-023-01198-5">publication</a>, link to <a href="https://arxiv.org/pdf/2308.13654.pdf">arXiv pre-print</a>, and link to <a href="https://github.com/boettiger-lab/approx-model-or-approx-soln">source code</a>.</p>

<p>We study the adaptive fishery management problem: given estimates of stock sizes for several species in a food web, decide the intensity with which to fish each species. We show that RL-based policies are more responsive to the system's dynamics compared to standard alternatives (MSY and constant escapement strategies). This leads to a higher long-term profitability <em>and</em> a lower chance of events such as near-extinctions in our simulations.</p>

<p>There is much to be said and done still before RL can be incorporated into adaptive management decisions, of course. We'd love to generate some discussion around the topic, and all feedback is super welcome!</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">SpringerLink</div>
                            
                            
                                
                                <div class="link-title"><a href="https://link.springer.com/article/10.1007/s11538-023-01198-5">Pretty Darn Good Control: When are Approximate Solutions Better than Approximate Models</a></div>
                                <div class="link-text">
                                    Bulletin of Mathematical Biology - Existing methods for optimal control struggle to deal with the complexity commonly encountered in real-world systems, including dimensionality, process error,...
                                </div>
                                
                                
    
        <a href="https://link.springer.com/article/10.1007/s11538-023-01198-5">
            <img class="preview" src="https://static-content.springer.com/cover/journal/11538/85/10.jpg"
                width="153"
                 height="232" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://link.springer.com/article/10.1007/s11538-023-01198-5</div>
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">boettiger-lab/approx-model-or-approx-soln</a></div>
                                <div class="link-text">
                                    When is an approximate solution to a more realistic model better than an optimal solution to a highly stylized one?
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        3
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        TeX
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêü Cameron Trotter, Yseult Hb, Sepand Dyanatkar, Cassie Buhler, Emilio Luz-Ricca, Justin Kay
                        </div>
                    
                        <div class="message-reaction">
                        üëç Justin Kay
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-03 10:30:23">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2023-11-03 10:30:23"><div class="time">2023-11-03 10:30:23</div></a>
                <div class="msg">
                    <p>We have released species labels for 81 species for the 100 million crown dataset in the National Ecological Observatory Network. Accuracy varies by site and length of local species list, but is generally around 70% for most sites using a hierarchical multi-temporal mixture of experts model with spectral attention (described previously here <a href="https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1002/rse2.335">https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1002/rse2.335</a>). The preprint for the tree maps is now up on biorxiv: <a href="https://www.biorxiv.org/content/10.1101/2023.10.25.563626v1.full.pdf">https://www.biorxiv.org/content/10.1101/2023.10.25.563626v1.full.pdf</a>. Dataset is here: <a href="https://zenodo.org/records/10067302">https://zenodo.org/records/10067302</a> and on Earth Engine (updating to v2 today). The data release also contains pre-cropped HSI numpy arrays for about 40,000 trees. I will be making a more formal machine learning ready dataset soon.  The model code is not fully reproducible due to the immense size of the underlying data, but is still open here: <a href="https://github.com/weecology/DeepTreeAttention/tree/species_release">https://github.com/weecology/DeepTreeAttention/tree/species_release</a>. The tree maps on earth engine can also be overlayed over other lower resolution remote sensing products , like NAIP on earth engine, and be used for pretraining across wide range of tree ecosystems. If you are a expert in earth engine and want to make this happen, let me know. Paper is being submitted to PLOS Biology. Remaining interesting machine learning problems include domain transfer among years and sensor calibration settings, handling class imbalance in a non-hierarchical model, and self-cleaning for incorrect label detection in both train and test. We welcome all uses of the data and models for machine learning and ecological applications.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Zenodo</div>
                            
                            
                                
                                <div class="link-title"><a href="https://zenodo.org/records/10067302">NEON Tree Species Predictions</a></div>
                                <div class="link-text">
                                    Individual Tree Predictions for 80 million trees in the National Ecological Observatory NetworkFor site abbreviations see:¬†&lt;https://www.neonscience.org/field-sites/explore-field-sitesFor&gt; each site, there is a .zip and .csv. The .zip is a set 1km .shp tiles. The .csv is all trees in a single file.Please see the manuscript for detailed methods.SummaryWe use¬†the DeepForest python package to predict individual crown location in the RGB camera mosaic (Weinstein et al. 2020a). Tree crowns with less than 3m maximum height in the LiDAR derived canopy height model are removed. At this stage in the workflow each individual tree has a unique ID, predicted crown location, crown area and confidence score from the DeepForest tree detection model. Following individual tree detection, we classify each individual as Alive or Dead based on the appearance in the RGB data. Since NEON captures airborne data during the leaf-on season, any standing tree with no leaf cover was annotated as &#39;dead&#39;. During prediction, the location of each predicted crown is cropped and passed to the Alive-Dead model for labeling as each Alive (0) or Dead (1) with a confidence score for each class.¬†To classify each tree crown to species we use the multi-temporal hierarchical model in Weinstein et al. 2023. Using the best trained model for each site we predict all available areas within the NEON AOP footprint that have overlapping RGB data for crown prediction and hyperspectral data for species prediction. The predicted species label confidence score, as well labels from the higher levels are included in the shapefile.¬†Column NameDefinitionGeometryA four pointed bounding box location in utm coordinates.indiv_idA unique crown identifier that combines the year, site and geoindex of the NEON airborne tile (e.g. 732000_4707000) is the utm coordinate of the top left of the tile.¬†sci_nameThe full latin name of predicted species aligned with NEON&#39;s taxonomic nomenclature.¬†ens_scoreThe confidence score of the species prediction. This score is the output of the multi-temporal model for the ensemble hierarchical model.¬†bleaf_taxaHighest predicted category for the broadleaf modelbleaf_scoreThe confidence score for the broadleaf taxa submodel¬†oak_taxaHighest predicted category for the oak model¬†dead_labelA two class alive/dead classification based on the RGB data. 0=Alive/1=Dead.dead_scoreThe confidence score of the Alive/Dead prediction.¬†site_idThe four letter code for the NEON site. See &lt;https://www.neonscience.org/field-sites/explore-field-sites&gt; for site locations.conif_taxaHighest predicted category for the conifer modelconif_scoreThe confidence score for the conifer taxa submodeldom_taxaHighest predicted category for the dominant taxa mode submodeldom_scoreThe confidence score for the dominant taxa submodel
                                </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                    <div class="print-only">Original URL: https://zenodo.org/records/10067302</div>
                                
                                
                            
                        </div>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üòç Sara Beery, Elie Alhajjar, Timm Haucke, Carly Batist, Suzanne Stathatos, Oisin Mac Aodha
                        </div>
                    
                        <div class="message-reaction">
                        üå≥ Nico Lang, Elie Alhajjar, Benjamin Hoffman, Omiros Pantazis, Urs, Shir Bar, Timm Haucke, Carly Batist, Suzanne Stathatos, Dan Morris, Wenxin Yang, Andr√©s C Rodr√≠guez, Toryn Schafer
                        </div>
                    
                        <div class="message-reaction">
                        üôå Emily Lines, Elie Alhajjar, Emilio Luz-Ricca, Alan Stenhouse, Sepand Dyanatkar
                        </div>
                    
                        <div class="message-reaction">
                        üëç Justin Kay
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-15 05:08:06">
            
                <img src="https://avatars.slack-edge.com/2023-11-15/6198197594674_5ce00fda6fdf290ac90e_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Titus
                     <span class="print-only user-email">(titus@theinvivogroup.com)</span>
                </div>
                <a href="#2023-11-15 05:08:06"><div class="time">2023-11-15 05:08:06</div></a>
                <div class="msg">
                    <p>Our review of AI for elephant monitoring came out today!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üêò Oisin Mac Aodha, Blair Costelloe, Cameron Trotter, Carly Batist, Sara Beery, Suzanne Stathatos, Yseult Hb, Dan Morris, Pen-Yuan Hsing, Rebecca Wilks
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-15 18:25:19">
            
                <img src="https://secure.gravatar.com/avatar/9b7d7691fb1ec5a21074a99921be2f86.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Steve Haddock
                     <span class="print-only user-email">(haddock@mbari.org)</span>
                </div>
                <a href="#2023-11-15 18:25:19"><div class="time">2023-11-15 18:25:19</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* &gt; <strong>Declaration of AI use</strong>
&gt; Yes, we have used AI-assisted technologies in creating this article. 
üòâ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-15 05:10:11">
            
                <img src="https://avatars.slack-edge.com/2023-11-15/6198197594674_5ce00fda6fdf290ac90e_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Titus
                     <span class="print-only user-email">(titus@theinvivogroup.com)</span>
                </div>
                <a href="#2023-11-15 05:10:11"><div class="time">2023-11-15 05:10:11</div></a>
                <div class="msg">
                    <p><a href="https://royalsocietypublishing.org/doi/10.1098/rsif.2023.0367">https://royalsocietypublishing.org/doi/10.1098/rsif.2023.0367</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-11-15 05:10:51">
            
                <img src="https://avatars.slack-edge.com/2023-11-15/6198197594674_5ce00fda6fdf290ac90e_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Titus
                     <span class="print-only user-email">(titus@theinvivogroup.com)</span>
                </div>
                <a href="#2023-11-15 05:10:51"><div class="time">2023-11-15 05:10:51</div></a>
                <div class="msg">
                    <p>‚ÄúElephants and algorithms: a review of the current and future role of AI in elephant monitoring</p>

<p>Leandra Brickson , Libby Zhang , Fritz Vollrath , Iain Douglas-Hamilton  and Alexander J. Titus‚Äù</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Justin Kay
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-12-01 17:43:02">
            
                <img src="https://secure.gravatar.com/avatar/f048f92dc51a0e1b63d63be1405a4e37.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0000-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Nathan Jacobs
                     <span class="print-only user-email">(jacobsn@wustl.edu)</span>
                </div>
                <a href="#2023-12-01 17:43:02"><div class="time">2023-12-01 17:43:02</div></a>
                <div class="msg">
                    <p>Our first paper working with species observation data will be presented at WACV 2024: <em>BirdSAT: Cross-View Contrastive Masked Autoencoders for Bird Species Classification and Mapping</em></p>

<p>arXiv: <a href="https://arxiv.org/pdf/2310.19168v1.pdf">https://arxiv.org/pdf/2310.19168v1.pdf</a>
Code: <a href="https://github.com/mvrl/BirdSAT">https://github.com/mvrl/BirdSAT</a>
Lead author: <a href="https://sites.wustl.edu/srikumarsastry/">https://sites.wustl.edu/srikumarsastry/</a>
Social media hype: <a href="https://www.linkedin.com/posts/jacobsn_ive-been-wanting-to-do-something-with-inaturalist-activity-7125481632219754496-0QM8?utm_source=share&amp;utm_medium=member_desktop|https://www.linkedin.com/posts/jacobsn_ive-been-wanting-to-do-something-with-inatural[‚Ä¶]632219754496-0QM8?utm_source=share&amp;utm_medium=member_desktop">https://www.linkedin.com/posts/jacobsn<em>ive-been-wanting-to-do-something-with-inaturalist-activity-7125481632219754496-0QM8?utm</em>source=share&amp;utm<em>medium=member</em>desktop|https://www.linkedin.com/posts/jacobsn<em>ive-been-wanting-to-do-something-with-inatural[‚Ä¶]632219754496-0QM8?utm</em>source=share&amp;utm<em>medium=member</em>desktop</a></p>

<p>Happy to discuss.</p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">mvrl/BirdSAT</a></div>
                                <div class="link-text">
                                    A PyTorch implementation of &#34;BirdSAT: Cross-View Contrastive Masked Autoencoders for Bird Species Classification and Mapping&#34;
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Website</div>
                                        &lt;https://sites.wustl.edu/srikumarsastry/birdsat/&gt;
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        2
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Suzanne Stathatos, Sara Beery, Dante Wasmuht, Timm Haucke, Emilio Luz-Ricca
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-12-11 14:15:12">
            
                <img src="https://secure.gravatar.com/avatar/9b7d7691fb1ec5a21074a99921be2f86.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Steve Haddock
                     <span class="print-only user-email">(haddock@mbari.org)</span>
                </div>
                <a href="#2023-12-11 14:15:12"><div class="time">2023-12-11 14:15:12</div></a>
                <div class="msg">
                    <p>BioCLIP Tree of life project...
<a href="https://imageomics.github.io/bioclip/">https://imageomics.github.io/bioclip/</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein, Robin Zbinden, Cameron Trotter, Andrew Schulz, Emilio Luz-Ricca, Sam Stevens
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-12-14 19:59:37">
            
                <img src="https://avatars.slack-edge.com/2021-04-30/2023568692212_f6aa1057696f5b133848_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Barry Brook
                     <span class="print-only user-email">(barry.brook@utas.edu.au)</span>
                </div>
                <a href="#2023-12-14 19:59:37"><div class="time">2023-12-14 19:59:37</div></a>
                <div class="msg">
                    <p>We have released a new preprint and would like feedback from users who want to train a customised AI model for wildlife-image classification!</p>

<p><strong>A user-friendly AI workflow for customised wildlife-image classification</strong></p>

<p>Monitoring wildlife is crucial for making informed conservation and land-management decisions. Remotely triggered cameras are widely used for this, but the resulting 'big data' are laborious to process. Artificial intelligence (AI) offers a solution to this bottleneck, but it has been challenging for ecologists and practitioners to tailor current approaches to their specific use cases. Generic, online offerings also have issues of ongoing costs and data privacy. Here we present an open-source, scalable, modular, cross-platform workflow, deployed using Docker, which leverages deep learning for wildlife-image classification. Run via a user-friendly command-line interface, our workflow democratises the implementation of AI for wildlife-image classification enabling end-users without specialised technical expertise to execute a full range of tasks‚Äîfrom animal detection to species prediction‚Äîon local or cloud GPU-accelerated machines. It integrates seamlessly with the widely used open-source camera-trapping software ‚ÄòCamelot‚Äô, writing AI-classification data directly to image metadata and to CSV files, ready for either expert verification or direct data analysis. The end result is an advanced but accessible pipeline for wildlife-image classification. A case study with Tasmanian wildlife demonstrates the utility of our end-to-end pipeline, from classifier training to inference.</p>

<p><a href="https://doi.org/10.32942/X2ZW3D">https://doi.org/10.32942/X2ZW3D</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery, Fagner Cunha
                        </div>
                    
                        <div class="message-reaction">
                        üëÄ Aran Dasan
                        </div>
                    
                        <div class="message-reaction">
                        üëç:skin_tone_3: Alan Stenhouse
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2023-12-17 00:34:11">
            
                <img src="https://avatars.slack-edge.com/2023-12-05/6293495957653_b94076ee446fdfa7cf83_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Piotr Tynecki
                     <span class="print-only user-email">(piotr@tynecki.pl)</span>
                </div>
                <a href="#2023-12-17 00:34:11"><div class="time">2023-12-17 00:34:11</div></a>
                <div class="msg">
                    <p><strong><a href="https://zslpublications.onlinelibrary.wiley.com/doi/10.1002/rse2.374">Camtrap DP: an open standard for the FAIR exchange and archiving of camera trap data (2023)</a></strong></p>

<p><a href="https://camtrap-dp.tdwg.org/">https://camtrap-dp.tdwg.org/</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">camtrap-dp.tdwg.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://camtrap-dp.tdwg.org/">Camtrap DP</a></div>
                                <div class="link-text">
                                    Data exchange format for camera trap data
                                </div>
                                
                                
    
        <a href="https://camtrap-dp.tdwg.org/">
            <img class="preview" src="https://camtrap-dp.tdwg.org/assets/home.jpg"
                width="1920"
                 height="768" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://camtrap-dp.tdwg.org/</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚úÖ Pen-Yuan Hsing, Anton Alvarez
                        </div>
                    
                        <div class="message-reaction">
                        ‚≠ê Dan Stowell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-05 16:20:33">
            
                <img src="https://secure.gravatar.com/avatar/f508b05f1d02b82040ea456ac87aba08.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Elly Knight
                     <span class="print-only user-email">(ecknight@ualberta.ca)</span>
                </div>
                <a href="#2024-01-05 16:20:33"><div class="time">2024-01-05 16:20:33</div></a>
                <div class="msg">
                    <p>New paper out from the Bayne lab and the Alberta Biodiversity Monitoring Institute on the effects of audio file compression! Likely of interest to folks who use deep learning on large acoustic datasets. We examined CNN recognizers in our exploration of MP3 compression and sample rate, with some interesting and complex effects.</p>

<p>OA paper here: <a href="https://www.tandfonline.com/doi/full/10.1080/09524622.2023.2290718?src=exp-la">https://www.tandfonline.com/doi/full/10.1080/09524622.2023.2290718?src=exp-la</a></p>

<p>Twitter synthesis here: <a href="https://twitter.com/ellycknight/status/1743374262407450775">https://twitter.com/ellycknight/status/1743374262407450775</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üîà Oisin Mac Aodha
                        </div>
                    
                        <div class="message-reaction">
                        üëè Matt Weldy, Carly Batist, Georgia Atkinson, Dan Morris, Enis Berk √áoban
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-05 19:06:51">
            
                <img src="https://avatars.slack-edge.com/2021-10-20/2615548747079_59b98294fae6beb7bd0b_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carl Boettiger
                     <span class="print-only user-email">(cboettig@berkeley.edu)</span>
                </div>
                <a href="#2024-01-05 19:06:51"><div class="time">2024-01-05 19:06:51</div></a>
                <div class="msg">
                    <p>Really happy to see this Policy Forum piece out this week in Science on "Biodiversity monitoring for a just planetary future" -- led by @Millie Chapman and bringing together co-authors from across ecology, computer science, sociology, geography and other disciplines. <a href="https://www.science.org/doi/10.1126/science.adh8874">https://www.science.org/doi/10.1126/science.adh8874</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üôå Sara Beery, Justin Kay, Yseult Hb, Dan Morris, Casey Youngflesh, Lauren Harrell
                        </div>
                    
                        <div class="message-reaction">
                        üëç Wenxin Yang
                        </div>
                    
                        <div class="message-reaction">
                        üôå:skin_tone_3: Alan Stenhouse
                        </div>
                    
                        <div class="message-reaction">
                        üëÄ Meredith Palmer
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-17 18:32:32">
            
                <img src="https://avatars.slack-edge.com/2024-01-17/6482985197270_8db7af3007d6980c9897_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Jarrett Blair
                     <span class="print-only user-email">(jarrettblair@gmail.com)</span>
                </div>
                <a href="#2024-01-17 18:32:32"><div class="time">2024-01-17 18:32:32</div></a>
                <div class="msg">
                    <p>For people looking to apply computer vision classification to their work but don't know where to start, we published a methods-guide paper for you! "A gentle introduction to computer vision-based specimen classification in ecological datasets" <a href="http://doi.org/10.1111/1365-2656.14042">http://doi.org/10.1111/1365-2656.14042</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üôå Michael Procko, Justin Kay, Suzanne Stathatos, Yseult Hb, Shir Bar, Meredith Palmer, Phuc Le, Steve Haddock, Ed Miller, Lauren Harrell, Ben Williams, Felipe Montealegre-Mora, Wenxin Yang
                        </div>
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Elly Knight, Shir Bar, Aran Dasan, Leonardo Viotti, Meredith Palmer
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-22 17:48:52">
            
                <img src="https://avatars.slack-edge.com/2021-04-15/1963481415669_4a6a5b352f18847c3614_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">David Will
                     <span class="print-only user-email">(david.will@islandconservation.org)</span>
                </div>
                <a href="#2024-01-22 17:48:52"><div class="time">2024-01-22 17:48:52</div></a>
                <div class="msg">
                    <p>Hi all - wanted to share our new paper on using hyperspectral data to detect animals based on their spectral signature rather than their shape. There is very little existing research about the application of hyperspectral data for wildlife and this is a first of a kind assessment of the utility of very high resolution drone-derived spectral data and ai models for terrestrial wildlife detection.</p>

<p><a href="https://www.mdpi.com/2072-4292/16/2/406">https://www.mdpi.com/2072-4292/16/2/406</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">MDPI</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.mdpi.com/2072-4292/16/2/406">Automated Hyperspectral Feature Selection and Classification of Wildlife Using Uncrewed Aerial Vehicles</a></div>
                                <div class="link-text">
                                    Timely and accurate detection and estimation of animal abundance is an important part of wildlife management. This is particularly true for invasive species where cost-effective tools are needed to enable landscape-scale surveillance and management responses, especially when targeting low-density populations residing in dense vegetation and under canopies. This research focused on investigating the feasibility and practicality of using uncrewed aerial systems (UAS) and hyperspectral imagery (HSI) to classify animals in the wild on a spectral‚Äîrather than spatial‚Äîbasis, in the hopes of developing methods to accurately classify animal targets even when their form may be significantly obscured. We collected HSI of four species of large mammals reported as invasive species on islands: cow (Bos taurus), horse (Equus caballus), deer (Odocoileus virginianus), and goat (Capra hircus) from a small UAS. Our objectives of this study were to (a) create a hyperspectral library of the four mammal species, (b) study the efficacy of HSI for animal classification by only using the spectral information via statistical separation, (c) study the efficacy of sequential and deep learning neural networks to classify the HSI pixels, (d) simulate five-band multispectral data from HSI and study its effectiveness for automated supervised classification, and (e) assess the ability of using HSI for invasive wildlife detection. Image classification models using sequential neural networks and one-dimensional convolutional neural networks were developed and tested. The results showed that the information from HSI derived using dimensionality reduction techniques were sufficient to classify the four species with class F1 scores all above 0.85. The performances of some classifiers were capable of reaching an overall accuracy over 98%and class F1 scores above 0.75, thus using only spectra to classify animals to species from existing sensors is feasible. This study discovered various challenges associated with the use of HSI for animal detection, particularly intra-class and seasonal variations in spectral reflectance and the practicalities of collecting and analyzing HSI data over large meaningful areas within an operational context. To make the use of spectral data a practical tool for wildlife and invasive animal management, further research into spectral profiles under a variety of real-world conditions, optimization of sensor spectra selection, and the development of on-board real-time analytics are needed.
                                </div>
                                
                                
    
        <a href="https://www.mdpi.com/2072-4292/16/2/406">
            <img class="preview" src="https://pub.mdpi-res.com/img/journals/remotesensing-logo-social.png?33ab614e9661caf2"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.mdpi.com/2072-4292/16/2/406</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëè Dan Morris
                        </div>
                    
                        <div class="message-reaction">
                        üëç Aakash Gupta
                        </div>
                    
                        <div class="message-reaction">
                        üôå Rebecca Wilks
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-23 09:32:43">
            
                <img src="https://avatars.slack-edge.com/2020-06-09/1197266804320_df3cb0235dd3aee97857_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Carly Batist
                     <span class="print-only user-email">(cbatist@gradcenter.cuny.edu)</span>
                </div>
                <a href="#2024-01-23 09:32:43"><div class="time">2024-01-23 09:32:43</div></a>
                <div class="msg">
                    <p>New paper on ecoacoustics + ML pipeline for detecting lemurs in Madagascar, and also comparisons to in-person obs &amp; manual analysis (time, cost, etc.)! With @Emmanuel Dufourq @Lor√®ne Jeantet &amp; more üôÇ
<a href="https://onlinelibrary.wiley.com/doi/10.1002/ajp.23599">https://onlinelibrary.wiley.com/doi/10.1002/ajp.23599</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üéâ Blair Costelloe, Felipe Parodi, Robin Zbinden, Shir Bar, Dan Morris, Mark Goldwater, Gracie Ermi, Taiki Sakai - NOAA Affiliate, Meredith Palmer, Omiros Pantazis, Georgia Atkinson, Yseult Hb, Andrew Schulz, Ankita Shukla
                        </div>
                    
                        <div class="message-reaction">
                        üîà Rowan Converse
                        </div>
                    
                        <div class="message-reaction">
                        üôå John Martinsson, Meredith Palmer
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-24 03:06:34">
            
                <img src="https://secure.gravatar.com/avatar/5b5dcdb7f88b12dd2f114e4c2568e73f.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Meredith Palmer
                     <span class="print-only user-email">(meredith.palmer@fauna-flora.org)</span>
                </div>
                <a href="#2024-01-24 03:06:34"><div class="time">2024-01-24 03:06:34</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Congrats!!</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Carly Batist
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-25 14:07:01">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2024-01-25 14:07:01"><div class="time">2024-01-25 14:07:01</div></a>
                <div class="msg">
                    <p>This is the first paper I've seen to put a dollar value not only on the benefits of AI for camera trap image processing, but also on the benefits of using connected cameras (and demonstrating the cost + carbon benefits of not constantly visiting cameras):</p>

<p><a href="https://www.researchsquare.com/article/rs-3637685/v1">https://www.researchsquare.com/article/rs-3637685/v1</a></p>

<p>The platform being evaluated was eVorta:</p>

<p><a href="https://web.evorta.com/">https://web.evorta.com/</a></p>

<p>I don't know whether any of the authors or any of the eVorta devs are on this Slack, but if you are, great work!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Justin Kay, Carly Batist, Malte Pedersen, Shir Bar, Sara Beery, Timm Haucke, Piotr Tynecki, Barry Brook, Aakash Gupta, Omiros Pantazis, Chris Lange, Dante Wasmuht, Tiziana Gelmi Candusso, David Will, Lauren Harrell, Anton Alvarez
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-30 04:45:32">
            
                <img src="https://secure.gravatar.com/avatar/8506d912aad282c3247f4196b17cef3e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0007-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Emily Lines
                     <span class="print-only user-email">(erl27@cam.ac.uk)</span>
                </div>
                <a href="#2024-01-30 04:45:32"><div class="time">2024-01-30 04:45:32</div></a>
                <div class="msg">
                    <p>Food for thought, we hope, for this community: <a href="https://www.nature.com/articles/s41561-023-01369-y">https://www.nature.com/articles/s41561-023-01369-y</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Nature</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nature.com/articles/s41561-023-01369-y">Prioritize environmental sustainability in use of AI and data science methods</a></div>
                                <div class="link-text">
                                    Nature Geoscience - Artificial Intelligence (AI) and data science will play a crucial role in improving environmental sustainability, but the energy requirements of these methods will have an...
                                </div>
                                
                                
    
        <a href="https://www.nature.com/articles/s41561-023-01369-y">
            <img class="preview" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41561-023-01369-y/MediaObjects/41561_2023_1369_Fig1_HTML.png"
                width="1062"
                 height="251" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nature.com/articles/s41561-023-01369-y</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Justine Boulent
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-30 12:39:19">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2024-01-30 12:39:19"><div class="time">2024-01-30 12:39:19</div></a>
                <div class="msg">
                    <p><a href="https://www.mdpi.com/2076-3417/13/18/10397">https://www.mdpi.com/2076-3417/13/18/10397</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">MDPI</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.mdpi.com/2076-3417/13/18/10397">WAID: A Large-Scale Dataset for Wildlife Detection with Drones</a></div>
                                <div class="link-text">
                                    Drones are widely used for wildlife monitoring. Deep learning algorithms are key to the success of monitoring wildlife with drones, although they face the problem of detecting small targets. To solve this problem, we have introduced the SE-YOLO model, which incorporates a channel self-attention mechanism into the advanced real-time object detection algorithm YOLOv7, enabling the model to perform effectively on small targets. However, there is another barrier; the lack of publicly available UAV wildlife aerial datasets hampers research on UAV wildlife monitoring algorithms. To fill this gap, we present a large-scale, multi-class, high-quality dataset called WAID (Wildlife Aerial Images from Drone), which contains 14,375 UAV aerial images from different environmental conditions, covering six wildlife species and multiple habitat types. We conducted a statistical analysis experiment, an algorithm detection comparison experiment, and a dataset generalization experiment. The statistical analysis experiment demonstrated the dataset characteristics both quantitatively and intuitively. The comparison and generalization experiments compared different types of advanced algorithms as well as the SE-YOLO method from the perspective of the practical application of UAVs for wildlife monitoring. The experimental results show that WAID is suitable for the study of wildlife monitoring algorithms for UAVs, and SE-YOLO is the most effective in this scenario, with a mAP of up to 0.983. This study brings new methods, data, and inspiration to the field of wildlife monitoring by UAVs.
                                </div>
                                
                                
    
        <a href="https://www.mdpi.com/2076-3417/13/18/10397">
            <img class="preview" src="https://pub.mdpi-res.com/img/journals/applsci-logo-social.png?8600e93ff98dbf14"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.mdpi.com/2076-3417/13/18/10397</div>
                                
                                
                            
                        </div>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-30 13:58:03">
            
                <img src="https://avatars.slack-edge.com/2022-08-26/4012029248913_f5ad71b1fb3bf7118c8b_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Caleb Robinson
                     <span class="print-only user-email">(calebrob6@gmail.com)</span>
                </div>
                <a href="#2024-01-30 13:58:03"><div class="time">2024-01-30 13:58:03</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* looks like a cool dataset, but mAP of 0.983 seems <em>really</em> high</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-30 13:58:40">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2024-01-30 13:58:40"><div class="time">2024-01-30 13:58:40</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* ya, I wasn't particularly happy with the paper, just posting so we can keep track of data. @Dan Morris</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-30 17:38:19">
            
                <img src="https://avatars.slack-edge.com/2021-01-11/1652047804128_8216640d1f5e36e41ef5_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Dan Morris
                     <span class="print-only user-email">(agentmorris@gmail.com)</span>
                </div>
                <a href="#2024-01-30 17:38:19"><div class="time">2024-01-30 17:38:19</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Oh, you know me too well, @Ben Weinstein, new datasets I can tinker with always make my day.  Added to the Big List O' Aerial Datsets, with sample code:</p>

<p><a href="https://github.com/agentmorris/agentmorrispublic/blob/main/drone-datasets.md#waid-wildlife-aerial-images-from-drone">https://github.com/agentmorris/agentmorrispublic/blob/main/drone-datasets.md#waid-wildlife-aerial-images-from-drone</a></p>

<p>Caveat: even when I paged through just a few images, to pick a thumbnail, I noticed that (a) not all images are completely annotated, and (b) many of the objects labeled "camelus" are... definitely not (but the boxes were still spatially accurate).  Also images seem to have been forced to square aspect ratios, so animals are generally squished in one dimension.  And if I looked at 0.01% of the dataset and noticed all that, the issues are likely somewhat widespread.  But data is never perfect, and I still think it's good enough to be useful overall, and it was very straightforward to work with, so, a net positive.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Ben Weinstein
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-01-31 07:34:17">
            
                <img src="https://avatars.slack-edge.com/2022-08-26/4012029248913_f5ad71b1fb3bf7118c8b_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Caleb Robinson
                     <span class="print-only user-email">(calebrob6@gmail.com)</span>
                </div>
                <a href="#2024-01-31 07:34:17"><div class="time">2024-01-31 07:34:17</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* It seems they did uniform random train/val/test splits, which makes it certain that some frames from the same video would be in both train and test</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-02-08 17:47:22">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2024-02-08 17:47:22"><div class="time">2024-02-08 17:47:22</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Plus this one is about goats. <a href="https://www.nature.com/articles/s41597-023-02555-8">https://www.nature.com/articles/s41597-023-02555-8</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Nature</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nature.com/articles/s41597-023-02555-8">CherryCh√®vre: A fine-grained dataset for goat detection in natural environments</a></div>
                                <div class="link-text">
                                    Scientific Data - CherryCh√®vre: A fine-grained dataset for goat detection in natural environments
                                </div>
                                
                                
    
        <a href="https://www.nature.com/articles/s41597-023-02555-8">
            <img class="preview" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41597-023-02555-8/MediaObjects/41597_2023_2555_Fig1_HTML.png"
                width="1500"
                 height="374" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nature.com/articles/s41597-023-02555-8</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üêê Dan Morris
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-14 08:06:43">
            
                <img src="https://avatars.slack-edge.com/2022-02-10/3079007120838_2256d6dbf14428a3afc4_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Devis Tuia
                     <span class="print-only user-email">(devis.tuia@epfl.ch)</span>
                </div>
                <a href="#2024-03-14 08:06:43"><div class="time">2024-03-14 08:06:43</div></a>
                <div class="msg">
                    <p>3D reconstruction and semantic segmentation of coral reefs! Fresh from the press at ME&amp;E: <a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.14307">https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.14307</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üåä Oisin Mac Aodha, Valentin Gabeff, Robin Zbinden, Gracie Ermi, Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëè Viktor Domazetoski, Robin Zbinden, Urs
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-15 05:38:15">
            
                <img src="https://avatars.slack-edge.com/2022-02-10/3079007120838_2256d6dbf14428a3afc4_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Devis Tuia
                     <span class="print-only user-email">(devis.tuia@epfl.ch)</span>
                </div>
                <a href="#2024-03-15 05:38:15"><div class="time">2024-03-15 05:38:15</div></a>
                <div class="msg">
                    <p>Mapping forests in the Swiss Alps since the 1940s: semantic segmentation and knowledge-guided deep learning help us building the time machine and show how much the treeline moves upwards in time: <a href="https://www.sciencedirect.com/science/article/pii/S0034425724001202">https://www.sciencedirect.com/science/article/pii/S0034425724001202</a> Super work by @Thi√™n-Anh Nguyen</p>
                    
                    
                    
                        <div class="message-reaction">
                        üå≤ Robin Zbinden, Shir Bar, Sara Beery, Gracie Ermi, Wenxin Yang
                        </div>
                    
                        <div class="message-reaction">
                        üëè Robin Zbinden, Shir Bar, Viktor Domazetoski, Tiziana Gelmi Candusso
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-15 19:45:22">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2024-03-15 19:45:22"><div class="time">2024-03-15 19:45:22</div></a>
                <div class="msg">
                    <p>Whenever I give a talk, I always stress that we are looking to complement traditional forest surveys with airborne information. I often offhand say there will never be a time in which robots will walk through forests identifying trees....<a href="https://ora.ox.ac.uk/objects/uuid:d29224bc-f133-484f-b8eb-f99fb34b6eb3/files/sx920fz468">https://ora.ox.ac.uk/objects/uuid:d29224bc-f133-484f-b8eb-f99fb34b6eb3/files/sx920fz468</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        ü§ñ Dan Morris, Chase Van Amburg, annie finneran, Yseult Hb, Anton Alvarez, Shir Bar, Omiros Pantazis, Carly Batist, Sara Beery, Gracie Ermi, Urs, Emilio Luz-Ricca, Sepand Dyanatkar, Alan Stenhouse
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-19 13:43:21">
            
                <img src="https://secure.gravatar.com/avatar/7db3e7381155cf9a7e36e7074397f08e.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Swayam Thakkar
                     <span class="print-only user-email">(swayamt1302@gmail.com)</span>
                </div>
                <a href="#2024-03-19 13:43:21"><div class="time">2024-03-19 13:43:21</div></a>
                <div class="msg">
                    <p>Excited to share our paper on individual identification of sloth bears (Melursus ursinus) using SSIM and Deep Learning !!
<a href="https://link.springer.com/article/10.1007/s42991-023-00396-x">https://link.springer.com/article/10.1007/s42991-023-00396-x</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">SpringerLink</div>
                            
                            
                                
                                <div class="link-title"><a href="https://link.springer.com/article/10.1007/s42991-023-00396-x">Bear biometrics: developing an individual recognition technique for sloth bears</a></div>
                                <div class="link-text">
                                    Mammalian Biology - Identifying individual animals, especially in large mammals, is an important goal for wildlife biologists and managers. Bears, occupying diverse habitats, face and experience...
                                </div>
                                
                                
    
        <a href="https://link.springer.com/article/10.1007/s42991-023-00396-x">
            <img class="preview" src="https://static-content.springer.com/image/art%3A10.1007%2Fs42991-023-00396-x/MediaObjects/42991_2023_396_Fig1_HTML.jpg"
                width="967"
                 height="667" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://link.springer.com/article/10.1007/s42991-023-00396-x</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Anton Alvarez, Sara Beery, Cameron Trotter, Majid Mirmehdi, Valentin Gabeff
                        </div>
                    
                        <div class="message-reaction">
                        üëè Aran Dasan, Ishan Nangia, Tiziana Gelmi Candusso
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-19 16:48:08">
            
                <img src="https://secure.gravatar.com/avatar/29bb5bfa2f4fc413cf2e1adfb3a5ebb9.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0015-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Majid Mirmehdi
                     <span class="print-only user-email">(m.mirmehdi@bristol.ac.uk)</span>
                </div>
                <a href="#2024-03-19 16:48:08"><div class="time">2024-03-19 16:48:08</div></a>
                <div class="msg">
                    <p>PanAf20K: A Large Video Dataset for Wild Ape Detection and Behaviour Recognition</p>

<p>Paper: <a href="https://link.springer.com/article/10.1007/s11263-024-02003-z">https://link.springer.com/article/10.1007/s11263-024-02003-z</a>
Project Website: <a href="https://obrookes.github.io/panaf.github.io/">https://obrookes.github.io/panaf.github.io/</a>
Dataset:  <a href="https://data.bris.ac.uk/data/dataset/1h73erszj3ckn2qjwm4sqmr2wt">PanAf20K AI-enabled Video Dataset of Great Apes in the Wild - Datasets - data.bris</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="None"></a></div>
                            
                                
    
        <!-- no preview available -->
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëè Timm Haucke, Felipe Parodi, Dante Wasmuht, Anton Alvarez, Dan Morris, Sara Beery, Valentin Gabeff, Cameron Trotter, Robin Zbinden, Hugo Magaldi, Sepand Dyanatkar
                        </div>
                    
                        <div class="message-reaction">
                        üëç Otto Brookes
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-03-22 11:37:40">
            
                <img src="https://secure.gravatar.com/avatar/170f4f5f03087b25cc411f7758518241.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Stowell
                     <span class="print-only user-email">(dan.stowell@naturalis.nl)</span>
                </div>
                <a href="#2024-03-22 11:37:40"><div class="time">2024-03-22 11:37:40</div></a>
                <div class="msg">
                    <p>New paper from us - training efficient small neural nets for @Benjamin Cretois‚Äôs "ecoVAD" task <a href="https://www.mdpi.com/1424-8220/24/7/2046">https://www.mdpi.com/1424-8220/24/7/2046</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">MDPI</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.mdpi.com/1424-8220/24/7/2046">Efficient Speech Detection in Environmental Audio Using Acoustic Recognition and Knowledge Distillation</a></div>
                                <div class="link-text">
                                    The ongoing biodiversity crisis, driven by factors such as land-use change and global warming, emphasizes the need for effective ecological monitoring methods. Acoustic monitoring of biodiversity has emerged as an important monitoring tool. Detecting human voices in soundscape monitoring projects is useful both for analyzing human disturbance and for privacy filtering. Despite significant strides in deep learning in recent years, the deployment of large neural networks on compact devices poses challenges due to memory and latency constraints. Our approach focuses on leveraging knowledge distillation techniques to design efficient, lightweight student models for speech detection in bioacoustics. In particular, we employed the MobileNetV3-Small-Pi model to create compact yet effective student architectures to compare against the larger EcoVAD teacher model, a well-regarded voice detection architecture in eco-acoustic monitoring. The comparative analysis included examining various configurations of the MobileNetV3-Small-Pi-derived student models to identify optimal performance. Additionally, a thorough evaluation of different distillation techniques was conducted to ascertain the most effective method for model selection. Our findings revealed that the distilled models exhibited comparable performance to the EcoVAD teacher model, indicating a promising approach to overcoming computational barriers for real-time ecological monitoring.
                                </div>
                                
                                
    
        <a href="https://www.mdpi.com/1424-8220/24/7/2046">
            <img class="preview" src="https://pub.mdpi-res.com/img/journals/sensors-logo-social.png?8600e93ff98dbf14"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.mdpi.com/1424-8220/24/7/2046</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üîä Oisin Mac Aodha, Dan Morris, Anton Alvarez
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Sam Lapp
                        </div>
                    
                        <div class="message-reaction">
                        üëç Maddie Cusimano
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-04-23 11:02:20">
            
                <img src="https://avatars.slack-edge.com/2023-12-05/6293495957653_b94076ee446fdfa7cf83_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Piotr Tynecki
                     <span class="print-only user-email">(piotr@tynecki.pl)</span>
                </div>
                <a href="#2024-04-23 11:02:20"><div class="time">2024-04-23 11:02:20</div></a>
                <div class="msg">
                    <p><strong><a href="https://www.nature.com/articles/s43247-024-01325-7">The conservation value of forests can be predicted at the scale of 1 hectare</a> (2024)</strong></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Nature</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nature.com/articles/s43247-024-01325-7">The conservation value of forests can be predicted at the scale of 1 hectare</a></div>
                                <div class="link-text">
                                    Communications Earth &amp;amp; Environment - Decreased availability of plant substrate can explain the decline in autotrophic respiration at constant temperature during the night, according to a simple...
                                </div>
                                
                                
    
        <a href="https://www.nature.com/articles/s43247-024-01325-7">
            <img class="preview" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs43247-024-01325-7/MediaObjects/43247_2024_1325_Fig1_HTML.png"
                width="1750"
                 height="2488" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nature.com/articles/s43247-024-01325-7</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üå≥ Dan Morris, Valentin Gabeff
                        </div>
                    
                        <div class="message-reaction">
                        üå¥ Chris Lange
                        </div>
                    
                        <div class="message-reaction">
                        üëç Leonardo Viotti
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-04-26 13:17:21">
            
                <img src="https://avatars.slack-edge.com/2021-02-05/1721385555875_8385898c48bfbbcb6e4c_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Declan
                     <span class="print-only user-email">(declan.pizzino@consbio.org)</span>
                </div>
                <a href="#2024-04-26 13:17:21"><div class="time">2024-04-26 13:17:21</div></a>
                <div class="msg">
                    <p>The positive impact of conservation action
<a href="https://www.science.org/doi/10.1126/science.adj6598">https://www.science.org/doi/10.1126/science.adj6598</a></p>

<p><a href="https://phys.org/news/2024-04-kind-actions-effective-halting-reversing.html">https://phys.org/news/2024-04-kind-actions-effective-halting-reversing.html</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">phys.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://phys.org/news/2024-04-kind-actions-effective-halting-reversing.html">First-of-its-kind study shows that conservation actions are effective at halting and reversing biodiversity loss</a></div>
                                <div class="link-text">
                                    A study published April 25, in the journal Science provides the strongest evidence to date that not only is nature conservation successful, but that scaling conservation interventions up would be transformational for halting and reversing biodiversity loss&amp;amp;mdash;a crisis that can lead to ecosystem collapses and a planet less able to support life&amp;amp;mdash;and reducing the effects of climate change.
                                </div>
                                
                                
    
        <a href="https://phys.org/news/2024-04-kind-actions-effective-halting-reversing.html">
            <img class="preview" src="https://scx2.b-cdn.net/gfx/news/hires/2024/first-of-its-kind-stud.jpg"
                width="2880"
                 height="1920" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://phys.org/news/2024-04-kind-actions-effective-halting-reversing.html</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üåä Ishan Nangia
                        </div>
                    
                        <div class="message-reaction">
                        üëç Chris Lange, Tiziana Gelmi Candusso
                        </div>
                    
                        <div class="message-reaction">
                        üöÄ Leonardo Viotti
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-05-09 16:07:29">
            
                <img src="https://avatars.slack-edge.com/2024-05-09/7080201993015_1fd377c8f60bb4364b09_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Jonathan Ventura
                     <span class="print-only user-email">(jventu09@calpoly.edu)</span>
                </div>
                <a href="#2024-05-09 16:07:29"><div class="time">2024-05-09 16:07:29</div></a>
                <div class="msg">
                    <p>Our paper on mapping California‚Äôs urban forest:
<a href="https://www.sciencedirect.com/science/article/pii/S1569843224002024">https://www.sciencedirect.com/science/article/pii/S1569843224002024</a></p>

<p>Explore our state-wide map of trees here:
<a href="https://jventu09.users.earthengine.app/view/urban-tree-detector">https://jventu09.users.earthengine.app/view/urban-tree-detector</a></p>
                    
                    
                    
                        <div class="message-reaction">
                        üå≥ Dan Morris, Sara Beery, Alan Stenhouse
                        </div>
                    
                        <div class="message-reaction">
                        üíØ Tiziana Gelmi Candusso, Ishan Nangia
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-05-10 13:31:12">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2024-05-10 13:31:12"><div class="time">2024-05-10 13:31:12</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Great paper! really glad to see both zero-shot and fine-tuned performance for DeepForest, let us know (<a href="https://github.com/weecology/DeepForest/issues">https://github.com/weecology/DeepForest/issues</a>), if there is anything about the workflow that could make it easier to serve as a baseline.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-05-10 15:40:05">
            
                <img src="https://avatars.slack-edge.com/2024-05-09/7080201993015_1fd377c8f60bb4364b09_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Jonathan Ventura
                     <span class="print-only user-email">(jventu09@calpoly.edu)</span>
                </div>
                <a href="#2024-05-10 15:40:05"><div class="time">2024-05-10 15:40:05</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks, Ben!  Was pretty straightforward to test out DeepForest on our data ‚Äî only issue was that we had point annotations so we had to devise some strategies to figure out how to train and test with a bounding box model.  I don‚Äôt know if others would fine it useful but I would be happy to share our code for that.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-05-11 03:22:58">
            
                <img src="https://avatars.slack-edge.com/2023-11-26/6271497607856_ed052afd9c0eaaf11da0_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Casey Clifton
                     <span class="print-only user-email">(caseyclifton@proton.me)</span>
                </div>
                <a href="#2024-05-11 03:22:58"><div class="time">2024-05-11 03:22:58</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Great stuff! Is the annotated training data publicly available?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-05-11 11:42:20">
            
                <img src="https://avatars.slack-edge.com/2024-05-09/7080201993015_1fd377c8f60bb4364b09_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Jonathan Ventura
                     <span class="print-only user-email">(jventu09@calpoly.edu)</span>
                </div>
                <a href="#2024-05-11 11:42:20"><div class="time">2024-05-11 11:42:20</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks!  It is, you can find the data here: <a href="https://github.com/jonathanventura/urban-tree-detection-data">https://github.com/jonathanventura/urban-tree-detection-data</a>
and the code here: <a href="https://github.com/jonathanventura/urban-tree-detection">https://github.com/jonathanventura/urban-tree-detection</a></p>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">jonathanventura/urban-tree-detection-data</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        28
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Last updated</div>
                                        3 days ago
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    <div class="message-attachment"
                            style="border-color: #24292f">
                            
                            
                            
                                
                                <div class="link-title"><a href="">jonathanventura/urban-tree-detection</a></div>
                                <div class="link-text">
                                    
                                </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Stars</div>
                                        46
                                    </div>
                                
                                    <div class="attachment-field">
                                        <div class="field-title">Language</div>
                                        Python
                                    </div>
                                
                                
    
        <!-- no preview available -->
    
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Casey Clifton
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-05-31 08:10:09">
            
                <img src="https://avatars.slack-edge.com/2022-02-10/3079007120838_2256d6dbf14428a3afc4_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Devis Tuia
                     <span class="print-only user-email">(devis.tuia@epfl.ch)</span>
                </div>
                <a href="#2024-05-31 08:10:09"><div class="time">2024-05-31 08:10:09</div></a>
                <div class="msg">
                    <p>Are you looking for species distribution maps for trees? Look no further! We have 10K of those for you (and estimates of distribution in 2100 as well!)
Check out our latest paper, with @Nina van Tiel in the lead: <a href="https://www.nature.com/articles/s41467-024-48276-3">https://www.nature.com/articles/s41467-024-48276-3</a></p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Nature</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nature.com/articles/s41467-024-48276-3">Regional uniqueness of tree species composition and response to forest loss and climate change</a></div>
                                <div class="link-text">
                                    Nature Communications - This study maps global tree composition in forests and assesses the impacts of historical forest cover loss and climate change. The results highlight the need for preserving...
                                </div>
                                
                                
    
        <a href="https://www.nature.com/articles/s41467-024-48276-3">
            <img class="preview" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41467-024-48276-3/MediaObjects/41467_2024_48276_Fig1_HTML.png"
                width="2028"
                 height="1083" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nature.com/articles/s41467-024-48276-3</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Sara Beery, Justin Kay, Timm Haucke, Robin Zbinden, Ben Weinstein, Nico Lang, Lauren Harrell, Chris Lange, Helena Russello, Catherine Villeneuve, Emilio Luz-Ricca, Millie Chapman, Valerie
                        </div>
                    
                        <div class="message-reaction">
                        üå≥ Ishan Nangia, Valentin Gabeff, Sam Lapp, Alan Stenhouse
                        </div>
                    
                        <div class="message-reaction">
                        üå¥ Chris Lange
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-05 14:26:59">
            
                <img src="https://secure.gravatar.com/avatar/1f4c833e8cd844b19615f8e6f5a51303.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Masato Hagiwara
                     <span class="print-only user-email">(hagisan@gmail.com)</span>
                </div>
                <a href="#2024-06-05 14:26:59"><div class="time">2024-06-05 14:26:59</div></a>
                <div class="msg">
                    <p>üåü Introducing BirdAVES: Our Latest Bird Sound Foundation Model üåü</p>

<p>We are thrilled to announce the release of our latest series of self-supervised animal vocalization encoder (AVES) models, named BirdAVES, specifically scaled and trained for bird sounds.</p>

<p>ü§ñFoundation models like GPTs have played a pivotal role in the AI revolution over the past few years. ESP has been heavily investing in the development of foundation models, and we released the first-ever discriminative foundation model, AVES, for animal vocalization last year. Trained through self-supervision, AVES can encode a wide range of animal vocalizations, achieving significant performance gains in many bioacoustic datasets and tasks.</p>

<p>ü¶úIn this iteration, we focused on bird vocalizations, as they are one of the best-studied and well-resourced types of animal vocalization in bioacoustics. Bird sounds have a wide range of ecological, behavioral, and conservation implications through behavioral studies, population monitoring, and habitat analysis.</p>

<p>üöÄWe significantly scaled up the training of AVES in terms of training data, model size, and compute power, as it has been shown that the scaling law of foundation models apply across many domains of machine learning.</p>

<p>üìàThe newly trained BirdAVES models have achieved over a 20% performance improvement on bird datasets and have shown enhanced performance across various other datasets as well.</p>

<p>Check out our pretrained models here: <a href="https://github.com/earthspecies/aves?tab=readme-ov-file#birdaves">https://github.com/earthspecies/aves?tab=readme-ov-file#birdaves</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="https://files.slack.com/files-pri/TM808NB0D-F0774F3M86M/birdaves.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc">BirdAVES.png</a></div>
                            
                                
    
        <a href="https://files.slack.com/files-pri/TM808NB0D-F0774F3M86M/birdaves.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc">
            <img class="preview" src="https://files.slack.com/files-tmb/TM808NB0D-F0774F3M86M-fe2801071e/birdaves_360.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc"
                width="360"
                 height="235" />
        </a>
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëç Carly Batist, Gaspard Dussert, Matt Weldy, Ben Weinstein, Robin Zbinden, Ritwik
                        </div>
                    
                        <div class="message-reaction">
                        ü¶â Shir Bar, Alan Stenhouse
                        </div>
                    
                        <div class="message-reaction">
                        üéâ Sam Lapp
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-17 08:39:41">
            
                <img src="https://secure.gravatar.com/avatar/6e7ea2578d2e0749f4cd906c84852a52.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0004-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Gaspard Dussert
                     <span class="print-only user-email">(gaspard.dussert@gmail.com)</span>
                </div>
                <a href="#2024-06-17 08:39:41"><div class="time">2024-06-17 08:39:41</div></a>
                <div class="msg">
                    <p>Can the confidence scores produced by your species classification model be interpreted as probabilities?
Check out my first paper to find out!  <a href="https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1002/rse2.412">https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1002/rse2.412</a>
(with @Simon Chamaill√© and @Vincent Miele CNRS)</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Dante Wasmuht, Sara Si-Moussi, Dan Morris, Omiros Pantazis, Chris Lange, Valentin Gabeff, Emilio Luz-Ricca
                        </div>
                    
                        <div class="message-reaction">
                        üëÄ Ishan Nangia, Taiki Sakai - NOAA Affiliate, Timm Haucke
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-17 09:33:49">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2024-06-17 09:33:49"><div class="time">2024-06-17 09:33:49</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Quick skim was super interesting! Great stuff. I didn't see any analysis of how calibration breaks down by class imbalance.
<code>Furthermore, we have focused our work on the calibration of the top-1 label on a multiclass classification task, and with a relatively small number of classes. But in future work, it would also be interesting to look at the calibration of the predictions on other tasks of interest for models applied to ecology. For instance, calibration could be explored in multi-label classification, hierarchical classification, object detection or classification over a very large number of classes.</code>
Do you anticipate that the calibration of the rarest of the 22nd classes would be worse? We have found decreasing reasonableness of confidence scores as classes is rarer in the dataset.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-17 10:16:31">
            
                <img src="https://secure.gravatar.com/avatar/6e7ea2578d2e0749f4cd906c84852a52.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0004-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Gaspard Dussert
                     <span class="print-only user-email">(gaspard.dussert@gmail.com)</span>
                </div>
                <a href="#2024-06-17 10:16:31"><div class="time">2024-06-17 10:16:31</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thank you very much! I didn't look in detail at the calibration by class, and in particular for the under-represented classes because I ended up with too few predictions in each bin to correctly estimate the ECE. So unfortunately I don't have an answer to your question!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-17 10:17:50">
            
                <img src="https://secure.gravatar.com/avatar/6e7ea2578d2e0749f4cd906c84852a52.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0004-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Gaspard Dussert
                     <span class="print-only user-email">(gaspard.dussert@gmail.com)</span>
                </div>
                <a href="#2024-06-17 10:17:50"><div class="time">2024-06-17 10:17:50</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* But perhaps I could try grouping together the rare classes to calculate the ECE</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-17 12:08:27">
            
                <img src="https://secure.gravatar.com/avatar/f508b05f1d02b82040ea456ac87aba08.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Elly Knight
                     <span class="print-only user-email">(ecknight@ualberta.ca)</span>
                </div>
                <a href="#2024-06-17 12:08:27"><div class="time">2024-06-17 12:08:27</div></a>
                <div class="msg">
                    <p>Review &amp; recommendations for individual ID in acoustic recordings! We argue this field needs a lot of attention from you fine folks in the deep learning world to truly open doors. Check out the twitter thread here (<a href="https://x.com/ellycknight/status/1802719544261165206">https://x.com/ellycknight/status/1802719544261165206</a>) for a plain-language summary and the paper here (<a href="https://authors.elsevier.com/a/1jEmtcZ3X04sY">https://authors.elsevier.com/a/1jEmtcZ3X04sY</a>) for the technical recommendations! This was a big multidisciplinary effort with many folks including @Tessa Rhinehart @Justin Kitzes @Matt Weldy</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">X (formerly Twitter)</div>
                            
                            
                                
                                <div class="link-title"><a href="https://x.com/ellycknight/status/1802719544261165206">Elly Knight (@ellycknight) on X</a></div>
                                <div class="link-text">
                                    Acoustic individual identification, or &#34;AIID&#34; has the potential to open new frontiers in ecological &amp;amp; evolutionary research.

We reviewed &amp;amp; synthesized studies that identify individuals in acoustic recordings (&#34;AIID&#34;) and make some recommendations for next steps!

1/n
                                </div>
                                
                                
    
        <a href="https://x.com/ellycknight/status/1802719544261165206">
            <img class="preview" src="https://pbs.twimg.com/profile_images/931545064978890752/CK77gSPE_200x200.jpg"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://x.com/ellycknight/status/1802719544261165206</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Justin Kay, Georgia Atkinson, Taiki Sakai - NOAA Affiliate
                        </div>
                    
                        <div class="message-reaction">
                        üôå Carly Batist, Sara Beery
                        </div>
                    
                        <div class="message-reaction">
                        üëç:skin_tone_2: Cara Appel
                        </div>
                    
                        <div class="message-reaction">
                        üôå:skin_tone_3: Alan Stenhouse
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-17 12:26:23">
            
                <img src="https://avatars.slack-edge.com/2023-06-29/5527341576752_de66af7025fe21d9109f_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Georgia Atkinson
                     <span class="print-only user-email">(g.atkinson@ncl.ac.uk)</span>
                </div>
                <a href="#2024-06-17 12:26:23"><div class="time">2024-06-17 12:26:23</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* I have just finished my PhD in the applications of deep learning to detect and classify dolphin signature whistles üê¨. I'm hoping to get some papers published from my research chapters and a dataset containing signature whistles to go with it!</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-17 12:27:33">
            
                <img src="https://secure.gravatar.com/avatar/f508b05f1d02b82040ea456ac87aba08.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Elly Knight
                     <span class="print-only user-email">(ecknight@ualberta.ca)</span>
                </div>
                <a href="#2024-06-17 12:27:33"><div class="time">2024-06-17 12:27:33</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Amazing! Looking forward to it @Georgia Atkinson! Check out the recommendations in the paper around storing datasets with the Environmental Data Initiative if you get a chance</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-17 12:27:58">
            
                <img src="https://avatars.slack-edge.com/2023-06-29/5527341576752_de66af7025fe21d9109f_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Georgia Atkinson
                     <span class="print-only user-email">(g.atkinson@ncl.ac.uk)</span>
                </div>
                <a href="#2024-06-17 12:27:58"><div class="time">2024-06-17 12:27:58</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* oh brilliant I will thanks!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Elly Knight
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-17 20:13:47">
            
                <img src="https://avatars.slack-edge.com/2023-06-22/5477501337601_ed0c1e1b182b69923cdd_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Risa Shinoda
                     <span class="print-only user-email">(shinoda.lisa.47z@gmail.com)</span>
                </div>
                <a href="#2024-06-17 20:13:47"><div class="time">2024-06-17 20:13:47</div></a>
                <div class="msg">
                    <p>Our ICIP2024 paper OpenAnimalTracks has been released !!
Identify animal species by their footprintsüë£
arXiv: <a href="https://arxiv.org/abs/2406.09647">https://arxiv.org/abs/2406.09647</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="https://files.slack.com/files-pri/TM808NB0D-F078FJMJ5EZ/_teaser.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc">_teaser.png</a></div>
                            
                                
    
        <a href="https://files.slack.com/files-pri/TM808NB0D-F078FJMJ5EZ/_teaser.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc">
            <img class="preview" src="https://files.slack.com/files-tmb/TM808NB0D-F078FJMJ5EZ-4af3cebea1/_teaser_360.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc"
                width="360"
                 height="125" />
        </a>
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëè »òtefan Istrate, Omiros Pantazis, Dan Morris, Tiziana Gelmi Candusso, Rebecca Wilks
                        </div>
                    
                        <div class="message-reaction">
                        üòç Steve Haddock
                        </div>
                    
                        <div class="message-reaction">
                        üëè:skin_tone_3: Alan Stenhouse
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-19 05:17:31">
            
                <img src="https://secure.gravatar.com/avatar/ab813615e32e36ff5a3f8fcedb4d485d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Alex Delplanque
                     <span class="print-only user-email">(alexandre.delplanque@uliege.be)</span>
                </div>
                <a href="#2024-06-19 05:17:31"><div class="time">2024-06-19 05:17:31</div></a>
                <div class="msg">
                    <p>Our latest research paper is published: a first semi-automated survey of African mammals using oblique imagery and deep learning üì∑üíªüêò <a href="https://www.researchgate.net/publication/381376237_Will_artificial_intelligence_revolutionize_aerial_surveys_A_first_large-scale_semi-automated_survey_of_African_wildlife_using_oblique_imagery_and_deep_learning">Click here</a> to access the full paper!</p>

<p>üîé In this study, we explored the synergy of a semi-automated deep learning model and oblique cameras for better estimation of large African mammal populations. Our research aimed to enhance the efficiency and accuracy of traditional systematic reconnaissance flights with rear-seat observers, which are widely used to monitor these populations.</p>

<p>üìà The proposed approach provided higher population estimates for small and static species and comparable estimates for larger ones. It required only 111 hours of human effort to process more than 190,000 images - a significant reduction compared to manual interpretation - making wildlife camera surveys more efficient and cost-effective.</p>

<p>üåü This study marks a significant step towards integrating AI in wildlife monitoring, suggesting a future shift to AI-assisted aerial surveys for greater efficiency and safety, especially with microlight aircraft.</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Dante Wasmuht, Robin Zbinden, Sara Beery, Dan Morris, Connor Levenson, Devis Tuia, Rebecca Wilks, Justine Boulent, Lucia Gordon
                        </div>
                    
                        <div class="message-reaction">
                        üëç:skin_tone_3: Alan Stenhouse
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-19 12:34:18">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2024-06-19 12:34:18"><div class="time">2024-06-19 12:34:18</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Is there any hope for the data, model weights, to be made available? Anything to contribute to the community to avoid future users to need repeat the annotation effort?</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-06-20 02:59:55">
            
                <img src="https://secure.gravatar.com/avatar/ab813615e32e36ff5a3f8fcedb4d485d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Alex Delplanque
                     <span class="print-only user-email">(alexandre.delplanque@uliege.be)</span>
                </div>
                <a href="#2024-06-20 02:59:55"><div class="time">2024-06-20 02:59:55</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* Thanks for the request, indeed it would be great but unfortunately the data is held by the park managers and cannot be shared with third parties.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-07-17 08:07:09">
            
                <img src="https://avatars.slack-edge.com/2024-08-02/7510233340197_2e10694603b688fab440_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Josh Veitch-Michaelis
                     <span class="print-only user-email">(j.veitchmichaelis@gmail.com)</span>
                </div>
                <a href="#2024-07-17 08:07:09"><div class="time">2024-07-17 08:07:09</div></a>
                <div class="msg">
                    <p>üå≥ Happy to report our global tree crown delineation dataset + paper (pre-print) is now live: <a href="https://arxiv.org/abs/2407.11743">https://arxiv.org/abs/2407.11743</a></p>

<p>üíæ You can find our code here: <a href="https://github.com/Restor-Foundation/tcd">https://github.com/Restor-Foundation/tcd</a>
ü§ó Our models and dataset are hosted on HuggingFace: <a href="https://huggingface.co/restor">https://huggingface.co/restor</a>; data are mirrored on Zenodo in MS-COCO JSON format: <a href="https://zenodo.org/records/11617167">https://zenodo.org/records/11617167</a>
üìö Documentation: <a href="https://restor-foundation.github.io/tcd/">https://restor-foundation.github.io/tcd/</a></p>

<p>üìî Colab example: <a href="https://colab.research.google.com/drive/1N_rWko6jzGji3j_ayDR7ngT5lf4P8at_">https://colab.research.google.com/drive/1N<em>rWko6jzGji3j</em>ayDR7ngT5lf4P8at_</a></p>

<p>There's still a lot to do and I'm actively working to improve the usability of the pipeline, but hopefully it's a useful resource for the community and after 2 and a bit years working on it, I'm excited (and exhausted) that it's finally public. Keen to get feedback if it's useful for anyone here and to answer questions üôÇ</p>

<p>‚ö†Ô∏è Limitations: see the supplementary info in the paper, but the main one is that we did not attempt (by design) to label every tree in dense/closed canopy, so in those situations you're better off using the semantic segmentation models (which agree well with LIDAR comparision). Instance segmentation will give you good image coverage, but if you need e.g. every tree in a rainforest you should look at packages like DetectTree2. The motivation for the work was to support restoration monitoring where we often care about (a) early stage projects pre- canopy closure and (b) later stage projects where often <em>coverage</em> is a more useful metric than counts. You can probably get a good first-order estimate for density estimation if you have a prior on crown size distribution for a particular site + the coverage %.</p>

<p>TL;DR: we're releasing an instance/semantic segmentation dataset containing over 280k individually delineated tree polygons and over 50k tree groups. Our images are sampled globally from high resolution (10 cm/px) orthomosaics from Open Aerial Map; over 90% are CC-BY 4.0 licensed with a small portion -NC or -SA. Code (Apache 2.0) and models are also public.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">arXiv.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://arxiv.org/abs/2407.11743">OAM-TCD: A globally diverse dataset of high-resolution tree cover maps</a></div>
                                <div class="link-text">
                                    Accurately quantifying tree cover is an important metric for ecosystem monitoring and for assessing progress in restored sites. Recent works have shown that deep learning-based segmentation algorithms are capable of accurately mapping trees at country and continental scales using high-resolution aerial and satellite imagery. Mapping at high (ideally sub-meter) resolution is necessary to identify individual trees, however there are few open-access datasets containing instance level annotations and those that exist are small or not geographically diverse. We present a novel open-access dataset for individual tree crown delineation (TCD) in high-resolution aerial imagery sourced from OpenAerialMap (OAM). Our dataset, OAM-TCD, comprises 5072 2048x2048 px images at 10 cm/px resolution with associated human-labeled instance masks for over 280k individual and 56k groups of trees. By sampling imagery from around the world, we are able to better capture the diversity and morphology of trees in different terrestrial biomes and in both urban and natural environments. Using our dataset, we train reference instance and semantic segmentation models that compare favorably to existing state-of-the-art models. We assess performance through k-fold cross-validation and comparison with existing datasets; additionally we demonstrate compelling results on independent aerial imagery captured over Switzerland and compare to municipal tree inventories and LIDAR-derived canopy maps in the city of Zurich. Our dataset, models and training/benchmark code are publicly released under permissive open-source licenses: Creative Commons (majority CC BY 4.0), and Apache 2.0 respectively.
                                </div>
                                
                                
    
        <a href="https://arxiv.org/abs/2407.11743">
            <img class="preview" src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://arxiv.org/abs/2407.11743</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëÄ Aria Ma
                        </div>
                    
                        <div class="message-reaction">
                        üå≥ Alan Stenhouse
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-07-18 12:17:01">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2024-07-18 12:17:01"><div class="time">2024-07-18 12:17:01</div></a>
                <div class="msg">
                    <p>Many of know about/are already using the data, but the official publication for the first NEON tree species prediction dataset is out in PLOS Biology. We released crown maps for 24 US forests for a total of 100 million crowns, classified to 81 canopy tree species. Predictions and training data are available on zenodo. <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002700">https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002700</a>. We use a hierarchical mixture of exports + temporal averaging + spectral attention for hyperspectral classification for each site. For those interested in challenging computer vision problems, the next steps are to find a single model across all sites that dynamically handles class imbalance, more sophisticated temporal ensembling, and better data augmentation and self-correction for misattributed samples.</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">journals.plos.org</div>
                            
                            
                                
                                <div class="link-title"><a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002700">Individual canopy tree species maps for the National Ecological Observatory Network</a></div>
                                <div class="link-text">
                                    Detailed maps of tree species can be used for forest analysis, biogeographic research and ecosystem monitoring. This study provides individual tree species maps for 24 sites in the United States National Ecological Observatory Network (NEON), covering 80 tree species and 100 million individuals.
                                </div>
                                
                                
    
        <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002700">
            <img class="preview" src="https://journals.plos.org/plosbiology/article/figure/image?id=10.1371/journal.pbio.3002700.g009&amp;size=inline"
                
                 />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002700</div>
                                
                                
                            
                        </div>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="https://files.slack.com/files-pri/TM808NB0D-F07D23LS41H/journal.pbio.3002700.g005.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc">journal.pbio.3002700.g005.PNG</a></div>
                            
                                
    
        <a href="https://files.slack.com/files-pri/TM808NB0D-F07D23LS41H/journal.pbio.3002700.g005.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc">
            <img class="preview" src="https://files.slack.com/files-tmb/TM808NB0D-F07D23LS41H-a48022e36e/journal.pbio.3002700.g005_360.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc"
                width="360"
                 height="273" />
        </a>
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üëè Timm Haucke, Robin Zbinden, Sam Lapp, Christine Laney
                        </div>
                    
                        <div class="message-reaction">
                        üå≥ Timm Haucke, Shir Bar, Dan Morris, Josh Veitch-Michaelis, Nina van Tiel, Sara Beery, Roberta Hunt, Emilio Luz-Ricca, Nico Lang, Sam Lapp, Alan Stenhouse
                        </div>
                    
                        <div class="message-reaction">
                        üöÄ Leonardo Viotti, Sam Lapp
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-07-19 04:39:10">
            
                <img src="https://avatars.slack-edge.com/2023-06-22/5477501337601_ed0c1e1b182b69923cdd_72.jpg" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Risa Shinoda
                     <span class="print-only user-email">(shinoda.lisa.47z@gmail.com)</span>
                </div>
                <a href="#2024-07-19 04:39:10"><div class="time">2024-07-19 04:39:10</div></a>
                <div class="msg">
                    <p>Introducing ‚ÄúPetFace: A Large-Scale Dataset and Benchmark for Animal Identification‚Äù (ECCV2024) !! üê¶</p>

<p>‚úÖ250k IDs (The largest ever!)
‚úÖ13 species
‚úÖFine-grained annotations</p>

<p>Website: <a href="https://dahlian00.github.io/PetFacePage/">https://dahlian00.github.io/PetFacePage/</a>
Paper: <a href="https://arxiv.org/abs/2407.13555">https://arxiv.org/abs/2407.13555</a></p>
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="https://files.slack.com/files-pri/TM808NB0D-F07D5RXG50T/image.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc">image.png</a></div>
                            
                                
    
        <a href="https://files.slack.com/files-pri/TM808NB0D-F07D5RXG50T/image.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc">
            <img class="preview" src="https://files.slack.com/files-tmb/TM808NB0D-F07D5RXG50T-53cdd96f0d/image_360.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc"
                width="360"
                 height="204" />
        </a>
    
                            
                        </div>
                    
                    
                        <div class="message-reaction">
                        üôå Josh Veitch-Michaelis, Roberta Hunt, Timm Haucke, Dan Morris, Connor Levenson, Dante Wasmuht, Sara Beery, Chris Lange
                        </div>
                    
                        <div class="message-reaction">
                        üëç Omiros Pantazis, Timm Haucke, Georgia Atkinson, Shir Bar, Rita Pucci, Otto Brookes
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-01 04:33:13">
            
                <img src="https://avatars.slack-edge.com/2021-03-23/1881693189366_9e10bd2ce0ea04fd1956_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Silvia Zuffi
                     <span class="print-only user-email">(silvia@mi.imati.cnr.it)</span>
                </div>
                <a href="#2024-08-01 04:33:13"><div class="time">2024-08-01 04:33:13</div></a>
                <div class="msg">
                    <p>I forgot to post here these last two works on horses: ‚ÄúThe Poses for Equine Research Dataset (PFERD)‚Äù (<a href="https://www.nature.com/articles/s41597-024-03312-1">https://www.nature.com/articles/s41597-024-03312-1</a>), where we do dense motion capture on horses, placing more than 100 markers, also capturing a wide range of poses (i.e. a sitting horse)</p>
                    <div class="message-attachment"
                            >
                            <div class="service-name">Nature</div>
                            
                            
                                
                                <div class="link-title"><a href="https://www.nature.com/articles/s41597-024-03312-1">The Poses for Equine Research Dataset (PFERD)</a></div>
                                <div class="link-text">
                                    Scientific Data - The Poses for Equine Research Dataset (PFERD)
                                </div>
                                
                                
    
        <a href="https://www.nature.com/articles/s41597-024-03312-1">
            <img class="preview" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41597-024-03312-1/MediaObjects/41597_2024_3312_Fig1_HTML.png"
                width="1500"
                 height="341" />
        </a>
    
                                
                                    <div class="print-only">Original URL: https://www.nature.com/articles/s41597-024-03312-1</div>
                                
                                
                            
                        </div>
                    
                    
                    
                        <div class="message-reaction">
                        üëè Malte Pedersen, Sara Beery, Chris Lange, Dan Morris, Roberta Hunt, Risa Shinoda
                        </div>
                    
                        <div class="message-reaction">
                        üêé Shir Bar, Andrew Schulz
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-01 04:38:46">
            
                <img src="https://avatars.slack-edge.com/2023-07-25/5629330214405_c9ffd65d99b302ec8496_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Malte Pedersen
                     <span class="print-only user-email">(mape@create.aau.dk)</span>
                </div>
                <a href="#2024-08-01 04:38:46"><div class="time">2024-08-01 04:38:46</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* We have a new PhD student starting today(!) on the topic of detecting pain in horses from their facial expressions. Thanks for sharing this dataset, may come in handy at some point ü¶Ñ</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-01 04:43:54">
            
                <img src="https://avatars.slack-edge.com/2021-03-23/1881693189366_9e10bd2ce0ea04fd1956_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Silvia Zuffi
                     <span class="print-only user-email">(silvia@mi.imati.cnr.it)</span>
                </div>
                <a href="#2024-08-01 04:43:54"><div class="time">2024-08-01 04:43:54</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* You‚Äôre welcome! All this work has been done with people from SLU and KTH and they are also interested in horse pain detection</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Malte Pedersen
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-01 12:41:25">
            
                <img src="https://avatars.slack-edge.com/2019-08-26/727564533250_4bda977d3f85f4f6fc06_72.jpg" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Amrita Gupta
                     <span class="print-only user-email">(agupta375@gatech.edu)</span>
                </div>
                <a href="#2024-08-01 12:41:25"><div class="time">2024-08-01 12:41:25</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* What a great name for the dataset! (üá©üá™ language learner here)</p>
                    
                    
                    
                        <div class="message-reaction">
                        üôÇ Dan Stowell
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-01 04:34:36">
            
                <img src="https://avatars.slack-edge.com/2021-03-23/1881693189366_9e10bd2ce0ea04fd1956_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Silvia Zuffi
                     <span class="print-only user-email">(silvia@mi.imati.cnr.it)</span>
                </div>
                <a href="#2024-08-01 04:34:36"><div class="time">2024-08-01 04:34:36</div></a>
                <div class="msg">
                    <p>And this one ‚ÄúVAREN: Very Accurate and Realistic Equine Network‚Äù, where we create an articulated 3D shape model of horses from 4D scans of real animals (<a href="https://varen.is.tue.mpg.de/">https://varen.is.tue.mpg.de/</a>).</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-01 10:37:20">
            
                <img src="https://secure.gravatar.com/avatar/5e1c5ddc888b49c919bcfd43e4b9cb3d.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Ben Weinstein
                     <span class="print-only user-email">(benweinstein2010@gmail.com)</span>
                </div>
                <a href="#2024-08-01 10:37:20"><div class="time">2024-08-01 10:37:20</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* really interesting. How accurate/designed for this purpose do the scans need to be? I've been toying with the idea of using museum specimen scans to try to make synthetic data for species detection.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-01 11:09:45">
            
                <img src="https://avatars.slack-edge.com/2021-03-23/1881693189366_9e10bd2ce0ea04fd1956_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Silvia Zuffi
                     <span class="print-only user-email">(silvia@mi.imati.cnr.it)</span>
                </div>
                <a href="#2024-08-01 11:09:45"><div class="time">2024-08-01 11:09:45</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* We tried that a long time ago and it did not work for us. The specimens we scanned in the museums had over smoothed and not realistic shapes.</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-01 11:10:07">
            
                <img src="https://avatars.slack-edge.com/2021-03-23/1881693189366_9e10bd2ce0ea04fd1956_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Silvia Zuffi
                     <span class="print-only user-email">(silvia@mi.imati.cnr.it)</span>
                </div>
                <a href="#2024-08-01 11:10:07"><div class="time">2024-08-01 11:10:07</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* We ended up scanning toys</p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-01 11:11:21">
            
                <img src="https://avatars.slack-edge.com/2021-03-23/1881693189366_9e10bd2ce0ea04fd1956_72.png" class="user_icon_reply" />
            
            
                <div class="reply">
            
                <div class="username">Silvia Zuffi
                     <span class="print-only user-email">(silvia@mi.imati.cnr.it)</span>
                </div>
                <a href="#2024-08-01 11:11:21"><div class="time">2024-08-01 11:11:21</div></a>
                <div class="msg">
                    <p><strong><em>*Thread Reply:</em></strong>* <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Zuffi_Three-D_Safari_Learning_to_Estimate_Zebra_Pose_Shape_and_Texture_ICCV_2019_paper.pdf">https://openaccess.thecvf.com/content_ICCV_2019/papers/Zuffi_Three-D_Safari_Learning_to_Estimate_Zebra_Pose_Shape_and_Texture_ICCV_2019_paper.pdf</a></p>
                    
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-01 04:36:27">
            
                <img src="https://avatars.slack-edge.com/2021-03-23/1881693189366_9e10bd2ce0ea04fd1956_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Silvia Zuffi
                     <span class="print-only user-email">(silvia@mi.imati.cnr.it)</span>
                </div>
                <a href="#2024-08-01 04:36:27"><div class="time">2024-08-01 04:36:27</div></a>
                <div class="msg">
                    
                    
                    <div class="message-upload">
                            <div class="link-title"><a href="https://files.slack.com/files-pri/TM808NB0D-F07F1FZRFTL/screenshot_2024-08-01_at_10.35.27.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc">Screenshot 2024-08-01 at 10.35.27.png</a></div>
                            
                                
    
        <a href="https://files.slack.com/files-pri/TM808NB0D-F07F1FZRFTL/screenshot_2024-08-01_at_10.35.27.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc">
            <img class="preview" src="https://files.slack.com/files-tmb/TM808NB0D-F07F1FZRFTL-958db7dbdc/screenshot_2024-08-01_at_10.35.27_360.png?t=xoxe-722008759013-7562008015927-7576556608226-c2910f7b7de02166d9ff289dd98396cc"
                width="296"
                 height="167" />
        </a>
    
                            
                        </div>
                    
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-04 13:00:36">
            
                <img src="https://avatars.slack-edge.com/2021-07-06/2270250594576_b26208ffe098b963d801_72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Zhongqi Miao
                     <span class="print-only user-email">(zhongqi.miao@berkeley.edu)</span>
                </div>
                <a href="#2024-08-04 13:00:36"><div class="time">2024-08-04 13:00:36</div></a>
                <div class="msg">
                    <p>Please check out our new paper on multimodal language models in biodiversity and conservation: <https://ecoevorxiv.org/repository/view/7477/#!|New frontiers in AI for biodiversity research and conservation with multimodal language models> ! Our paper provides a thorough yet accessible introduction to the capabilities and transformative potential of MML models in biodiversity
and conservation applications. Furthermore, we outline existing hurdles to implementing these techniques
in real-world scenarios and propose directions for future research to overcome these challenges. We aim to foster robust discussion with this paper and provide information for future research into the sustainable and equitable development of MML models as a potential paradigm shift in AI for biodiversity monitoring and conservation. It is currently in submission but any comments are welcome! Thank you very much!</p>
                    
                    
                    
                        <div class="message-reaction">
                        üå≥ Burak Ekim, Alan Stenhouse, Sara Beery, Sam Lapp, Lasha Otarashvili
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-05 02:36:33">
            
                <img src="https://secure.gravatar.com/avatar/196f705532a1917a16027477db802aa5.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0012-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Alan Stenhouse
                     <span class="print-only user-email">(alan.stenhouse@csiro.au)</span>
                </div>
                <a href="#2024-08-05 02:36:33"><div class="time">2024-08-05 02:36:33</div></a>
                <div class="msg">
                    <p>Nice work! Am working on multi-agent systems in natural history collections space so will take a close look. üôÇ Love the Koala and Antechinus examples! üê®</p>
                    
                    
                    
                        <div class="message-reaction">
                        ‚ù§Ô∏è Zhongqi Miao
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
                
                    <div class="message-container">
        <div id="2024-08-12 12:19:40">
            
                <img src="https://secure.gravatar.com/avatar/170f4f5f03087b25cc411f7758518241.jpg?s=72&amp;d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png" class="user_icon" />
            
            
                <div class="message">
            
                <div class="username">Dan Stowell
                     <span class="print-only user-email">(dan.stowell@naturalis.nl)</span>
                </div>
                <a href="#2024-08-12 12:19:40"><div class="time">2024-08-12 12:19:40</div></a>
                <div class="msg">
                    <p>I'm excited to share this research paper:
<strong>"Bird song comparison using deep learning trained from avian perceptual judgments"</strong>
Zandberg et al (2024), <em>Plos Computational Biology</em>
<a href="https://doi.org/10.1371/journal.pcbi.1012329">https://doi.org/10.1371/journal.pcbi.1012329</a>
We attempted something quite difficult: instead of using human labels, or unsupervised learning, to train machine learning on animal sounds -- can we train an algorithm directly from the birds' own perceptual judgments?
(Social media summary is <a href="https://mastodon.social/@danstowell/112949875984539676">here</a> on my mastodon)</p>
                    
                    
                    
                        <div class="message-reaction">
                        üëç Holger Klinck, Sara Beery, C√©line Angonin, Yseult Hb, Chris Lange, Enis Berk √áoban
                        </div>
                    
                        <div class="message-reaction">
                        üòÑ Maddie Cusimano
                        </div>
                    
                        <div class="message-reaction">
                        ‚≠ê Maddie Cusimano
                        </div>
                    
                        <div class="message-reaction">
                        üëÄ John Martinsson
                        </div>
                    
		</div>
            </div>
        </div>
    </div>
                
            
        
            
        
    </div>
</div>

<script>
(function() {
  var sidebar = document.querySelector('#sidebar');
  var selected = document.querySelector('.active');
  sidebar.scrollTop = selected.offsetTop - 200;

  // make dropdown from channel title
  var channel_title = document.querySelector("#channel-title");
  var channel_dropdown = document.querySelector("#channel-list");
  channel_title.addEventListener('click', function() {
    channel_title.classList.toggle('arrow');
    channel_dropdown.classList.toggle('close');
  });

  // make dropdown from group title
  var group_title = document.querySelector("#group-title");
  var group_dropdown = document.querySelector("#group-list");
  group_title.addEventListener('click', function() {
    group_title.classList.toggle('arrow');
    group_dropdown.classList.toggle('close');
  });

  // make dropdown from dm title
  var dm_title = document.querySelector("#dm-title");
  var dm_dropdown = document.querySelector("#dms-list");
  dm_title.addEventListener('click', function() {
    dm_title.classList.toggle('arrow');
    dm_dropdown.classList.toggle('close');
  });

  // make dromdown from group dm title
  var mpim_title = document.querySelector("#mpim-title");
  var mpim_dropdown = document.querySelector("#mpims-list");
  mpim_title.addEventListener('click', function() {
    mpim_title.classList.toggle('arrow');
    mpim_dropdown.classList.toggle('close');
  });
})()
</script>
</body>
</html>